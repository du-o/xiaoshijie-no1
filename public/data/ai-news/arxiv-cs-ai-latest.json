{
  "source": "arXiv CS.AI",
  "source_url": "https://export.arxiv.org/rss/cs.AI",
  "fetch_time": "2026-02-27T02:36:34.461Z",
  "articles": [
    {
      "title": "A Dynamic Survey of Soft Set Theory and Its Extensions",
      "date": "Thu, 26 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.21268v1 Announce Type: new Abstract: Soft set theory provides a direct framework for parameterized decision modeling by assigning to each attribute (parameter) a subset of a given universe, thereby representing uncertainty in a structured way [1, 2]. Over the past decades, the theory has expanded into numerous variants-including hypersoft sets, superhypersoft sets, TreeSoft sets, bipolar soft sets, and dynamic soft sets-and has been connected to diverse areas such as topology and matr",
      "url": "https://arxiv.org/abs/2602.21268",
      "category": "cs.AI"
    },
    {
      "title": "A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives",
      "date": "Thu, 26 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.21351v1 Announce Type: new Abstract: The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture",
      "url": "https://arxiv.org/abs/2602.21351",
      "category": [
        "cs.AI",
        "cs.IR",
        "cs.MA"
      ]
    },
    {
      "title": "Beyond Refusal: Probing the Limits of Agentic Self-Correction for Semantic Sensitive Information",
      "date": "Thu, 26 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.21496v1 Announce Type: new Abstract: While defenses for structured PII are mature, Large Language Models (LLMs) pose a new threat: Semantic Sensitive Information (SemSI), where models infer sensitive identity attributes, generate reputation-harmful content, or hallucinate potentially wrong information. The capacity of LLMs to self-regulate these complex, context-dependent sensitive information leaks without destroying utility remains an open scientific question. To address this, we in",
      "url": "https://arxiv.org/abs/2602.21496",
      "category": "cs.AI"
    },
    {
      "title": "ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning",
      "date": "Thu, 26 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.21534v1 Announce Type: new Abstract: Agentic reinforcement learning (ARL) has rapidly gained attention as a promising paradigm for training agents to solve complex, multi-step interactive tasks. Despite encouraging early results, ARL remains highly unstable, often leading to training collapse. This instability limits scalability to larger environments and longer interaction horizons, and constrains systematic exploration of algorithmic design choices. In this paper, we first propose A",
      "url": "https://arxiv.org/abs/2602.21534",
      "category": "cs.AI"
    },
    {
      "title": "Power and Limitations of Aggregation in Compound AI Systems",
      "date": "Thu, 26 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.21556v1 Announce Type: new Abstract: When designing compound AI systems, a common approach is to query multiple copies of the same model and aggregate the responses to produce a synthesized output. Given the homogeneity of these models, this raises the question of whether aggregation unlocks access to a greater set of outputs than querying a single model. In this work, we investigate the power and limitations of aggregation within a stylized principal-agent framework. This framework m",
      "url": "https://arxiv.org/abs/2602.21556",
      "category": [
        "cs.AI",
        "cs.GT"
      ]
    },
    {
      "title": "The ASIR Courage Model: A Phase-Dynamic Framework for Truth Transitions in Human and AI Systems",
      "date": "Thu, 26 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.21745v1 Announce Type: new Abstract: We introduce the ASIR (Awakened Shared Intelligence Relationship) Courage Model, a phase-dynamic framework that formalizes truth-disclosure as a state transition rather than a personality trait. The mode characterizes the shift from suppression (S0) to expression (S1) as occurring when facilitative forces exceed inhibitory thresholds, expressed by the inequality lambda(1+gamma)+psi > theta+phi, where the terms represent baseline openness, relationa",
      "url": "https://arxiv.org/abs/2602.21745",
      "category": [
        "cs.AI",
        "cs.CY"
      ]
    }
  ],
  "status": "success",
  "error": null
}