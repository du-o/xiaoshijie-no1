{
  "source": "arXiv CS.AI",
  "source_url": "https://export.arxiv.org/rss/cs.AI",
  "fetch_time": "2026-03-01T12:20:43.119Z",
  "articles": [
    {
      "title": "Graph Your Way to Inspiration: Integrating Co-Author Graphs with Retrieval-Augmented Generation for Large Language Model Based Scientific Idea Generation",
      "date": "Sat, 28 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.22215v1 Announce Type: new Abstract: Large Language Models (LLMs) demonstrate potential in the field of scientific idea generation. However, the generated results often lack controllable academic context and traceable inspiration pathways. To bridge this gap, this paper proposes a scientific idea generation system called GYWI, which combines author knowledge graphs with retrieval-augmented generation (RAG) to form an external knowledge base to provide controllable context and trace of",
      "url": "https://arxiv.org/abs/2602.22215",
      "category": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ]
    },
    {
      "title": "FIRE: A Comprehensive Benchmark for Financial Intelligence and Reasoning Evaluation",
      "date": "Sat, 28 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.22273v1 Announce Type: new Abstract: We introduce FIRE, a comprehensive benchmark designed to evaluate both the theoretical financial knowledge of LLMs and their ability to handle practical business scenarios. For theoretical assessment, we curate a diverse set of examination questions drawn from widely recognized financial qualification exams, enabling evaluation of LLMs deep understanding and application of financial knowledge. In addition, to assess the practical value of LLMs in r",
      "url": "https://arxiv.org/abs/2602.22273",
      "category": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Multi-Level Causal Embeddings",
      "date": "Sat, 28 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.22287v1 Announce Type: new Abstract: Abstractions of causal models allow for the coarsening of models such that relations of cause and effect are preserved. Whereas abstractions focus on the relation between two models, in this paper we study a framework for causal embeddings which enable multiple detailed models to be mapped into sub-systems of a coarser causal model. We define causal embeddings as a generalization of abstraction, and present a generalized notion of consistency. By d",
      "url": "https://arxiv.org/abs/2602.22287",
      "category": [
        "cs.AI",
        "cs.LG"
      ]
    },
    {
      "title": "Agent Behavioral Contracts: Formal Specification and Runtime Enforcement for Reliable Autonomous AI Agents",
      "date": "Sat, 28 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.22302v1 Announce Type: new Abstract: Traditional software relies on contracts -- APIs, type systems, assertions -- to specify and enforce correct behavior. AI agents, by contrast, operate on prompts and natural language instructions with no formal behavioral specification. This gap is the root cause of drift, governance failures, and frequent project failures in agentic AI deployments. We introduce Agent Behavioral Contracts (ABC), a formal framework that brings Design-by-Contract pri",
      "url": "https://arxiv.org/abs/2602.22302",
      "category": [
        "cs.AI",
        "cs.MA",
        "cs.SE"
      ]
    },
    {
      "title": "Vibe Researching as Wolf Coming: Can AI Agents with Skills Replace or Augment Social Scientists?",
      "date": "Sat, 28 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.22401v1 Announce Type: new Abstract: AI agents -- systems that execute multi-step reasoning workflows with persistent state, tool access, and specialist skills -- represent a qualitative shift from prior automation technologies in social science. Unlike chatbots that respond to isolated queries, AI agents can now read files, run code, query databases, search the web, and invoke domain-specific skills to execute entire research pipelines autonomously. This paper introduces the concept ",
      "url": "https://arxiv.org/abs/2602.22401",
      "category": [
        "cs.AI",
        "cs.HC"
      ]
    },
    {
      "title": "Towards Autonomous Memory Agents",
      "date": "Sat, 28 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.22406v1 Announce Type: new Abstract: Recent memory agents improve LLMs by extracting experiences and conversation history into an external storage. This enables low-overhead context assembly and online memory update without expensive LLM training. However, existing solutions remain passive and reactive; memory growth is bounded by information that happens to be available, while memory agents seldom seek external inputs in uncertainties. We propose autonomous memory agents that activel",
      "url": "https://arxiv.org/abs/2602.22406",
      "category": "cs.AI"
    }
  ],
  "status": "error",
  "error": "Parse error: Unknown RSS format"
}