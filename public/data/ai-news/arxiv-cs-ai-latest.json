{
  "source": "arXiv CS.AI",
  "source_url": "https://export.arxiv.org/rss/cs.AI",
  "fetch_time": "2026-02-18T12:30:47.141Z",
  "articles": [
    {
      "title": "Attention-gated U-Net model for semantic segmentation of brain tumors and feature extraction for survival prognosis",
      "date": "Wed, 18 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.15067v1 Announce Type: new Abstract: Gliomas, among the most common primary brain tumors, vary widely in aggressiveness, prognosis, and histology, making treatment challenging due to complex and time-intensive surgical interventions. This study presents an Attention-Gated Recurrent Residual U-Net (R2U-Net) based Triplanar (2.5D) model for improved brain tumor segmentation. The proposed model enhances feature representation and segmentation accuracy by integrating residual, recurrent, ",
      "url": "https://arxiv.org/abs/2602.15067",
      "category": "cs.AI"
    },
    {
      "title": "ResearchGym: Evaluating Language Model Agents on Real-World AI Research",
      "date": "Wed, 18 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.15112v1 Announce Type: new Abstract: We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each en",
      "url": "https://arxiv.org/abs/2602.15112",
      "category": "cs.AI"
    },
    {
      "title": "Protecting Language Models Against Unauthorized Distillation through Trace Rewriting",
      "date": "Wed, 18 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.15143v1 Announce Type: new Abstract: Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost put into developing frontier models. We investigate methods for modifying teacher-generated reasoning traces to achieve two objectives that deter unauthorized distillation: (1) \\emph{anti-distillation}, or",
      "url": "https://arxiv.org/abs/2602.15143",
      "category": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Panini: Continual Learning in Token Space via Structured Memory",
      "date": "Wed, 18 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.15156v1 Announce Type: new Abstract: Language models are increasingly used to reason over content they were not trained on, such as new documents, evolving knowledge, and user-specific data. A common approach is retrieval-augmented generation (RAG), which stores verbatim documents externally (as chunks) and retrieves only a relevant subset at inference time for an LLM to reason over. However, this results in inefficient usage of test-time compute (LLM repeatedly reasons over the same ",
      "url": "https://arxiv.org/abs/2602.15156",
      "category": "cs.AI"
    },
    {
      "title": "da Costa and Tarski meet Goguen and Carnap: a novel approach for ontological heterogeneity based on consequence systems",
      "date": "Wed, 18 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.15158v1 Announce Type: new Abstract: This paper presents a novel approach for ontological heterogeneity that draws heavily from Carnapian-Goguenism, as presented by Kutz, Mossakowski and L\\\"ucke (2010). The approach is provisionally designated da Costian-Tarskianism, named after da Costa's Principle of Tolerance in Mathematics and after Alfred Tarski's work on the concept of a consequence operator. The approach is based on the machinery of consequence systems, as developed by Carniell",
      "url": "https://arxiv.org/abs/2602.15158",
      "category": [
        "cs.AI",
        "cs.IR",
        "math.LO"
      ]
    },
    {
      "title": "Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs",
      "date": "Wed, 18 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.15173v1 Announce Type: new Abstract: The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions: (1) prospect representation (explicit vs. experience based) and (2) decision rationale (explanation). Our study, which involves 20 frontier and open LL",
      "url": "https://arxiv.org/abs/2602.15173",
      "category": "cs.AI"
    }
  ],
  "status": "success",
  "error": null
}