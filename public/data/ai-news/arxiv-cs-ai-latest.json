{
  "source": "arXiv CS.AI",
  "source_url": "https://export.arxiv.org/rss/cs.AI",
  "fetch_time": "2026-02-19T05:21:12.850Z",
  "articles": [
    {
      "title": "Towards Efficient Constraint Handling in Neural Solvers for Routing Problems",
      "date": "Thu, 19 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.16012v1 Announce Type: new Abstract: Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or implicit feasibility awareness can be inefficient or inapplicable for hard constraints. In this paper, we present Construct-and-Refine (CaR), the first general and efficie",
      "url": "https://arxiv.org/abs/2602.16012",
      "category": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ]
    },
    {
      "title": "Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection",
      "date": "Thu, 19 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.16037v1 Announce Type: new Abstract: Autonomous agentic workflows that iteratively refine their own behavior hold considerable promise, yet their failure modes remain poorly characterized. We investigate optimization instability, a phenomenon in which continued autonomous improvement paradoxically degrades classifier performance, using Pythia, an open-source framework for automated prompt optimization. Evaluating three clinical symptoms with varying prevalence (shortness of breath at ",
      "url": "https://arxiv.org/abs/2602.16037",
      "category": [
        "cs.AI",
        "cs.MA"
      ]
    },
    {
      "title": "How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment",
      "date": "Thu, 19 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.16039v1 Announce Type: new Abstract: The rapid rise of large language models (LLMs) is reshaping the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in adaptability to diverse question types and flexibility in output formats, they also introduce new challenges related to output uncertainty, stemming from the inherently probabilistic nature of LLMs. Output uncertainty is an inescapable challenge in automatic assessment, as assessme",
      "url": "https://arxiv.org/abs/2602.16039",
      "category": "cs.AI"
    },
    {
      "title": "Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025 Endocrinology Board-Style Examination",
      "date": "Thu, 19 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.16050v1 Announce Type: new Abstract: Background: Large language models have demonstrated strong performance on general medical examinations, but subspecialty clinical reasoning remains challenging due to rapidly evolving guidelines and nuanced evidence hierarchies. Methods: We evaluated January Mirror, an evidence-grounded clinical reasoning system, against frontier LLMs (GPT-5, GPT-5.2, Gemini-3-Pro) on a 120-question endocrinology board-style examination. Mirror integrates a curated",
      "url": "https://arxiv.org/abs/2602.16050",
      "category": [
        "cs.AI",
        "cs.CL"
      ]
    },
    {
      "title": "Improving Interactive In-Context Learning from Natural Language Feedback",
      "date": "Thu, 19 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.16066v1 Announce Type: new Abstract: Adapting one's thought process based on corrective feedback is an essential ability in human learning, particularly in collaborative settings. In contrast, the current large language model training paradigm relies heavily on modeling vast, static corpora. While effective for knowledge acquisition, it overlooks the interactive feedback loops essential for models to adapt dynamically to their context. In this work, we propose a framework that treats ",
      "url": "https://arxiv.org/abs/2602.16066",
      "category": "cs.AI"
    },
    {
      "title": "GPSBench: Do Large Language Models Understand GPS Coordinates?",
      "date": "Thu, 19 Feb 2026 05:00:00 GMT",
      "summary": "arXiv:2602.16105v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly deployed in applications that interact with the physical world, such as navigation, robotics, or mapping, making robust geospatial reasoning a critical capability. Despite that, LLMs' ability to reason about GPS coordinates and real-world geography remains underexplored. We introduce GPSBench, a dataset of 57,800 samples across 17 tasks for evaluating geospatial reasoning in LLMs, spanning geometric coo",
      "url": "https://arxiv.org/abs/2602.16105",
      "category": "cs.AI"
    }
  ],
  "status": "success",
  "error": null
}