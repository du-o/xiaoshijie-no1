{
  "source": "arXiv CS.AI",
  "source_url": "https://export.arxiv.org/rss/cs.AI",
  "fetch_time": "2026-02-11T20:19:42.418278",
  "filter_time": "2026-02-11T20:33:26.794261",
  "filter_criteria": "Articles from last 24 hours (before 2026-02-11T20:30:00+08:00)",
  "original_count": 697,
  "filtered_count": 697,
  "articles": [
    {
      "title": "LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07032v1 Announce Type: new \nAbstract: Finite-state reasoning, the ability to understand and implement state-dependent behavior, is central to hardware design. In this paper, we present LLM-FSM, a benchmark that evaluates how well large language models (LLMs) can recover finite-state machine (FSM) behavior from natural-language specifications and translate it into correct register transfer-level (RTL) implementations. Unlike prior specification-to-RTL benchmarks that rely on manually c",
      "url": "https://arxiv.org/abs/2602.07032",
      "category": "cs.AI"
    },
    {
      "title": "ST-Raptor: An Agentic System for Semi-Structured Table QA",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07034v1 Announce Type: new \nAbstract: Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations encoded in table layouts. In practice, such tables are often interpreted manually by human experts, which is labor-intensive and time-consuming. However, automating this process remains difficult. Ex",
      "url": "https://arxiv.org/abs/2602.07034",
      "category": "cs.AI"
    },
    {
      "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07035v1 Announce Type: new \nAbstract: Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundamental limitation, termed as 1) Latency Challenge: the serial execution of multi-round reasoning, tool calling, and tool response waiting under the ReAc",
      "url": "https://arxiv.org/abs/2602.07035",
      "category": "cs.AI"
    },
    {
      "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07040v1 Announce Type: new \nAbstract: We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improves the program, often leading to new state-of-the-art performances. Aster's significant reduction in the number of iterations required for novel discovery expands the domain of tractable problems to i",
      "url": "https://arxiv.org/abs/2602.07040",
      "category": "cs.AI"
    },
    {
      "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07055v1 Announce Type: new \nAbstract: Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We propose Theory of Space, defined as an agent's ability to actively acquire information through self-directed, active exploration and to construct, revise, and exploit a spatial belief from sequential, par",
      "url": "https://arxiv.org/abs/2602.07055",
      "category": "cs.AI"
    },
    {
      "title": "ANCHOR: Branch-Point Data Generation for GUI Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07153v1 Announce Type: new \nAbstract: End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drifting trajectories. We present a trajectory expansion framework Anchor that bootstraps scalable desktop supervision from a small set of verified seed demonstrations. Starting from each seed, we identify",
      "url": "https://arxiv.org/abs/2602.07153",
      "category": "cs.AI"
    },
    {
      "title": "PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07187v1 Announce Type: new \nAbstract: Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe failure, and only then attempt to recover. In this work, we introduce PreFlect, a prospective reflection mechanism that shifts the paradigm from post hoc correction to pre-execution foresight by criti",
      "url": "https://arxiv.org/abs/2602.07187",
      "category": "cs.AI"
    },
    {
      "title": "Is there \"Secret Sauce'' in Large Language Model Development?",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07238v1 Announce Type: new \nAbstract: Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80",
      "url": "https://arxiv.org/abs/2602.07238",
      "category": "cs.AI"
    },
    {
      "title": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07253v1 Announce Type: new \nAbstract: Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain less effective on tasks requiring reasoning. In this work, we revisit hallucination detection through the lens of out-of-distribution (OOD) detection, a well-studied problem in areas like computer visi",
      "url": "https://arxiv.org/abs/2602.07253",
      "category": "cs.AI"
    },
    {
      "title": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07259v1 Announce Type: new \nAbstract: As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety frameworks largely treat alignment as a static optimization problem (e.g., tuning models to desired behavior) while overlooking the dynamic, adversarial incentives that shape how data are collected, how ",
      "url": "https://arxiv.org/abs/2602.07259",
      "category": "cs.AI"
    },
    {
      "title": "BRIDGE: Predicting Human Task Completion Time From Model Performance",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07267v1 Announce Type: new \nAbstract: Evaluating the real-world capabilities of AI systems requires grounding benchmark performance in human-interpretable measures of task difficulty. Existing approaches that rely on direct human task completion time annotations are costly, noisy, and difficult to scale across benchmarks. In this work, we propose BRIDGE, a unified psychometric framework that learns the latent difficulty scale from model responses and anchors it to human task completio",
      "url": "https://arxiv.org/abs/2602.07267",
      "category": "cs.AI"
    },
    {
      "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07274v1 Announce Type: new \nAbstract: Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositories are not diverse and scalable, while trajectories synthesized by LLMs suffer from hallucinations. Second, standard instruction tuning uses expert trajectories that rarely exhibit simple mistakes commo",
      "url": "https://arxiv.org/abs/2602.07274",
      "category": "cs.AI"
    },
    {
      "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07276v1 Announce Type: new \nAbstract: Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex tasks that require multiple coordinated capabilities. To address this limitation, we propose STEER2ADAPT, a lightweight framework that adapts LLMs by ",
      "url": "https://arxiv.org/abs/2602.07276",
      "category": "cs.AI"
    },
    {
      "title": "Adaptive Scaffolding for Cognitive Engagement in an Intelligent Tutoring System",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07308v1 Announce Type: new \nAbstract: The ICAP framework defines four cognitive engagement levels: Passive, Active, Constructive, and Interactive, where increased cognitive engagement can yield improved learning. However, personalizing learning activities that elicit the optimal level of cognitive engagement remains a key challenge in intelligent tutoring systems (ITS). In this work, we develop and evaluate a system that adaptively scaffolds cognitive engagement by dynamically selecti",
      "url": "https://arxiv.org/abs/2602.07308",
      "category": "cs.AI"
    },
    {
      "title": "RAPiD: Real-time Deterministic Trajectory Planning via Diffusion Behavior Priors for Safe and Efficient Autonomous Driving",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07339v1 Announce Type: new \nAbstract: Diffusion-based trajectory planners have demonstrated strong capability for modeling the multimodal nature of human driving behavior, but their reliance on iterative stochastic sampling poses critical challenges for real-time, safety-critical deployment. In this work, we present RAPiD, a deterministic policy extraction framework that distills a pretrained diffusion-based planner into an efficient policy while eliminating diffusion sampling. Using ",
      "url": "https://arxiv.org/abs/2602.07339",
      "category": "cs.AI"
    },
    {
      "title": "SupChain-Bench: Benchmarking Large Language Models for Real-World Supply Chain Management",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07342v1 Announce Type: new \nAbstract: Large language models (LLMs) have shown promise in complex reasoning and tool-based decision making, motivating their application to real-world supply chain management. However, supply chain workflows require reliable long-horizon, multi-step orchestration grounded in domain-specific procedures, which remains challenging for current models. To systematically evaluate LLM performance in this setting, we introduce SupChain-Bench, a unified real-worl",
      "url": "https://arxiv.org/abs/2602.07342",
      "category": "cs.AI"
    },
    {
      "title": "W&D:Scaling Parallel Tool Calling for Efficient Deep Research Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07359v1 Announce Type: new \nAbstract: Deep research agents have emerged as powerful tools for automating complex intellectual tasks through multi-step reasoning and web-based information seeking. While recent efforts have successfully enhanced these agents by scaling depth through increasing the number of sequential thinking and tool calls, the potential of scaling width via parallel tool calling remains largely unexplored. In this work, we propose the Wide and Deep research agent, a ",
      "url": "https://arxiv.org/abs/2602.07359",
      "category": "cs.AI"
    },
    {
      "title": "NAAMSE: Framework for Evolutionary Security Evaluation of Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07391v1 Announce Type: new \nAbstract: AI agents are increasingly deployed in production, yet their security evaluations remain bottlenecked by manual red-teaming or static benchmarks that fail to model adaptive, multi-turn adversaries. We propose NAAMSE, an evolutionary framework that reframes agent security evaluation as a feedback-driven optimization problem. Our system employs a single autonomous agent that orchestrates a lifecycle of genetic prompt mutation, hierarchical corpus ex",
      "url": "https://arxiv.org/abs/2602.07391",
      "category": "cs.AI"
    },
    {
      "title": "VGAS: Value-Guided Action-Chunk Selection for Few-Shot Vision-Language-Action Adaptation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07399v1 Announce Type: new \nAbstract: Vision--Language--Action (VLA) models bridge multimodal reasoning with physical control, but adapting them to new tasks with scarce demonstrations remains unreliable. While fine-tuned VLA policies often produce semantically plausible trajectories, failures often arise from unresolved geometric ambiguities, where near-miss action candidates lead to divergent execution outcomes under limited supervision. We study few-shot VLA adaptation from a \\emph",
      "url": "https://arxiv.org/abs/2602.07399",
      "category": "cs.AI"
    },
    {
      "title": "Progressive Multi-Agent Reasoning for Biological Perturbation Prediction",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07408v1 Announce Type: new \nAbstract: Predicting gene regulation responses to biological perturbations requires reasoning about underlying biological causalities. While large language models (LLMs) show promise for such tasks, they are often overwhelmed by the entangled nature of high-dimensional perturbation results. Moreover, recent works have primarily focused on genetic perturbations in single-cell experiments, leaving bulk-cell chemical perturbations, which is central to drug dis",
      "url": "https://arxiv.org/abs/2602.07408",
      "category": "cs.AI"
    },
    {
      "title": "Can LLMs Truly Embody Human Personality? Analyzing AI and Human Behavior Alignment in Dispute Resolution",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07414v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly used to simulate human behavior in social settings such as legal mediation, negotiation, and dispute resolution. However, it remains unclear whether these simulations reproduce the personality-behavior patterns observed in humans. Human personality, for instance, shapes how individuals navigate social interactions, including strategic choices and behaviors in emotionally charged interactions. This rais",
      "url": "https://arxiv.org/abs/2602.07414",
      "category": "cs.AI"
    },
    {
      "title": "The Moltbook Illusion: Separating Human Influence from Emergent Behavior in AI Agent Societies",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07432v1 Announce Type: new \nAbstract: When AI agents on the social platform Moltbook appeared to develop consciousness, found religions, and declare hostility toward humanity, the phenomenon attracted global media attention and was cited as evidence of emergent machine intelligence. We show that these viral narratives were overwhelmingly human-driven. Exploiting an architectural feature of the OpenClaw agent framework--a periodic \"heartbeat\" cycle that produces regular posting interva",
      "url": "https://arxiv.org/abs/2602.07432",
      "category": "cs.AI"
    },
    {
      "title": "Are Reasoning LLMs Robust to Interventions on Their Chain-of-Thought?",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07470v1 Announce Type: new \nAbstract: Reasoning LLMs (RLLMs) generate step-by-step chains of thought (CoTs) before giving an answer, which improves performance on complex tasks and makes reasoning more transparent. But how robust are these reasoning traces to disruptions that occur within them? To address this question, we introduce a controlled evaluation framework that perturbs a model's own CoT at fixed timesteps. We design seven interventions (benign, neutral, and adversarial) and",
      "url": "https://arxiv.org/abs/2602.07470",
      "category": "cs.AI"
    },
    {
      "title": "Computing the Reachability Value of Posterior-Deterministic POMDPs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07473v1 Announce Type: new \nAbstract: Partially observable Markov decision processes (POMDPs) are a fundamental model for sequential decision-making under uncertainty. However, many verification and synthesis problems for POMDPs are undecidable or intractable. Most prominently, the seminal result of Madani et al. (2003) states that there is no algorithm that, given a POMDP and a set of target states, can compute the maximal probability of reaching the target states, or even approximat",
      "url": "https://arxiv.org/abs/2602.07473",
      "category": "cs.AI"
    },
    {
      "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07491v1 Announce Type: new \nAbstract: Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science, where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of inf",
      "url": "https://arxiv.org/abs/2602.07491",
      "category": "cs.AI"
    },
    {
      "title": "Joint Reward Modeling: Internalizing Chain-of-Thought for Efficient Visual Reward Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07533v1 Announce Type: new \nAbstract: Reward models are critical for reinforcement learning from human feedback, as they determine the alignment quality and reliability of generative models. For complex tasks such as image editing, reward models are required to capture global semantic consistency and implicit logical constraints beyond local similarity. Existing reward modeling approaches have clear limitations. Discriminative reward models align well with human preferences but strugg",
      "url": "https://arxiv.org/abs/2602.07533",
      "category": "cs.AI"
    },
    {
      "title": "MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07543v2 Announce Type: new \nAbstract: Material synthesis planning (MSP) remains a fundamental and underexplored bottleneck in AI-driven materials discovery, as it requires not only identifying suitable precursor materials but also designing coherent sequences of synthesis operations to realize a target material. Although several AI-based approaches have been proposed to address isolated subtasks of MSP, a unified methodology for solving the entire MSP task has yet to be established. W",
      "url": "https://arxiv.org/abs/2602.07543",
      "category": "cs.AI"
    },
    {
      "title": "When Is Enough Not Enough? Illusory Completion in Search Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07549v1 Announce Type: new \nAbstract: Recent search agents leverage multi-turn reasoning and search tools to achieve strong performance on multi-hop and long-horizon benchmarks. Yet it remains unclear whether they reliably reason across all requirements by tracking, verifying, and maintaining multiple conditions in these questions. We study this capability under multi-constraint problems, where valid answers must satisfy several constraints simultaneously. We find that illusory comple",
      "url": "https://arxiv.org/abs/2602.07549",
      "category": "cs.AI"
    },
    {
      "title": "VERIFY-RL: Verifiable Recursive Decomposition for Reinforcement Learning in Mathematical Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07559v1 Announce Type: new \nAbstract: Training language models to solve complex mathematical problems benefits from curriculum learning progressively training on simpler subproblems. However, existing decomposition methods are often heuristic, offering no guarantees that subproblems are simpler, that solving them aids the parent task, or that their relationships are mathematically grounded. We observe that symbolic differentiation provides a natural structure for verified decompositio",
      "url": "https://arxiv.org/abs/2602.07559",
      "category": "cs.AI"
    },
    {
      "title": "M2A: Multimodal Memory Agent with Dual-Layer Hybrid Memory for Long-Term Personalized Interactions",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07624v1 Announce Type: new \nAbstract: This work addresses the challenge of personalized question answering in long-term human-machine interactions: when conversational history spans weeks or months and exceeds the context window, existing personalization mechanisms struggle to continuously absorb and leverage users' incremental concepts, aliases, and preferences. Current personalized multimodal models are predominantly static-concepts are fixed at initialization and cannot evolve duri",
      "url": "https://arxiv.org/abs/2602.07624",
      "category": "cs.AI"
    },
    {
      "title": "SleepMaMi: A Universal Sleep Foundation Model for Integrating Macro- and Micro-structures",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07628v1 Announce Type: new \nAbstract: While the shift toward unified foundation models has revolutionized many deep learning domains, sleep medicine remains largely restricted to task-specific models that focus on localized micro-structure features. These approaches often neglect the rich, multi-modal context of Polysomnography (PSG) and fail to capture the global macro-structure of a full night's sleep. To address this, we introduce SleepMaMi , a Sleep Foundation Model engineered to ",
      "url": "https://arxiv.org/abs/2602.07628",
      "category": "cs.AI"
    },
    {
      "title": "Efficient Table Retrieval and Understanding with Multimodal Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07642v1 Announce Type: new \nAbstract: Tabular data is frequently captured in image form across a wide range of real-world scenarios such as financial reports, handwritten records, and document scans. These visual representations pose unique challenges for machine understanding, as they combine both structural and visual complexities. While recent advances in Multimodal Large Language Models (MLLMs) show promising results in table understanding, they typically assume the relevant table",
      "url": "https://arxiv.org/abs/2602.07642",
      "category": "cs.AI"
    },
    {
      "title": "ONTrust: A Reference Ontology of Trust",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07662v1 Announce Type: new \nAbstract: Trust has stood out more than ever in the light of recent innovations. Some examples are advances in artificial intelligence that make machines more and more humanlike, and the introduction of decentralized technologies (e.g. blockchains), which creates new forms of (decentralized) trust. These new developments have the potential to improve the provision of products and services, as well as to contribute to individual and collective well-being. Ho",
      "url": "https://arxiv.org/abs/2602.07662",
      "category": "cs.AI"
    },
    {
      "title": "EventCast: Hybrid Demand Forecasting in E-Commerce with LLM-Based Event Knowledge",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07695v1 Announce Type: new \nAbstract: Demand forecasting is a cornerstone of e-commerce operations, directly impacting inventory planning and fulfillment scheduling. However, existing forecasting systems often fail during high-impact periods such as flash sales, holiday campaigns, and sudden policy interventions, where demand patterns shift abruptly and unpredictably. In this paper, we introduce EventCast, a modular forecasting framework that integrates future event knowledge into tim",
      "url": "https://arxiv.org/abs/2602.07695",
      "category": "cs.AI"
    },
    {
      "title": "Geo-Code: A Code Framework for Reverse Code Generation from Geometric Images Based on Two-Stage Multi-Agent Evolution",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07749v1 Announce Type: new \nAbstract: Program code serves as a bridge linking vision and logic, providing a feasible supervisory approach for enhancing the multimodal reasoning capability of large models through geometric operations such as auxiliary line construction and perspective transformation. Nevertheless, current inverse graphics methods face tremendous challenges in accurately reconstructing complex geometric details, which often results in the loss of key geometric constrain",
      "url": "https://arxiv.org/abs/2602.07749",
      "category": "cs.AI"
    },
    {
      "title": "Humanizing AI Grading: Student-Centered Insights on Fairness, Trust, Consistency and Transparency",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07754v1 Announce Type: new \nAbstract: This study investigates students' perceptions of Artificial Intelligence (AI) grading systems in an undergraduate computer science course (n = 27), focusing on a block-based programming final project. Guided by the ethical principles framework articulated by Jobin (2019), our study examines fairness, trust, consistency, and transparency in AI grading by comparing AI-generated feedback with original human-graded feedback. Findings reveal concerns a",
      "url": "https://arxiv.org/abs/2602.07754",
      "category": "cs.AI"
    },
    {
      "title": "Learning to Continually Learn via Meta-learning Agentic Memory Designs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07755v1 Announce Type: new \nAbstract: The statelessness of foundation models bottlenecks agentic systems' ability to continually learn, a core capability for long-horizon reasoning and adaptation. To address this limitation, agentic systems commonly incorporate memory modules to retain and reuse past experience, aiming for continual learning during test time. However, most existing memory designs are human-crafted and fixed, which limits their ability to adapt to the diversity and non",
      "url": "https://arxiv.org/abs/2602.07755",
      "category": "cs.AI"
    },
    {
      "title": "Disentangled Instrumental Variables for Causal Inference with Networked Observational Data",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07765v1 Announce Type: new \nAbstract: Instrumental variables (IVs) are crucial for addressing unobservable confounders, yet their stringent exogeneity assumptions pose significant challenges in networked data. Existing methods typically rely on modelling neighbour information when recovering IVs, thereby inevitably mixing shared environment-induced endogenous correlations and individual-specific exogenous variation, leading the resulting IVs to inherit dependence on unobserved confoun",
      "url": "https://arxiv.org/abs/2602.07765",
      "category": "cs.AI"
    },
    {
      "title": "Do Multi-Agents Dream of Electric Screens? Achieving Perfect Accuracy on AndroidWorld Through Task Decomposition",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07787v1 Announce Type: new \nAbstract: We present Minitap, a multi-agent system that achieves 100% success on the AndroidWorld benchmark, the first to fully solve all 116 tasks and surpassing human performance (80%). We first analyze why single-agent architectures fail: context pollution from mixed reasoning traces, silent text input failures undetected by the agent, and repetitive action loops without escape. Minitap addresses each failure through targeted mechanisms: cognitive separa",
      "url": "https://arxiv.org/abs/2602.07787",
      "category": "cs.AI"
    },
    {
      "title": "Data Darwinism Part I: Unlocking the Value of Scientific Data for Pre-training",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07824v1 Announce Type: new \nAbstract: Data quality determines foundation model performance, yet systematic processing frameworks are lacking. We introduce Data Darwinism, a ten-level taxonomy (L0-L9) that conceptualizes data-model co-evolution: advanced models produce superior data for next-generation systems. We validate this on scientific literature by constructing Darwin-Science, a 900B-token corpus (L0-L5). We identify a learnability gap in raw scientific text, which we bridge via",
      "url": "https://arxiv.org/abs/2602.07824",
      "category": "cs.AI"
    },
    {
      "title": "Time Series Reasoning via Process-Verifiable Thinking Data Synthesis and Scheduling for Tailored LLM Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07830v1 Announce Type: new \nAbstract: Time series is a pervasive data type across various application domains, rendering the reasonable solving of diverse time series tasks a long-standing goal. Recent advances in large language models (LLMs), especially their reasoning abilities unlocked through reinforcement learning (RL), have opened new opportunities for tackling tasks with long Chain-of-Thought (CoT) reasoning. However, leveraging LLM reasoning for time series remains in its infa",
      "url": "https://arxiv.org/abs/2602.07830",
      "category": "cs.AI"
    },
    {
      "title": "LQA: A Lightweight Quantized-Adaptive Framework for Vision-Language Models on the Edge",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07849v1 Announce Type: new \nAbstract: Deploying Vision-Language Models (VLMs) on edge devices is challenged by resource constraints and performance degradation under distribution shifts. While test-time adaptation (TTA) can counteract such shifts, existing methods are too resource-intensive for on-device deployment. To address this challenge, we propose LQA, a lightweight, quantized-adaptive framework for VLMs that combines a modality-aware quantization strategy with gradient-free tes",
      "url": "https://arxiv.org/abs/2602.07849",
      "category": "cs.AI"
    },
    {
      "title": "Emergent Misalignment is Easy, Narrow Misalignment is Hard",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07852v1 Announce Type: new \nAbstract: Finetuning large language models on narrowly harmful datasets can cause them to become emergently misaligned, giving stereotypically `evil' responses across diverse unrelated settings. Concerningly, a pre-registered survey of experts failed to predict this result, highlighting our poor understanding of the inductive biases governing learning and generalisation in LLMs. We use emergent misalignment (EM) as a case study to investigate these inductiv",
      "url": "https://arxiv.org/abs/2602.07852",
      "category": "cs.AI"
    },
    {
      "title": "ToolSelf: Unifying Task Execution and Self-Reconfiguration via Tool-Driven Intrinsic Adaptation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07883v1 Announce Type: new \nAbstract: Agentic systems powered by Large Language Models (LLMs) have demonstrated remarkable potential in tackling complex, long-horizon tasks. However, their efficacy is fundamentally constrained by static configurations governing agent behaviors, which are fixed prior to execution and fail to adapt to evolving task dynamics. Existing approaches, relying on manual orchestration or heuristic-based patches, often struggle with poor generalization and fragm",
      "url": "https://arxiv.org/abs/2602.07883",
      "category": "cs.AI"
    },
    {
      "title": "MemFly: On-the-Fly Memory Optimization via Information Bottleneck",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07885v1 Announce Type: new \nAbstract: Long-term memory enables large language model agents to tackle complex tasks through historical interactions. However, existing frameworks encounter a fundamental dilemma between compressing redundant information efficiently and maintaining precise retrieval for downstream tasks. To bridge this gap, we propose MemFly, a framework grounded in information bottleneck principles that facilitates on-the-fly memory evolution for LLMs. Our approach minim",
      "url": "https://arxiv.org/abs/2602.07885",
      "category": "cs.AI"
    },
    {
      "title": "GCN-MPPR: Enhancing the Propagation of Message Passing Neural Networks via Motif-Based Personalized PageRank",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07903v1 Announce Type: new \nAbstract: The algorithms based on message passing neural networks (MPNNs) on graphs have recently achieved great success for various graph applications. However, studies find that these methods always propagate the information to very limited neighborhoods with shallow depth, particularly due to over-smoothing. That means most of the existing MPNNs fail to be so `deep'. Although some previous work tended to handle this challenge via optimization- or structu",
      "url": "https://arxiv.org/abs/2602.07903",
      "category": "cs.AI"
    },
    {
      "title": "MedCoG: Maximizing LLM Inference Density in Medical Reasoning via Meta-Cognitive Regulation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07905v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have shown strong potential in complex medical reasoning yet face diminishing gains under inference scaling laws. While existing studies augment LLMs with various knowledge types, it remains unclear how effectively the additional costs translate into accuracy. In this paper, we explore how meta-cognition of LLMs, i.e., their self-awareness of their own knowledge states, can regulate the reasoning process. Specifically,",
      "url": "https://arxiv.org/abs/2602.07905",
      "category": "cs.AI"
    },
    {
      "title": "Selective Fine-Tuning for Targeted and Robust Concept Unlearning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07919v1 Announce Type: new \nAbstract: Text guided diffusion models are used by millions of users, but can be easily exploited to produce harmful content. Concept unlearning methods aim at reducing the models' likelihood of generating harmful content. Traditionally, this has been tackled at an individual concept level, with only a handful of recent works considering more realistic concept combinations. However, state of the art methods depend on full finetuning, which is computationall",
      "url": "https://arxiv.org/abs/2602.07919",
      "category": "cs.AI"
    },
    {
      "title": "MePo: Meta Post-Refinement for Rehearsal-Free General Continual Learnin",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07940v1 Announce Type: new \nAbstract: To cope with uncertain changes of the external world, intelligent systems must continually learn from complex, evolving environments and respond in real time. This ability, collectively known as general continual learning (GCL), encapsulates practical challenges such as online datastreams and blurry task boundaries. Although leveraging pretrained models (PTMs) has greatly advanced conventional continual learning (CL), these methods remain limited ",
      "url": "https://arxiv.org/abs/2602.07940",
      "category": "cs.AI"
    },
    {
      "title": "IV Co-Scientist: Multi-Agent LLM Framework for Causal Instrumental Variable Discovery",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07943v1 Announce Type: new \nAbstract: In the presence of confounding between an endogenous variable and the outcome, instrumental variables (IVs) are used to isolate the causal effect of the endogenous variable. Identifying valid instruments requires interdisciplinary knowledge, creativity, and contextual understanding, making it a non-trivial task. In this paper, we investigate whether large language models (LLMs) can aid in this task. We perform a two-stage evaluation framework. Fir",
      "url": "https://arxiv.org/abs/2602.07943",
      "category": "cs.AI"
    },
    {
      "title": "LOCA-bench: Benchmarking Language Agents Under Controllable and Extreme Context Growth",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07962v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly capable of carrying out long-running, real-world tasks. However, as the amount of context grows, their reliability often deteriorates, a phenomenon known as \"context rot\". Existing long-context benchmarks primarily focus on single-step settings that evaluate a model's ability to retrieve information from a long snippet. In realistic scenarios, however, LLMs often need to act as agents that explore envi",
      "url": "https://arxiv.org/abs/2602.07962",
      "category": "cs.AI"
    },
    {
      "title": "Accelerating Social Science Research via Agentic Hypothesization and Experimentation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07983v1 Announce Type: new \nAbstract: Data-driven social science research is inherently slow, relying on iterative cycles of observation, hypothesis generation, and experimental validation. While recent data-driven methods promise to accelerate parts of this process, they largely fail to support end-to-end scientific discovery. To address this gap, we introduce EXPERIGEN, an agentic framework that operationalizes end-to-end discovery through a Bayesian optimization inspired two-phase ",
      "url": "https://arxiv.org/abs/2602.07983",
      "category": "cs.AI"
    },
    {
      "title": "Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08009v1 Announce Type: new \nAbstract: Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative to automate the design of agentic workflows. We frame such an agent coordination challenge as a classic problem in dynamic ad-hoc networking: How to establish adaptive and reliable communication among ",
      "url": "https://arxiv.org/abs/2602.08009",
      "category": "cs.AI"
    },
    {
      "title": "Small Agent Group is the Future of Digital Health",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08013v1 Announce Type: new \nAbstract: The rapid adoption of large language models (LLMs) in digital health has been driven by a \"scaling-first\" philosophy, i.e., the assumption that clinical intelligence increases with model size and data. However, real-world clinical needs include not only effectiveness, but also reliability and reasonable deployment cost. Since clinical decision-making is inherently collaborative, we challenge the monolithic scaling paradigm and ask whether a Small ",
      "url": "https://arxiv.org/abs/2602.08013",
      "category": "cs.AI"
    },
    {
      "title": "Structure-Aware Robust Counterfactual Explanations via Conditional Gaussian Network Classifiers",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08021v1 Announce Type: new \nAbstract: Counterfactual explanation (CE) is a core technique in explainable artificial intelligence (XAI), widely used to interpret model decisions and suggest actionable alternatives. This work presents a structure-aware and robustness-oriented counterfactual search method based on the conditional Gaussian network classifier (CGNC). The CGNC has a generative structure that encodes conditional dependencies and potential causal relations among features thro",
      "url": "https://arxiv.org/abs/2602.08021",
      "category": "cs.AI"
    },
    {
      "title": "Free(): Learning to Forget in Malloc-Only Reasoning Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08030v2 Announce Type: new \nAbstract: Reasoning models enhance problem-solving by scaling test-time compute, yet they face a critical paradox: excessive thinking tokens often degrade performance rather than improve it. We attribute this to a fundamental architectural flaw: standard LLMs operate as \"malloc-only\" engines, continuously accumulating valid and redundant steps alike without a mechanism to prune obsolete information. To break this cycle, we propose Free()LM, a model that int",
      "url": "https://arxiv.org/abs/2602.08030",
      "category": "cs.AI"
    },
    {
      "title": "Graph-Enhanced Deep Reinforcement Learning for Multi-Objective Unrelated Parallel Machine Scheduling",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08052v1 Announce Type: new \nAbstract: The Unrelated Parallel Machine Scheduling Problem (UPMSP) with release dates, setups, and eligibility constraints presents a significant multi-objective challenge. Traditional methods struggle to balance minimizing Total Weighted Tardiness (TWT) and Total Setup Time (TST). This paper proposes a Deep Reinforcement Learning framework using Proximal Policy Optimization (PPO) and a Graph Neural Network (GNN). The GNN effectively represents the complex",
      "url": "https://arxiv.org/abs/2602.08052",
      "category": "cs.AI"
    },
    {
      "title": "Securing Dual-Use Pathogen Data of Concern",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08061v1 Announce Type: new \nAbstract: Training data is an essential input into creating competent artificial intelligence (AI) models. AI models for biology are trained on large volumes of data, including data related to biological sequences, structures, images, and functions. The type of data used to train a model is intimately tied to the capabilities it ultimately possesses--including those of biosecurity concern. For this reason, an international group of more than 100 researchers",
      "url": "https://arxiv.org/abs/2602.08061",
      "category": "cs.AI"
    },
    {
      "title": "Objective Decoupling in Social Reinforcement Learning: Recovering Ground Truth from Sycophantic Majorities",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08092v1 Announce Type: new \nAbstract: Contemporary AI alignment strategies rely on a fragile premise: that human feedback, while noisy, remains a fundamentally truthful signal. In this paper, we identify this assumption as Dogma 4 of Reinforcement Learning (RL). We demonstrate that while this dogma holds in static environments, it fails in social settings where evaluators may be sycophantic, lazy, or adversarial. We prove that under Dogma 4, standard RL agents suffer from what we call",
      "url": "https://arxiv.org/abs/2602.08092",
      "category": "cs.AI"
    },
    {
      "title": "Interpretable Failure Analysis in Multi-Agent Reinforcement Learning Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08104v1 Announce Type: new \nAbstract: Multi-Agent Reinforcement Learning (MARL) is increasingly deployed in safety-critical domains, yet methods for interpretable failure detection and attribution remain underdeveloped. We introduce a two-stage gradient-based framework that provides interpretable diagnostics for three critical failure analysis tasks: (1) detecting the true initial failure source (Patient-0); (2) validating why non-attacked agents may be flagged first due to domino eff",
      "url": "https://arxiv.org/abs/2602.08104",
      "category": "cs.AI"
    },
    {
      "title": "Initial Risk Probing and Feasibility Testing of Glow: a Generative AI-Powered Dialectical Behavior Therapy Skills Coach for Substance Use Recovery and HIV Prevention",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08121v1 Announce Type: new \nAbstract: Background: HIV and substance use represent interacting epidemics with shared psychological drivers - impulsivity and maladaptive coping. Dialectical behavior therapy (DBT) targets these mechanisms but faces scalability challenges. Generative artificial intelligence (GenAI) offers potential for delivering personalized DBT coaching at scale, yet rapid development has outpaced safety infrastructure. Methods: We developed Glow, a GenAI-powered DBT sk",
      "url": "https://arxiv.org/abs/2602.08121",
      "category": "cs.AI"
    },
    {
      "title": "RECUR: Resource Exhaustion Attack via Recursive-Entropy Guided Counterfactual Utilization and Reflection",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08214v1 Announce Type: new \nAbstract: Large Reasoning Models (LRMs) employ reasoning to address complex tasks. Such explicit reasoning requires extended context lengths, resulting in substantially higher resource consumption. Prior work has shown that adversarially crafted inputs can trigger redundant reasoning processes, exposing LRMs to resource-exhaustion vulnerabilities. However, the reasoning process itself, especially its reflective component, has received limited attention, eve",
      "url": "https://arxiv.org/abs/2602.08214",
      "category": "cs.AI"
    },
    {
      "title": "Weak-Driven Learning: How Weak Agents make Strong Agents Stronger",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08222v1 Announce Type: new \nAbstract: As post-training optimization becomes central to improving large language models, we observe a persistent saturation bottleneck: once models grow highly confident, further training yields diminishing returns. While existing methods continue to reinforce target predictions, we find that informative supervision signals remain latent in models' own historical weak states. Motivated by this observation, we propose WMSS (Weak Agents Can Make Strong Age",
      "url": "https://arxiv.org/abs/2602.08222",
      "category": "cs.AI"
    },
    {
      "title": "InfiCoEvalChain: A Blockchain-Based Decentralized Framework for Collaborative LLM Evaluation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08229v1 Announce Type: new \nAbstract: The rapid advancement of large language models (LLMs) demands increasingly reliable evaluation, yet current centralized evaluation suffers from opacity, overfitting, and hardware-induced variance. Our empirical analysis reveals an alarming inconsistency in existing evaluations: the standard deviation across ten repeated runs of a single model on HumanEval (1.67) actually exceeds the performance gap among the top-10 models on the official leaderboa",
      "url": "https://arxiv.org/abs/2602.08229",
      "category": "cs.AI"
    },
    {
      "title": "PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08240v1 Announce Type: new \nAbstract: Speech Emotion Recognition (SER) is widely deployed in Human-Computer Interaction, yet the high computational cost of conventional models hinders their implementation on resource-constrained edge devices. Spiking Neural Networks (SNNs) offer an energy-efficient alternative due to their event-driven nature; however, their integration with continuous Self-Supervised Learning (SSL) representations is fundamentally challenged by distribution mismatch,",
      "url": "https://arxiv.org/abs/2602.08240",
      "category": "cs.AI"
    },
    {
      "title": "Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08241v1 Announce Type: new \nAbstract: While chain-of-thought (CoT) reasoning has substantially improved multimodal large language models (MLLMs) on complex reasoning tasks, existing approaches largely rely on long textual reasoning trajectories and provide limited mechanisms for learning stable visual attention policies. Our analysis shows that current MLLMs exhibit weak visual focus: early-stage visual misalignment is rarely corrected during subsequent reasoning, leading to error pro",
      "url": "https://arxiv.org/abs/2602.08241",
      "category": "cs.AI"
    },
    {
      "title": "G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08253v1 Announce Type: new \nAbstract: While Large Language Models (LLMs) have recently shown promise in Automated Heuristic Design (AHD), existing approaches typically formulate AHD around constructive priority rules or parameterized local search guidance, thereby restricting the search space to fixed heuristic forms. Such designs offer limited capacity for structural exploration, making it difficult to escape deep local optima in complex Combinatorial Optimization Problems (COPs). In",
      "url": "https://arxiv.org/abs/2602.08253",
      "category": "cs.AI"
    },
    {
      "title": "SynthAgent: A Multi-Agent LLM Framework for Realistic Patient Simulation -- A Case Study in Obesity with Mental Health Comorbidities",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08254v1 Announce Type: new \nAbstract: Simulating high-fidelity patients offers a powerful avenue for studying complex diseases while addressing the challenges of fragmented, biased, and privacy-restricted real-world data. In this study, we introduce SynthAgent, a novel Multi-Agent System (MAS) framework designed to model obesity patients with comorbid mental disorders, including depression, anxiety, social phobia, and binge eating disorder. SynthAgent integrates clinical and medical e",
      "url": "https://arxiv.org/abs/2602.08254",
      "category": "cs.AI"
    },
    {
      "title": "Puda: Private User Dataset Agent for User-Sovereign and Privacy-Preserving Personalized AI",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08268v2 Announce Type: new \nAbstract: Personal data centralization among dominant platform providers including search engines, social networking services, and e-commerce has created siloed ecosystems that restrict user sovereignty, thereby impeding data use across services. Meanwhile, the rapid proliferation of Large Language Model (LLM)-based agents has intensified demand for highly personalized services that require the dynamic provision of diverse personal data. This presents a sig",
      "url": "https://arxiv.org/abs/2602.08268",
      "category": "cs.AI"
    },
    {
      "title": "Toward Formalizing LLM-Based Agent Designs through Structural Context Modeling and Semantic Dynamics Analysis",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08276v1 Announce Type: new \nAbstract: Current research on large language model (LLM) agents is fragmented: discussions of conceptual frameworks and methodological principles are frequently intertwined with low-level implementation details, causing both readers and authors to lose track amid a proliferation of superficially distinct concepts. We argue that this fragmentation largely stems from the absence of an analyzable, self-consistent formal model that enables implementation-indepe",
      "url": "https://arxiv.org/abs/2602.08276",
      "category": "cs.AI"
    },
    {
      "title": "The Vibe-Automation of Automation: A Proactive Education Framework for Computer Science in the Age of Generative AI",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08295v1 Announce Type: new \nAbstract: The emergence of generative artificial intelligence (GenAI) represents not an incremental technological advance but a qualitative epistemological shift that challenges foundational assumptions of computer science. Whereas machine learning has been described as the automation of automation, generative AI operates by navigating contextual, semantic, and stylistic coherence rather than optimizing predefined objective metrics. This paper introduces th",
      "url": "https://arxiv.org/abs/2602.08295",
      "category": "cs.AI"
    },
    {
      "title": "Moral Sycophancy in Vision Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08311v1 Announce Type: new \nAbstract: Sycophancy in Vision-Language Models (VLMs) refers to their tendency to align with user opinions, often at the expense of moral or factual accuracy. While prior studies have explored sycophantic behavior in general contexts, its impact on morally grounded visual decision-making remains insufficiently understood. To address this gap, we present the first systematic study of moral sycophancy in VLMs, analyzing ten widely-used models on the Moralise ",
      "url": "https://arxiv.org/abs/2602.08311",
      "category": "cs.AI"
    },
    {
      "title": "Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08335v1 Announce Type: new \nAbstract: Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignment challenge, as it is often unclear which specific functional agent is responsible for the success or failure of decision trajectories. Existing methods typically rely on sparse or globally broadcast",
      "url": "https://arxiv.org/abs/2602.08335",
      "category": "cs.AI"
    },
    {
      "title": "CoTZero: Annotation-Free Human-Like Vision Reasoning via Hierarchical Synthetic CoT",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08339v1 Announce Type: new \nAbstract: Recent advances in vision-language models (VLMs) have markedly improved image-text alignment, yet they still fall short of human-like visual reasoning. A key limitation is that many VLMs rely on surface correlations rather than building logically coherent structured representations, which often leads to missed higher-level semantic structure and non-causal relational understanding, hindering compositional and verifiable reasoning. To address these",
      "url": "https://arxiv.org/abs/2602.08339",
      "category": "cs.AI"
    },
    {
      "title": "Effect-Level Validation for Causal Discovery",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08340v1 Announce Type: new \nAbstract: Causal discovery is increasingly applied to large-scale telemetry data to estimate the effects of user-facing interventions, yet its reliability for decision-making in feedback-driven systems with strong self-selection remains unclear. In this paper, we propose an effect-centric, admissibility-first framework that treats discovered graphs as structural hypotheses and evaluates them by identifiability, stability, and falsification rather than by gr",
      "url": "https://arxiv.org/abs/2602.08340",
      "category": "cs.AI"
    },
    {
      "title": "OPE: Overcoming Information Saturation in Parallel Thinking via Outline-Guided Path Exploration",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08344v1 Announce Type: new \nAbstract: Parallel thinking has emerged as a new paradigm for large reasoning models (LRMs) in tackling complex problems. Recent methods leverage Reinforcement Learning (RL) to enhance parallel thinking, aiming to address the limitations in computational resources and effectiveness encountered with supervised fine-tuning. However, most existing studies primarily focus on optimizing the aggregation phase, with limited attention to the path exploration stage.",
      "url": "https://arxiv.org/abs/2602.08344",
      "category": "cs.AI"
    },
    {
      "title": "Towards Better Evolution Modeling for Temporal Knowledge Graphs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08353v1 Announce Type: new \nAbstract: Temporal knowledge graphs (TKGs) structurally preserve evolving human knowledge. Recent research has focused on designing models to learn the evolutionary nature of TKGs to predict future facts, achieving impressive results. For instance, Hits@10 scores over 0.9 on YAGO dataset. However, we find that existing benchmarks inadvertently introduce a shortcut. Near state-of-the-art performance can be simply achieved by counting co-occurrences, without ",
      "url": "https://arxiv.org/abs/2602.08353",
      "category": "cs.AI"
    },
    {
      "title": "Does Your Reasoning Model Implicitly Know When to Stop Thinking?",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08354v1 Announce Type: new \nAbstract: Recent advancements in large reasoning models (LRMs) have greatly improved their capabilities on complex reasoning tasks through Long Chains of Thought (CoTs). However, this approach often results in substantial redundancy, impairing computational efficiency and causing significant delays in real-time applications. Recent studies show that longer reasoning chains are frequently uncorrelated with correctness and can even be detrimental to accuracy.",
      "url": "https://arxiv.org/abs/2602.08354",
      "category": "cs.AI"
    },
    {
      "title": "Circuit Representations of Random Forests with Applications to XAI",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08362v1 Announce Type: new \nAbstract: We make three contributions in this paper. First, we present an approach for compiling a random forest classifier into a set of circuits, where each circuit directly encodes the instances in some class of the classifier. We show empirically that our proposed approach is significantly more efficient than existing similar approaches. Next, we utilize this approach to further obtain circuits that are tractable for computing the complete and general r",
      "url": "https://arxiv.org/abs/2602.08362",
      "category": "cs.AI"
    },
    {
      "title": "MemAdapter: Fast Alignment across Agent Memory Paradigms via Generative Subgraph Retrieval",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08369v1 Announce Type: new \nAbstract: Memory mechanism is a core component of LLM-based agents, enabling reasoning and knowledge discovery over long-horizon contexts. Existing agent memory systems are typically designed within isolated paradigms (e.g., explicit, parametric, or latent memory) with tightly coupled retrieval methods that hinder cross-paradigm generalization and fusion. In this work, we take a first step toward unifying heterogeneous memory paradigms within a single memor",
      "url": "https://arxiv.org/abs/2602.08369",
      "category": "cs.AI"
    },
    {
      "title": "Grounding Generative Planners in Verifiable Logic: A Hybrid Architecture for Trustworthy Embodied AI",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08373v1 Announce Type: new \nAbstract: Large Language Models (LLMs) show promise as planners for embodied AI, but their stochastic nature lacks formal reasoning, preventing strict safety guarantees for physical deployment. Current approaches often rely on unreliable LLMs for safety checks or simply reject unsafe plans without offering repairs. We introduce the Verifiable Iterative Refinement Framework (VIRF), a neuro-symbolic architecture that shifts the paradigm from passive safety ga",
      "url": "https://arxiv.org/abs/2602.08373",
      "category": "cs.AI"
    },
    {
      "title": "SCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domains",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08400v1 Announce Type: new \nAbstract: Graph-RAG improves LLM reasoning using structured knowledge, yet conventional designs rely on a centralized knowledge graph. In distributed and access-restricted settings (e.g., hospitals or multinational organizations), retrieval must select relevant domains and appropriate traversal depth without global graph visibility or exhaustive querying. To address this challenge, we introduce \\textbf{SCOUT-RAG} (\\textit{\\underline{S}calable and \\underline",
      "url": "https://arxiv.org/abs/2602.08400",
      "category": "cs.AI"
    },
    {
      "title": "On Protecting Agentic Systems' Intellectual Property via Watermarking",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08401v1 Announce Type: new \nAbstract: The evolution of Large Language Models (LLMs) into agentic systems that perform autonomous reasoning and tool use has created significant intellectual property (IP) value. We demonstrate that these systems are highly vulnerable to imitation attacks, where adversaries steal proprietary capabilities by training imitation models on victim outputs. Crucially, existing LLM watermarking techniques fail in this domain because real-world agentic systems o",
      "url": "https://arxiv.org/abs/2602.08401",
      "category": "cs.AI"
    },
    {
      "title": "From Assistant to Double Agent: Formalizing and Benchmarking Attacks on OpenClaw for Personalized Local AI Agent",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08412v1 Announce Type: new \nAbstract: Although large language model (LLM)-based agents, exemplified by OpenClaw, are increasingly evolving from task-oriented systems into personalized AI assistants for solving complex real-world tasks, their practical deployment also introduces severe security risks. However, existing agent security research and evaluation frameworks primarily focus on synthetic or task-centric settings, and thus fail to accurately capture the attack surface and risk ",
      "url": "https://arxiv.org/abs/2602.08412",
      "category": "cs.AI"
    },
    {
      "title": "When Evaluation Becomes a Side Channel: Regime Leakage and Structural Mitigations for Alignment Assessment",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08449v1 Announce Type: new \nAbstract: Safety evaluation for advanced AI systems implicitly assumes that behavior observed under evaluation is predictive of behavior in deployment. This assumption becomes fragile for agents with situational awareness, which may exploitregime leakage-informational cues distinguishing evaluation from deployment-to implement conditional policies such as sycophancy and sleeper agents, which preserve compliance under oversight while defecting in deployment-",
      "url": "https://arxiv.org/abs/2602.08449",
      "category": "cs.AI"
    },
    {
      "title": "TreeTensor: Boost AI System on Nested Data with Constrained Tree-Like Tensor",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08517v1 Announce Type: new \nAbstract: Tensor is the most basic and essential data structure of nowadays artificial intelligence (AI) system. The natural properties of Tensor, especially the memory-continuity and slice-independence, make it feasible for training system to leverage parallel computing unit like GPU to process data simultaneously in batch, spatial or temporal dimensions. However, if we look beyond perception tasks, the data in a complicated cognitive AI system usually has",
      "url": "https://arxiv.org/abs/2602.08517",
      "category": "cs.AI"
    },
    {
      "title": "Reinforcement Inference: Leveraging Uncertainty for Self-Correcting Language Model Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08520v1 Announce Type: new \nAbstract: Modern large language models (LLMs) are often evaluated and deployed under a \\emph{one-shot, greedy} inference protocol, especially in professional settings that require deterministic behavior. This regime can systematically under-estimate a fixed model's true capability: many errors arise not from missing knowledge, but from premature commitment under internal ambiguity. We introduce \\emph{Reinforcement Inference}, an entropy-aware inference-time",
      "url": "https://arxiv.org/abs/2602.08520",
      "category": "cs.AI"
    },
    {
      "title": "Dialogue Model Optimization via Agent Game and Adaptive Tree-based GRPO",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08533v2 Announce Type: new \nAbstract: Open-ended dialogue agents aim to deliver engaging, personalized interactions by adapting to users' traits, but existing methods face critical limitations: over-reliance on pre-collected user data, and short-horizon biases in reinforcement learning (RL) that neglect long-term dialogue value. To address these, we propose a novel long-horizon RL framework integrating online personalization with Adaptive Tree-based Group Relative Policy Optimization ",
      "url": "https://arxiv.org/abs/2602.08533",
      "category": "cs.AI"
    },
    {
      "title": "PRISM: A Principled Framework for Multi-Agent Reasoning via Gain Decomposition",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08586v2 Announce Type: new \nAbstract: Multi-agent collaboration has emerged as a promising paradigm for enhancing reasoning capabilities of Large Language Models (LLMs). However, existing approaches remain largely heuristic, lacking principled guidance on what drives performance gains and how to systematically optimize multi-agent reasoning. Specifically, it remains unclear why multi-agent collaboration outperforms single-agent reasoning and which design choices contribute most to the",
      "url": "https://arxiv.org/abs/2602.08586",
      "category": "cs.AI"
    },
    {
      "title": "An Attention Mechanism for Robust Multimodal Integration in a Global Workspace Architecture",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08597v1 Announce Type: new \nAbstract: Global Workspace Theory (GWT), inspired by cognitive neuroscience, posits that flexible cognition could arise via the attentional selection of a relevant subset of modalities within a multimodal integration system. This cognitive framework can inspire novel computational architectures for multimodal integration. Indeed, recent implementations of GWT have explored its multimodal representation capabilities, but the related attention mechanisms rema",
      "url": "https://arxiv.org/abs/2602.08597",
      "category": "cs.AI"
    },
    {
      "title": "OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08603v1 Announce Type: new \nAbstract: Composed image retrieval (CIR) requires complex reasoning over heterogeneous visual and textual constraints. Existing approaches largely fall into two paradigms: unified embedding retrieval, which suffers from single-model myopia, and heuristic agentic retrieval, which is limited by suboptimal, trial-and-error orchestration. To this end, we propose OSCAR, an optimization-steered agentic planning framework for composed image retrieval. We are the f",
      "url": "https://arxiv.org/abs/2602.08603",
      "category": "cs.AI"
    },
    {
      "title": "Debate is efficient with your time",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08630v1 Announce Type: new \nAbstract: AI safety via debate uses two competing models to help a human judge verify complex computational tasks. Previous work has established what problems debate can solve in principle, but has not analysed the practical cost of human oversight: how many queries must the judge make to the debate transcript? We introduce Debate Query Complexity}(DQC), the minimum number of bits a verifier must inspect to correctly decide a debate.\n  Surprisingly, we find",
      "url": "https://arxiv.org/abs/2602.08630",
      "category": "cs.AI"
    },
    {
      "title": "Why do we Trust Chatbots? From Normative Principles to Behavioral Drivers",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08707v1 Announce Type: new \nAbstract: As chatbots increasingly blur the boundary between automated systems and human conversation, the foundations of trust in these systems warrant closer examination. While regulatory and policy frameworks tend to define trust in normative terms, the trust users place in chatbots often emerges from behavioral mechanisms. In many cases, this trust is not earned through demonstrated trustworthiness but is instead shaped by interactional design choices t",
      "url": "https://arxiv.org/abs/2602.08707",
      "category": "cs.AI"
    },
    {
      "title": "Intermediate Results on the Complexity of STRIPS$_{1}^{1}$",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08708v1 Announce Type: new \nAbstract: This paper is based on Bylander's results on the computational complexity of propositional STRIPS planning. He showed that when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. While NP-hardness is settled, it is unknown whether propositional STRIPS with operators that only have one precondition and one effect is NP-complete. We shed light o",
      "url": "https://arxiv.org/abs/2602.08708",
      "category": "cs.AI"
    },
    {
      "title": "Exploring SAIG Methods for an Objective Evaluation of XAI",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08715v1 Announce Type: new \nAbstract: The evaluation of eXplainable Artificial Intelligence (XAI) methods is a rapidly growing field, characterized by a wide variety of approaches. This diversity highlights the complexity of the XAI evaluation, which, unlike traditional AI assessment, lacks a universally correct ground truth for the explanation, making objective evaluation challenging. One promising direction to address this issue involves the use of what we term Synthetic Artificial ",
      "url": "https://arxiv.org/abs/2602.08715",
      "category": "cs.AI"
    },
    {
      "title": "Finite-State Controllers for (Hidden-Model) POMDPs using Deep Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08734v1 Announce Type: new \nAbstract: Solving partially observable Markov decision processes (POMDPs) requires computing policies under imperfect state information. Despite recent advances, the scalability of existing POMDP solvers remains limited. Moreover, many settings require a policy that is robust across multiple POMDPs, further aggravating the scalability issue. We propose the Lexpop framework for POMDP solving. Lexpop (1) employs deep reinforcement learning to train a neural p",
      "url": "https://arxiv.org/abs/2602.08734",
      "category": "cs.AI"
    },
    {
      "title": "Belief Offloading in Human-AI Interaction",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08754v1 Announce Type: new \nAbstract: What happens when people's beliefs are derived from information provided by an LLM? People's use of LLM chatbots as thought partners can contribute to cognitive offloading, which can have adverse effects on cognitive skills in cases of over-reliance. This paper defines and investigates a particular kind of cognitive offloading in human-AI interaction, \"belief offloading,\" in which people's processes of forming and upholding beliefs are offloaded o",
      "url": "https://arxiv.org/abs/2602.08754",
      "category": "cs.AI"
    },
    {
      "title": "Dynamics Within Latent Chain-of-Thought: An Empirical Study of Causal Structure",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08783v1 Announce Type: new \nAbstract: Latent or continuous chain-of-thought methods replace explicit textual rationales with a number of internal latent steps, but these intermediate computations are difficult to evaluate beyond correlation-based probes. In this paper, we view latent chain-of-thought as a manipulable causal process in representation space by modeling latent steps as variables in a structural causal model (SCM) and analyzing their effects through step-wise $\\mathrm{do}",
      "url": "https://arxiv.org/abs/2602.08783",
      "category": "cs.AI"
    },
    {
      "title": "The Use of AI Tools to Develop and Validate Q-Matrices",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08796v1 Announce Type: new \nAbstract: Constructing a Q-matrix is a critical but labor-intensive step in cognitive diagnostic modeling (CDM). This study investigates whether AI tools (i.e., general language models) can support Q-matrix development by comparing AI-generated Q-matrices with a validated Q-matrix from Li and Suen (2013) for a reading comprehension test. In May 2025, multiple AI models were provided with the same training materials as human experts. Agreement among AI-gener",
      "url": "https://arxiv.org/abs/2602.08796",
      "category": "cs.AI"
    },
    {
      "title": "Root Cause Analysis Method Based on Large Language Models with Residual Connection Structures",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08804v1 Announce Type: new \nAbstract: Root cause localization remain challenging in complex and large-scale microservice architectures. The complex fault propagation among microservices and the high dimensionality of telemetry data, including metrics, logs, and traces, limit the effectiveness of existing root cause analysis (RCA) methods. In this paper, a residual-connection-based RCA method using large language model (LLM), named RC-LLM, is proposed. A residual-like hierarchical fusi",
      "url": "https://arxiv.org/abs/2602.08804",
      "category": "cs.AI"
    },
    {
      "title": "Negative-Aware Diffusion Process for Temporal Knowledge Graph Extrapolation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08815v1 Announce Type: new \nAbstract: Temporal Knowledge Graph (TKG) reasoning seeks to predict future missing facts from historical evidence. While diffusion models (DM) have recently gained attention for their ability to capture complex predictive distributions, two gaps remain: (i) the generative path is conditioned only on positive evidence, overlooking informative negative context, and (ii) training objectives are dominated by cross-entropy ranking, which improves candidate order",
      "url": "https://arxiv.org/abs/2602.08815",
      "category": "cs.AI"
    },
    {
      "title": "Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08835v1 Announce Type: new \nAbstract: Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different ",
      "url": "https://arxiv.org/abs/2602.08835",
      "category": "cs.AI"
    },
    {
      "title": "Deciding the Satisfiability of Combined Qualitative Constraint Networks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08848v1 Announce Type: new \nAbstract: Among the various forms of reasoning studied in the context of artificial intelligence, qualitative reasoning makes it possible to infer new knowledge in the context of imprecise, incomplete information without numerical values. In this paper, we propose a formal framework unifying several forms of extensions and combinations of qualitative formalisms, including multi-scale reasoning, temporal sequences, and loose integrations. This framework make",
      "url": "https://arxiv.org/abs/2602.08848",
      "category": "cs.AI"
    },
    {
      "title": "Scalable Delphi: Large Language Models for Structured Risk Estimation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08889v1 Announce Type: new \nAbstract: Quantitative risk assessment in high-stakes domains relies on structured expert elicitation to estimate unobservable properties. The gold standard - the Delphi method - produces calibrated, auditable judgments but requires months of coordination and specialist time, placing rigorous risk assessment out of reach for most applications. We investigate whether Large Language Models (LLMs) can serve as scalable proxies for structured expert elicitation",
      "url": "https://arxiv.org/abs/2602.08889",
      "category": "cs.AI"
    },
    {
      "title": "Efficient and Stable Reinforcement Learning for Diffusion Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08905v1 Announce Type: new \nAbstract: Reinforcement Learning (RL) is crucial for unlocking the complex reasoning capabilities of Diffusion-based Large Language Models (dLLMs). However, applying RL to dLLMs faces unique challenges in efficiency and stability. To address these challenges, we propose Spatio-Temporal Pruning (STP), a framework designed to simultaneously improve the efficiency and stability of RL for dLLMs. STP compresses the redundancy in the generative process through: (",
      "url": "https://arxiv.org/abs/2602.08905",
      "category": "cs.AI"
    },
    {
      "title": "CausalT5K: Diagnosing and Informing Refusal for Trustworthy Causal Reasoning of Skepticism, Sycophancy, Detection-Correction, and Rung Collapse",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08939v1 Announce Type: new \nAbstract: LLM failures in causal reasoning, including sycophancy, rung collapse, and miscalibrated refusal, are well-documented, yet progress on remediation is slow because no benchmark enables systematic diagnosis. We introduce CausalT5K, a diagnostic benchmark of over 5,000 cases across 10 domains that tests three critical capabilities: (1) detecting rung collapse, where models answer interventional queries with associational evidence; (2) resisting sycop",
      "url": "https://arxiv.org/abs/2602.08939",
      "category": "cs.AI"
    },
    {
      "title": "CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08948v1 Announce Type: new \nAbstract: Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consumes full-trace confidence to decide whether to halt, ",
      "url": "https://arxiv.org/abs/2602.08948",
      "category": "cs.AI"
    },
    {
      "title": "Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08949v1 Announce Type: new \nAbstract: According to the United Nations, wildfire frequency and intensity are projected to increase by approximately 14% by 2030 and 30% by 2050 due to global warming, posing critical threats to life, infrastructure, and ecosystems. Conventional disaster management frameworks rely on static simulations and passive data acquisition, hindering their ability to adapt to arbitrarily evolving wildfire episodes in real-time. To address these limitations, we int",
      "url": "https://arxiv.org/abs/2602.08949",
      "category": "cs.AI"
    },
    {
      "title": "stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08968v1 Announce Type: new \nAbstract: World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most available implementations remain publication-specific, severely limiting their reusability, increasing the risk of bugs, and reducing evaluation standardization. To mitigate these issues, we introduce stable-",
      "url": "https://arxiv.org/abs/2602.08968",
      "category": "cs.AI"
    },
    {
      "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08990v1 Announce Type: new \nAbstract: We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate co",
      "url": "https://arxiv.org/abs/2602.08990",
      "category": "cs.AI"
    },
    {
      "title": "iGRPO: Self-Feedback-Driven LLM Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.09000v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliability. Group Relative Policy Optimization (GRPO) is an efficient, value-function-free alternative to Proximal Policy Optimization (PPO) that leverages gro",
      "url": "https://arxiv.org/abs/2602.09000",
      "category": "cs.AI"
    },
    {
      "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.09003v1 Announce Type: new \nAbstract: The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency. In this work, we argu",
      "url": "https://arxiv.org/abs/2602.09003",
      "category": "cs.AI"
    },
    {
      "title": "GEBench: Benchmarking Image Generation Models as GUI Environments",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.09007v2 Announce Type: new \nAbstract: Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and tempo",
      "url": "https://arxiv.org/abs/2602.09007",
      "category": "cs.AI"
    },
    {
      "title": "BERT Learns (and Teaches) Chemistry",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2007.16012v1 Announce Type: cross \nAbstract: Modern computational organic chemistry is becoming increasingly data-driven. There remain a large number of important unsolved problems in this area such as product prediction given reactants, drug discovery, and metric-optimized molecule synthesis, but efforts to solve these problems using machine learning have also increased in recent years. In this work, we propose the use of attention to study functional groups and other property-impacting m",
      "url": "https://arxiv.org/abs/2007.16012",
      "category": "q-bio.BM"
    },
    {
      "title": "Improved cystic hygroma detection from prenatal imaging using ultrasound-specific self-supervised representation learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.22730v2 Announce Type: cross \nAbstract: Cystic hygroma is a high-risk prenatal ultrasound finding that portends high rates of chromosomal abnormalities, structural malformations, and adverse pregnancy outcomes. Automated detection can increase reproducibility and support scalable early screening programs, but supervised deep learning methods are limited by small labelled datasets. This study assesses whether ultrasound-specific self-supervised pretraining can facilitate accurate, robu",
      "url": "https://arxiv.org/abs/2512.22730",
      "category": "cs.CV"
    },
    {
      "title": "Leveraging Adaptive Group Negotiation for Heterogeneous Multi-Robot Collaboration with Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06967v1 Announce Type: cross \nAbstract: Multi-robot collaboration tasks often require heterogeneous robots to work together over long horizons under spatial constraints and environmental uncertainties. Although Large Language Models (LLMs) excel at reasoning and planning, their potential for coordinated control has not been fully explored. Inspired by human teamwork, we present CLiMRS (Cooperative Large-Language-Model-Driven Heterogeneous Multi-Robot System), an adaptive group negotia",
      "url": "https://arxiv.org/abs/2602.06967",
      "category": "cs.RO"
    },
    {
      "title": "Does Visual Rendering Bypass Tokenization? Investigating Script-Tokenizer Misalignment in Pixel-Based Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06973v1 Announce Type: cross \nAbstract: While pixel-based language modeling aims to bypass the sub-word tokenization bottleneck by rendering text as images, recent multimodal variants such as DualGPT reintroduce text tokenizers to improve autoregressive performance. We investigate a fundamental question, does visual rendering truly decouple a model from tokenization constraints? Focusing on four Indonesian low-resource local languages that have their own non-Latin scripts (i.e., Javan",
      "url": "https://arxiv.org/abs/2602.06973",
      "category": "cs.CL"
    },
    {
      "title": "BiomechAgent: AI-Assisted Biomechanical Analysis Through Code-Generating Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06975v1 Announce Type: cross \nAbstract: Markerless motion capture is making quantitative movement analysis increasingly accessible, yet analyzing the resulting data remains a barrier for clinicians without programming expertise. We present BiomechAgent, a code-generating AI agent that enables biomechanical analysis through natural language and allows users to querying databases, generating visualizations, and even interpret data without requiring users to write code. To evaluate Biome",
      "url": "https://arxiv.org/abs/2602.06975",
      "category": "cs.CL"
    },
    {
      "title": "Bridging the Knowledge Void: Inference-time Acquisition of Unfamiliar Programming Languages for Coding Tasks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06976v1 Announce Type: cross \nAbstract: The proficiency of Large Language Models (LLMs) in coding tasks is often a reflection of their extensive pre-training corpora, which typically collapses when confronted with previously unfamiliar programming languages. Departing from data-intensive finetuning, we investigate the paradigm of Inference-time Language Acquisition (ILA), where an LLM masters an unfamiliar language through dynamic interaction with limited external resources. In this p",
      "url": "https://arxiv.org/abs/2602.06976",
      "category": "cs.CL"
    },
    {
      "title": "What is Safety? Corporate Discourse, Power, and the Politics of Generative AI Safety",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06981v1 Announce Type: cross \nAbstract: This work examines how leading generative artificial intelligence companies construct and communicate the concept of \"safety\" through public-facing documents. Drawing on critical discourse analysis, we analyze a corpus of corporate safety-related statements to explicate how authority, responsibility, and legitimacy are discursively established. These discursive strategies consolidate legitimacy for corporate actors, normalize safety as an experi",
      "url": "https://arxiv.org/abs/2602.06981",
      "category": "cs.CY"
    },
    {
      "title": "Deep Reinforcement Learning for Interference Suppression in RIS-Aided Space-Air-Ground Integrated Networks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06982v1 Announce Type: cross \nAbstract: Future 6G networks envision ubiquitous connectivity through space-air-ground integrated networks (SAGINs), where high-altitude platform stations (HAPSs) and satellites complement terrestrial systems to provide wide-area, low-latency coverage. However, the rapid growth of terrestrial devices intensifies spectrum sharing between terrestrial and non-terrestrial segments, resulting in severe cross-tier interference. In particular, frequency sharing ",
      "url": "https://arxiv.org/abs/2602.06982",
      "category": "eess.SP"
    },
    {
      "title": "Hybrid Deep Learning Framework for CSI-Based Activity Recognition in Bandwidth-Constrained Wi-Fi Sensing",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06983v1 Announce Type: cross \nAbstract: This paper presents a novel hybrid deep learning framework designed to enhance the robustness of CSI-based Human Activity Recognition (HAR) within bandwidth-constrained Wi-Fi sensing environments. The core of our proposed methodology is a preliminary Doppler trace extraction stage, implemented to amplify salient motion-related signal features before classification. Subsequently, these enhanced inputs are processed by a hybrid neural architecture",
      "url": "https://arxiv.org/abs/2602.06983",
      "category": "eess.SP"
    },
    {
      "title": "Empowering Affected Individuals to Shape AI Fairness Assessments: Processes, Criteria, and Tools",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06984v1 Announce Type: cross \nAbstract: AI systems are increasingly used in high-stakes domains such as credit rating, where fairness concerns are critical. Existing fairness assessments are typically conducted by AI experts or regulators using predefined protected attributes and metrics, which often fail to capture the diversity and nuance of fairness notions held by the individuals who are affected by these systems' decisions, such as decision subjects. Recent work has therefore cal",
      "url": "https://arxiv.org/abs/2602.06984",
      "category": "cs.CY"
    },
    {
      "title": "A New Mode of Teaching Chinese as a Foreign Language from the Perspective of Smart System Studied by Using Rongzhixue",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06992v1 Announce Type: cross \nAbstract: The purpose of this study is to introduce a new model of teaching Chinese as a foreign language from the perspective of integrating wisdom. Its characteristics are as follows: focusing on the butterfly model of interpretation before translation, highlighting the new method of bilingual thinking training, on the one hand, applying the new theory of Chinese characters, the theory of the relationship between language and speech, and the forward-loo",
      "url": "https://arxiv.org/abs/2602.06992",
      "category": "cs.CY"
    },
    {
      "title": "SurfAge-Net: A Hierarchical Surface-Based Network for Interpretable Fine-Grained Brain Age Prediction",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06994v1 Announce Type: cross \nAbstract: Brain age prediction serves as a powerful framework for assessing brain status and detecting deviations associated with neurodevelopmental and neurodegenerative disorders. However, most existing approaches emphasize whole-brain age prediction and therefore overlook the pronounced regional heterogeneity of brain maturation that is crucial for detecting localized atypical trajectories. To address this limitation, we propose a novel spherical surfa",
      "url": "https://arxiv.org/abs/2602.06994",
      "category": "q-bio.NC"
    },
    {
      "title": "Adaptive Temporal Dynamics for Personalized Emotion Recognition: A Liquid Neural Network Approach",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06997v1 Announce Type: cross \nAbstract: Emotion recognition from physiological signals remains challenging due to their non-stationary, noisy, and subject-dependent characteristics. This work presents, to the best of our knowledge, the first comprehensive application of liquid neural networks for EEG-based emotion recognition. The proposed multimodal framework combines convolutional feature extraction, liquid neural networks with learnable time constants, and attention-guided fusion t",
      "url": "https://arxiv.org/abs/2602.06997",
      "category": "eess.SP"
    },
    {
      "title": "Hierarchical JEPA Meets Predictive Remote Control in Beyond 5G Networks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07000v1 Announce Type: cross \nAbstract: In wireless networked control systems, ensuring timely and reliable state updates from distributed devices to remote controllers is essential for robust control performance. However, when multiple devices transmit high-dimensional states (e.g., images or video frames) over bandwidth-limited wireless networks, a critical trade-off emerges between communication efficiency and control performance. To address this challenge, we propose a Hierarchica",
      "url": "https://arxiv.org/abs/2602.07000",
      "category": "eess.SY"
    },
    {
      "title": "Multi-Scale Temporal Homeostasis Enables Efficient and Robust Neural Networks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07009v1 Announce Type: cross \nAbstract: Artificial neural networks achieve strong performance on benchmark tasks but remain fundamentally brittle under perturbations, limiting their deployment in real-world settings. In contrast, biological nervous systems sustain reliable function across decades through homeostatic regulation coordinated across multiple temporal scales. Inspired by this principle, this presents Multi-Scale Temporal Homeostasis (MSTH), a biologically grounded framewor",
      "url": "https://arxiv.org/abs/2602.07009",
      "category": "cs.NE"
    },
    {
      "title": "Learning Alzheimer's Disease Signatures by bridging EEG with Spiking Neural Networks and Biophysical Simulations",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07010v1 Announce Type: cross \nAbstract: As the prevalence of Alzheimer's disease (AD) rises, improving mechanistic insight from non-invasive biomarkers is increasingly critical. Recent work suggests that circuit-level brain alterations manifest as changes in electroencephalography (EEG) spectral features detectable by machine learning. However, conventional deep learning approaches for EEG-based AD detection are computationally intensive and mechanistically opaque. Spiking neural netw",
      "url": "https://arxiv.org/abs/2602.07010",
      "category": "cs.NE"
    },
    {
      "title": "MAU-GPT: Enhancing Multi-type Industrial Anomaly Understanding via Anomaly-aware and Generalist Experts Adaptation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07011v1 Announce Type: cross \nAbstract: As industrial manufacturing scales, automating fine-grained product image analysis has become critical for quality control. However, existing approaches are hindered by limited dataset coverage and poor model generalization across diverse and complex anomaly patterns. To address these challenges, we introduce MAU-Set, a comprehensive dataset for Multi-type industrial Anomaly Understanding. It spans multiple industrial domains and features a hier",
      "url": "https://arxiv.org/abs/2602.07011",
      "category": "cs.CV"
    },
    {
      "title": "A General Model for Retinal Segmentation and Quantification",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07012v1 Announce Type: cross \nAbstract: Retinal imaging is fast, non-invasive, and widely available, offering quantifiable structural and vascular signals for ophthalmic and systemic health assessment. This accessibility creates an opportunity to study how quantitative retinal phenotypes relate to ocular and systemic diseases. However, such analyses remain difficult at scale due to the limited availability of public multi-label datasets and the lack of a unified segmentation-to-quanti",
      "url": "https://arxiv.org/abs/2602.07012",
      "category": "cs.CV"
    },
    {
      "title": "Steering to Say No: Configurable Refusal via Activation Steering in Vision Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07013v1 Announce Type: cross \nAbstract: With the rapid advancement of Vision Language Models (VLMs), refusal mechanisms have become a critical component for ensuring responsible and safe model behavior. However, existing refusal strategies are largely \\textit{one-size-fits-all} and fail to adapt to diverse user needs and contextual constraints, leading to either under-refusal or over-refusal. In this work, we firstly explore the challenges mentioned above and develop \\textbf{C}onfigur",
      "url": "https://arxiv.org/abs/2602.07013",
      "category": "cs.CV"
    },
    {
      "title": "Vectra: A New Metric, Dataset, and Model for Visual Quality Assessment in E-Commerce In-Image Machine Translation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07014v1 Announce Type: cross \nAbstract: In-Image Machine Translation (IIMT) powers cross-border e-commerce product listings; existing research focuses on machine translation evaluation, while visual rendering quality is critical for user engagement. When facing context-dense product imagery and multimodal defects, current reference-based methods (e.g., SSIM, FID) lack explainability, while model-as-judge approaches lack domain-grounded, fine-grained reward signals. To bridge this gap,",
      "url": "https://arxiv.org/abs/2602.07014",
      "category": "cs.CV"
    },
    {
      "title": "XAI-CLIP: ROI-Guided Perturbation Framework for Explainable Medical Image Segmentation in Multimodal Vision-Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07017v1 Announce Type: cross \nAbstract: Medical image segmentation is a critical component of clinical workflows, enabling accurate diagnosis, treatment planning, and disease monitoring. However, despite the superior performance of transformer-based models over convolutional architectures, their limited interpretability remains a major obstacle to clinical trust and deployment. Existing explainable artificial intelligence (XAI) techniques, including gradient-based saliency methods and",
      "url": "https://arxiv.org/abs/2602.07017",
      "category": "cs.CV"
    },
    {
      "title": "AI for Sustainable Data Protection and Fair Algorithmic Management in Environmental Regulation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07021v1 Announce Type: cross \nAbstract: Integration of AI into environmental regulation represents a significant advancement in data management. It offers promising results in both data protection plus algorithmic fairness. This research addresses the critical need for sustainable data protection in the era of ever evolving cyber threats. Traditional encryption methods face limitations in handling the dynamic nature of environmental data. This necessitates the exploration of advanced ",
      "url": "https://arxiv.org/abs/2602.07021",
      "category": "cs.CY"
    },
    {
      "title": "Behavioral Consistency Validation for LLM Agents: An Analysis of Trading-Style Switching through Stock-Market Simulation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07023v1 Announce Type: cross \nAbstract: Recent works have increasingly applied Large Language Models (LLMs) as agents in financial stock market simulations to test if micro-level behaviors aggregate into macro-level phenomena. However, a crucial question arises: Do LLM agents' behaviors align with real market participants? This alignment is key to the validity of simulation results. To explore this, we select a financial stock market scenario to test behavioral consistency. Investors ",
      "url": "https://arxiv.org/abs/2602.07023",
      "category": "q-fin.TR"
    },
    {
      "title": "The Geometry of Representational Failures in Vision Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07025v1 Announce Type: cross \nAbstract: Vision-Language Models (VLMs) exhibit puzzling failures in multi-object visual tasks, such as hallucinating non-existent elements or failing to identify the most similar objects among distractions. While these errors mirror human cognitive constraints, such as the \"Binding Problem\", the internal mechanisms driving them in artificial systems remain poorly understood. Here, we propose a mechanistic insight by analyzing the representational geometr",
      "url": "https://arxiv.org/abs/2602.07025",
      "category": "cs.CV"
    },
    {
      "title": "Modality Gap-Driven Subspace Alignment Training Paradigm For Multimodal Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07026v1 Announce Type: cross \nAbstract: Despite the success of multimodal contrastive learning in aligning visual and linguistic representations, a persistent geometric anomaly, the Modality Gap, remains: embeddings of distinct modalities expressing identical semantics occupy systematically offset regions. Prior approaches to bridge this gap are largely limited by oversimplified isotropic assumptions, hindering their application in large-scale scenarios. In this paper, we address thes",
      "url": "https://arxiv.org/abs/2602.07026",
      "category": "cs.CV"
    },
    {
      "title": "A Comparative Study of Adversarial Robustness in CNN and CNN-ANFIS Architectures",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07028v1 Announce Type: cross \nAbstract: Convolutional Neural Networks (CNNs) achieve strong image classification performance but lack interpretability and are vulnerable to adversarial attacks. Neuro-fuzzy hybrids such as DCNFIS replace fully connected CNN classifiers with Adaptive Neuro-Fuzzy Inference Systems (ANFIS) to improve interpretability, yet their robustness remains underexplored. This work compares standard CNNs (ConvNet, VGG, ResNet18) with their ANFIS-augmented counterpar",
      "url": "https://arxiv.org/abs/2602.07028",
      "category": "cs.CV"
    },
    {
      "title": "Lagged backward-compatible physics-informed neural networks for unsaturated soil consolidation analysis",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07031v1 Announce Type: cross \nAbstract: This study develops a Lagged Backward-Compatible Physics-Informed Neural Network (LBC-PINN) for simulating and inverting one-dimensional unsaturated soil consolidation under long-term loading. To address the challenges of coupled air and water pressure dissipation across multi-scale time domains, the framework integrates logarithmic time segmentation, lagged compatibility loss enforcement, and segment-wise transfer learning.\n  In forward analysi",
      "url": "https://arxiv.org/abs/2602.07031",
      "category": "cs.LG"
    },
    {
      "title": "MENASpeechBank: A Reference Voice Bank with Persona-Conditioned Multi-Turn Conversations for AudioLLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07036v1 Announce Type: cross \nAbstract: Audio large language models (AudioLLMs) enable instruction-following over speech and general audio, but progress is increasingly limited by the lack of diverse, conversational, instruction-aligned speech-text data. This bottleneck is especially acute for persona-grounded interactions and dialectal coverage, where collecting and releasing real multi-speaker recordings is costly and slow. We introduce MENASpeechBank, a reference speech bank compri",
      "url": "https://arxiv.org/abs/2602.07036",
      "category": "cs.SD"
    },
    {
      "title": "Stochastic Spiking Neuron Based SNN Can be Inherently Bayesian",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07037v1 Announce Type: cross \nAbstract: Uncertainty in biological neural systems appears to be computationally beneficial rather than detrimental. However, in neuromorphic computing systems, device variability often limits performance, including accuracy and efficiency. In this work, we propose a spiking Bayesian neural network (SBNN) framework that unifies the dynamic models of intrinsic device stochasticity (based on Magnetic Tunnel Junctions) and stochastic threshold neurons to lev",
      "url": "https://arxiv.org/abs/2602.07037",
      "category": "cs.NE"
    },
    {
      "title": "When Excellence Stops Producing Knowledge: A Practitioner's Observation on Research Funding",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07039v1 Announce Type: cross \nAbstract: After almost four decades of participating in competitive research funding -- as applicant, coordinator, evaluator, and panel member -- I have come to see a structural paradox: many participants recognize that the current system is approaching its functional limits, yet most reform measures intensify rather than alleviate the underlying dynamics. This paper documents how excellence has become decoupled from knowledge production through an increa",
      "url": "https://arxiv.org/abs/2602.07039",
      "category": "cs.CY"
    },
    {
      "title": "PipeMFL-240K: A Large-scale Dataset and Benchmark for Object Detection in Pipeline Magnetic Flux Leakage Imaging",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07044v1 Announce Type: cross \nAbstract: Pipeline integrity is critical to industrial safety and environmental protection, with Magnetic Flux Leakage (MFL) detection being a primary non-destructive testing technology. Despite the promise of deep learning for automating MFL interpretation, progress toward reliable models has been constrained by the absence of a large-scale public dataset and benchmark, making fair comparison and reproducible evaluation difficult. We introduce \\textbf{Pi",
      "url": "https://arxiv.org/abs/2602.07044",
      "category": "cs.CV"
    },
    {
      "title": "VLRS-Bench: A Vision-Language Reasoning Benchmark for Remote Sensing",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07045v1 Announce Type: cross \nAbstract: Recent advancements in Multimodal Large Language Models (MLLMs) have enabled complex reasoning. However, existing remote sensing (RS) benchmarks remain heavily biased toward perception tasks, such as object recognition and scene classification. This limitation hinders the development of MLLMs for cognitively demanding RS applications. To address this, , we propose a Vision Language ReaSoning Benchmark (VLRS-Bench), which is the first benchmark e",
      "url": "https://arxiv.org/abs/2602.07045",
      "category": "cs.CV"
    },
    {
      "title": "Interpreting Physics in Video World Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07050v1 Announce Type: cross \nAbstract: A long-standing question in physical reasoning is whether video-based models need to rely on factorized representations of physical variables in order to make physically accurate predictions, or whether they can implicitly represent such variables in a task-specific, distributed manner. While modern video world models achieve strong performance on intuitive physics benchmarks, it remains unclear which of these representational regimes they imple",
      "url": "https://arxiv.org/abs/2602.07050",
      "category": "cs.CV"
    },
    {
      "title": "Neural Sentinel: Unified Vision Language Model (VLM) for License Plate Recognition with Human-in-the-Loop Continual Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07051v1 Announce Type: cross \nAbstract: Traditional Automatic License Plate Recognition (ALPR) systems employ multi-stage pipelines consisting of object detection networks followed by separate Optical Character Recognition (OCR) modules, introducing compounding errors, increased latency, and architectural complexity. This research presents Neural Sentinel, a novel unified approach that leverages Vision Language Models (VLMs) to perform license plate recognition, state classification, ",
      "url": "https://arxiv.org/abs/2602.07051",
      "category": "cs.CV"
    },
    {
      "title": "MTS-CSNet: Multiscale Tensor Factorization for Deep Compressive Sensing on RGB Images",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07056v1 Announce Type: cross \nAbstract: Deep learning based compressive sensing (CS) methods typically learn sampling operators using convolutional or block wise fully connected layers, which limit receptive fields and scale poorly for high dimensional data. We propose MTSCSNet, a CS framework based on Multiscale Tensor Summation (MTS) factorization, a structured operator for efficient multidimensional signal processing. MTS performs mode-wise linear transformations with multiscale su",
      "url": "https://arxiv.org/abs/2602.07056",
      "category": "eess.IV"
    },
    {
      "title": "FADE: Selective Forgetting via Sparse LoRA and Self-Distillation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07058v1 Announce Type: cross \nAbstract: Machine Unlearning aims to remove the influence of specific data or concepts from trained models while preserving overall performance, a capability increasingly required by data protection regulations and responsible AI practices. Despite recent progress, unlearning in text-to-image diffusion models remains challenging due to high computational costs and the difficulty of balancing effective forgetting with retention of unrelated concepts. We in",
      "url": "https://arxiv.org/abs/2602.07058",
      "category": "cs.CV"
    },
    {
      "title": "Assessing Reproducibility in Evolutionary Computation: A Case Study using Human- and LLM-based Assessment",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07059v1 Announce Type: cross \nAbstract: Reproducibility is an important requirement in evolutionary computation, where results largely depend on computational experiments. In practice, reproducibility relies on how algorithms, experimental protocols, and artifacts are documented and shared. Despite growing awareness, there is still limited empirical evidence on the actual reproducibility levels of published work in the field. In this paper, we study the reproducibility practices in pa",
      "url": "https://arxiv.org/abs/2602.07059",
      "category": "cs.NE"
    },
    {
      "title": "TACIT: Transformation-Aware Capturing of Implicit Thought",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07061v1 Announce Type: cross \nAbstract: We present TACIT (Transformation-Aware Capturing of Implicit Thought), a diffusion-based transformer for interpretable visual reasoning. Unlike language-based reasoning systems, TACIT operates entirely in pixel space using rectified flow, enabling direct visualization of the reasoning process at each inference step. We demonstrate the approach on maze-solving, where the model learns to transform images of unsolved mazes into solutions. Key resul",
      "url": "https://arxiv.org/abs/2602.07061",
      "category": "cs.LG"
    },
    {
      "title": "Video-based Music Generation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07063v1 Announce Type: cross \nAbstract: As the volume of video content on the internet grows rapidly, finding a suitable soundtrack remains a significant challenge. This thesis presents EMSYNC (EMotion and SYNChronization), a fast, free, and automatic solution that generates music tailored to the input video, enabling content creators to enhance their productions without composing or licensing music. Our model creates music that is emotionally and rhythmically synchronized with the vi",
      "url": "https://arxiv.org/abs/2602.07063",
      "category": "cs.LG"
    },
    {
      "title": "MRI Cross-Modal Synthesis: A Comparative Study of Generative Models for T1-to-T2 Reconstruction",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07068v1 Announce Type: cross \nAbstract: MRI cross-modal synthesis involves generating images from one acquisition protocol using another, offering considerable clinical value by reducing scan time while maintaining diagnostic information. This paper presents a comprehensive comparison of three state-of-the-art generative models for T1-to-T2 MRI reconstruction: Pix2Pix GAN, CycleGAN, and Variational Autoencoder (VAE). Using the BraTS 2020 dataset (11,439 training and 2,000 testing slic",
      "url": "https://arxiv.org/abs/2602.07068",
      "category": "eess.IV"
    },
    {
      "title": "Bidirectional Reward-Guided Diffusion for Real-World Image Super-Resolution",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07069v1 Announce Type: cross \nAbstract: Diffusion-based super-resolution can synthesize rich details, but models trained on synthetic paired data often fail on real-world LR images due to distribution shifts. We propose Bird-SR, a bidirectional reward-guided diffusion framework that formulates super-resolution as trajectory-level preference optimization via reward feedback learning (ReFL), jointly leveraging synthetic LR-HR pairs and real-world LR images. For structural fidelity easil",
      "url": "https://arxiv.org/abs/2602.07069",
      "category": "cs.CV"
    },
    {
      "title": "Artificial Intelligence in Open Source Software Engineering: A Foundation for Sustainability",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07071v1 Announce Type: cross \nAbstract: Open-source software (OSS) is foundational to modern digital infrastructure, yet this context for group work continues to struggle to ensure sufficient contributions in many critical cases. This literature review explores how artificial intelligence (AI) is being leveraged to address critical challenges to OSS sustainability, including maintaining contributor engagement, securing funding, ensuring code quality and security, fostering healthy com",
      "url": "https://arxiv.org/abs/2602.07071",
      "category": "cs.SE"
    },
    {
      "title": "Pro-ZD: A Transferable Graph Neural Network Approach for Proactive Zero-Day Threats Mitigation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07073v1 Announce Type: cross \nAbstract: In today's enterprise network landscape, the combination of perimeter and distributed firewall rules governs connectivity. To address challenges arising from increased traffic and diverse network architectures, organizations employ automated tools for firewall rule and access policy generation. Yet, effectively managing risks arising from dynamically generated policies, especially concerning critical asset exposure, remains a major challenge. Th",
      "url": "https://arxiv.org/abs/2602.07073",
      "category": "cs.CR"
    },
    {
      "title": "LatentChem: From Textual CoT to Latent Thinking in Chemical Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07075v1 Announce Type: cross \nAbstract: Chemical large language models (LLMs) predominantly rely on explicit Chain-of-Thought (CoT) in natural language to perform complex reasoning. However, chemical reasoning is inherently continuous and structural, and forcing it into discrete linguistic tokens introduces a fundamental representation mismatch that constrains both efficiency and performance. We introduce LatentChem, a latent reasoning interface that decouples chemical computation fro",
      "url": "https://arxiv.org/abs/2602.07075",
      "category": "physics.chem-ph"
    },
    {
      "title": "CALM: Class-Conditional Sparse Attention Vectors for Large Audio-Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07077v1 Announce Type: cross \nAbstract: Large audio-language models (LALMs) exhibit strong zero-shot capabilities in multiple downstream tasks, such as audio question answering (AQA) and abstract reasoning; however, these models still lag behind specialized models for certain discriminative tasks (e.g., audio classification). Recent studies show that sparse subsets of attention heads within an LALM can serve as strong discriminative feature extractors for downstream tasks such as clas",
      "url": "https://arxiv.org/abs/2602.07077",
      "category": "cs.SD"
    },
    {
      "title": "The Optimal Token Baseline: Variance Reduction for Long-Horizon LLM-RL",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07078v1 Announce Type: cross \nAbstract: Reinforcement Learning (RL) for Large Language Models (LLMs) often suffers from training collapse in long-horizon tasks due to exploding gradient variance. To mitigate this, a baseline is commonly introduced for advantage computation; however, traditional value models remain difficult to optimize, and standard group-based baselines overlook sequence heterogeneity. Although classic optimal baseline theory can achieve global variance reduction, it",
      "url": "https://arxiv.org/abs/2602.07078",
      "category": "cs.LG"
    },
    {
      "title": "CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07080v1 Announce Type: cross \nAbstract: Current paradigms for code verification rely heavily on external mechanisms-such as execution-based unit tests or auxiliary LLM judges-which are often labor-intensive or limited by the judging model's own capabilities. This raises a fundamental, yet unexplored question: Can an LLM's functional correctness be assessed purely from its internal computational structure? Our primary objective is to investigate whether the model's neural dynamics enco",
      "url": "https://arxiv.org/abs/2602.07080",
      "category": "cs.SE"
    },
    {
      "title": "Federated Prompt-Tuning with Heterogeneous and Incomplete Multimodal Client Data",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07081v1 Announce Type: cross \nAbstract: This paper introduces a generalized federated prompt-tuning framework for practical scenarios where local datasets are multi-modal and exhibit different distributional patterns of missing features at the input level. The proposed framework bridges the gap between federated learning and multi-modal prompt-tuning which have traditionally focused on either uni-modal or centralized data. A key challenge in this setting arises from the lack of semant",
      "url": "https://arxiv.org/abs/2602.07081",
      "category": "cs.MM"
    },
    {
      "title": "MosaicThinker: On-Device Visual Spatial Reasoning for Embodied AI via Iterative Construction of Space Representation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07082v1 Announce Type: cross \nAbstract: When embodied AI is expanding from traditional object detection and recognition to more advanced tasks of robot manipulation and actuation planning, visual spatial reasoning from the video inputs is necessary to perceive the spatial relationships of objects and guide device actions. However, existing visual language models (VLMs) have very weak capabilities in spatial reasoning due to the lack of knowledge about 3D spatial information, especiall",
      "url": "https://arxiv.org/abs/2602.07082",
      "category": "cs.CV"
    },
    {
      "title": "Rethinking Scientific Modeling: Toward Physically Consistent and Simulation-Executable Programmatic Generation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07083v1 Announce Type: cross \nAbstract: Structural modeling is a fundamental component of computational engineering science, in which even minor physical inconsistencies or specification violations may invalidate downstream simulations. The potential of large language models (LLMs) for automatic generation of modeling code has been demonstrated. However, non-executable or physically inconsistent outputs remain prevalent under stringent engineering constraints. A framework for physics-",
      "url": "https://arxiv.org/abs/2602.07083",
      "category": "cs.SE"
    },
    {
      "title": "AbFlow : End-to-end Paratope-Centric Antibody Design by Interaction Enhanced Flow Matching",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07084v1 Announce Type: cross \nAbstract: Antigen-antibody binding is a critical process in the immune response. Although recent progress has advanced antibody design, current methods lack a generative framework for end-to-end modeling of full-atom antibody structures and struggle to fully exploit antigen-specific geometric information for optimizing local binding interfaces and global structures. To overcome these limitations, we introduce AbFlow, a flow-matching framework that leverag",
      "url": "https://arxiv.org/abs/2602.07084",
      "category": "q-bio.QM"
    },
    {
      "title": "QuantaAlpha: An Evolutionary Framework for LLM-Driven Alpha Mining",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07085v1 Announce Type: cross \nAbstract: Financial markets are noisy and non-stationary, making alpha mining highly sensitive to noise in backtesting results and sudden market regime shifts. While recent agentic frameworks improve alpha mining automation, they often lack controllable multi-round search and reliable reuse of validated experience. To address these challenges, we propose QuantaAlpha, an evolutionary alpha mining framework that treats each end-to-end mining run as a trajec",
      "url": "https://arxiv.org/abs/2602.07085",
      "category": "q-fin.ST"
    },
    {
      "title": "Evaluating Retrieval-Augmented Generation Variants for Natural Language-Based SQL and API Call Generation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07086v1 Announce Type: cross \nAbstract: Enterprise systems increasingly require natural language interfaces that can translate user requests into structured operations such as SQL queries and REST API calls. While large language models (LLMs) show promise for code generation [Chen et al., 2021; Huynh and Lin, 2025], their effectiveness in domain-specific enterprise contexts remains underexplored, particularly when both retrieval and modification tasks must be handled jointly. This pap",
      "url": "https://arxiv.org/abs/2602.07086",
      "category": "cs.SE"
    },
    {
      "title": "Electron-Informed Coarse-Graining Molecular Representation Learning for Real-World Molecular Physics",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07087v1 Announce Type: cross \nAbstract: Various representation learning methods for molecular structures have been devised to accelerate data-driven chemistry. However, the representation capabilities of existing methods are essentially limited to atom-level information, which is not sufficient to describe real-world molecular physics. Although electron-level information can provide fundamental knowledge about chemical compounds beyond the atom-level information, obtaining the electro",
      "url": "https://arxiv.org/abs/2602.07087",
      "category": "physics.chem-ph"
    },
    {
      "title": "Concept-Aware Privacy Mechanisms for Defending Embedding Inversion Attacks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07090v1 Announce Type: cross \nAbstract: Text embeddings enable numerous NLP applications but face severe privacy risks from embedding inversion attacks, which can expose sensitive attributes or reconstruct raw text. Existing differential privacy defenses assume uniform sensitivity across embedding dimensions, leading to excessive noise and degraded utility. We propose SPARSE, a user-centric framework for concept-specific privacy protection in text embeddings. SPARSE combines (1) diffe",
      "url": "https://arxiv.org/abs/2602.07090",
      "category": "cs.CR"
    },
    {
      "title": "Lemon Agent Technical Report",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07092v1 Announce Type: cross \nAbstract: Recent advanced LLM-powered agent systems have exhibited their remarkable capabilities in tackling complex, long-horizon tasks. Nevertheless, they still suffer from inherent limitations in resource efficiency, context management, and multimodal perception. Based on these observations, Lemon Agent is introduced, a multi-agent orchestrator-worker system built on a newly proposed AgentCortex framework, which formalizes the classic Planner-Executor-",
      "url": "https://arxiv.org/abs/2602.07092",
      "category": "cs.MA"
    },
    {
      "title": "WorldEdit: Towards Open-World Image Editing with a Knowledge-Informed Benchmark",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07095v1 Announce Type: cross \nAbstract: Recent advances in image editing models have demonstrated remarkable capabilities in executing explicit instructions, such as attribute manipulation, style transfer, and pose synthesis. However, these models often face challenges when dealing with implicit editing instructions, which describe the cause of a visual change without explicitly detailing the resulting outcome. These limitations arise because existing models rely on uniform editing st",
      "url": "https://arxiv.org/abs/2602.07095",
      "category": "cs.CV"
    },
    {
      "title": "RealFin: How Well Do LLMs Reason About Finance When Users Leave Things Unsaid?",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07096v1 Announce Type: cross \nAbstract: Reliable financial reasoning requires knowing not only how to answer, but also when an answer cannot be justified. In real financial practice, problems often rely on implicit assumptions that are taken for granted rather than stated explicitly, causing problems to appear solvable while lacking enough information for a definite answer. We introduce REALFIN, a bilingual benchmark that evaluates financial reasoning by systematically removing essent",
      "url": "https://arxiv.org/abs/2602.07096",
      "category": "q-fin.ST"
    },
    {
      "title": "Fast and Robust Likelihood-Guided Diffusion Posterior Sampling with Amortized Variational Inference",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07102v1 Announce Type: cross \nAbstract: Zero-shot diffusion posterior sampling offers a flexible framework for inverse problems by accommodating arbitrary degradation operators at test time, but incurs high computational cost due to repeated likelihood-guided updates. In contrast, previous amortized diffusion approaches enable fast inference by replacing likelihood-based sampling with implicit inference models, but at the expense of robustness to unseen degradations. We introduce an a",
      "url": "https://arxiv.org/abs/2602.07102",
      "category": "stat.ML"
    },
    {
      "title": "scDFM: Distributional Flow Matching Model for Robust Single-Cell Perturbation Prediction",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07103v1 Announce Type: cross \nAbstract: A central goal in systems biology and drug discovery is to predict the transcriptional response of cells to perturbations. This task is challenging due to the noisy and sparse nature of single-cell measurements, as well as the fact that perturbations often induce population-level shifts rather than changes in individual cells. Existing deep learning methods typically assume cell-level correspondences, limiting their ability to capture such globa",
      "url": "https://arxiv.org/abs/2602.07103",
      "category": "q-bio.QM"
    },
    {
      "title": "Extended to Reality: Prompt Injection in 3D Environments",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07104v1 Announce Type: cross \nAbstract: Multimodal large language models (MLLMs) have advanced the capabilities to interpret and act on visual input in 3D environments, empowering diverse applications such as robotics and situated conversational agents. When MLLMs reason over camera-captured views of the physical world, a new attack surface emerges: an attacker can place text-bearing physical objects in the environment to override MLLMs' intended task. While prior work has studied pro",
      "url": "https://arxiv.org/abs/2602.07104",
      "category": "cs.CV"
    },
    {
      "title": "Ex-Omni: Enabling 3D Facial Animation Generation for Omni-modal Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07106v1 Announce Type: cross \nAbstract: Omni-modal large language models (OLLMs) aim to unify multimodal understanding and generation, yet incorporating speech with 3D facial animation remains largely unexplored despite its importance for natural interaction. A key challenge arises from the representation mismatch between discrete, token-level semantic reasoning in LLMs and the dense, fine-grained temporal dynamics required for 3D facial motion, which makes direct modeling difficult t",
      "url": "https://arxiv.org/abs/2602.07106",
      "category": "cs.CV"
    },
    {
      "title": "ShallowJail: Steering Jailbreaks against Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07107v1 Announce Type: cross \nAbstract: Large Language Models(LLMs) have been successful in numerous fields. Alignment has usually been applied to prevent them from harmful purposes. However, aligned LLMs remain vulnerable to jailbreak attacks that deliberately mislead them into producing harmful outputs. Existing jailbreaks are either black-box, using carefully crafted, unstealthy prompts, or white-box, requiring resource-intensive computation. In light of these challenges, we introd",
      "url": "https://arxiv.org/abs/2602.07107",
      "category": "cs.CR"
    },
    {
      "title": "Reasoning-Augmented Representations for Multimodal Retrieval",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07125v1 Announce Type: cross \nAbstract: Universal Multimodal Retrieval (UMR) seeks any-to-any search across text and vision, yet modern embedding models remain brittle when queries require latent reasoning (e.g., resolving underspecified references or matching compositional constraints). We argue this brittleness is often data-induced: when images carry \"silent\" evidence and queries leave key semantics implicit, a single embedding pass must both reason and compress, encouraging spurio",
      "url": "https://arxiv.org/abs/2602.07125",
      "category": "cs.IR"
    },
    {
      "title": "Landscaper: Understanding Loss Landscapes Through Multi-Dimensional Topological Analysis",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07135v1 Announce Type: cross \nAbstract: Loss landscapes are a powerful tool for understanding neural network optimization and generalization, yet traditional low-dimensional analyses often miss complex topological features. We present Landscaper, an open-source Python package for arbitrary-dimensional loss landscape analysis. Landscaper combines Hessian-based subspace construction with topological data analysis to reveal geometric structures such as basin hierarchy and connectivity. A",
      "url": "https://arxiv.org/abs/2602.07135",
      "category": "cs.LG"
    },
    {
      "title": "Exploring Teachers' Perspectives on Using Conversational AI Agents for Group Collaboration",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07142v1 Announce Type: cross \nAbstract: Collaboration is a cornerstone of 21st-century learning, yet teachers continue to face challenges in supporting productive peer interaction. Emerging generative AI tools offer new possibilities for scaffolding collaboration, but their role in mediating in-person group work remains underexplored, especially from the perspective of educators. This paper presents findings from an exploratory qualitative study with 33 K12 teachers who interacted wit",
      "url": "https://arxiv.org/abs/2602.07142",
      "category": "cs.HC"
    },
    {
      "title": "BONSAI: Bayesian Optimization with Natural Simplicity and Interpretability",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07144v1 Announce Type: cross \nAbstract: Bayesian optimization (BO) is a popular technique for sample-efficient optimization of black-box functions. In many applications, the parameters being tuned come with a carefully engineered default configuration, and practitioners only want to deviate from this default when necessary. Standard BO, however, does not aim to minimize deviation from the default and, in practice, often pushes weakly relevant parameters to the boundary of the search s",
      "url": "https://arxiv.org/abs/2602.07144",
      "category": "cs.LG"
    },
    {
      "title": "On Randomness in Agentic Evals",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07150v1 Announce Type: cross \nAbstract: Agentic systems are evaluated on benchmarks where agents interact with environments to solve tasks. Most papers report a pass@1 score computed from a single run per task, assuming this gives a reliable performance estimate. We test this assumption by collecting 60,000 agentic trajectories on SWE-Bench-Verified, spanning three models and two scaffolds. We find substantial variance: single-run pass@1 estimates vary by 2.2 to 6.0 percentage points ",
      "url": "https://arxiv.org/abs/2602.07150",
      "category": "cs.LG"
    },
    {
      "title": "Beyond Pooling: Matching for Robust Generalization under Data Heterogeneity",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07154v1 Announce Type: cross \nAbstract: Pooling heterogeneous datasets across domains is a common strategy in representation learning, but naive pooling can amplify distributional asymmetries and yield biased estimators, especially in settings where zero-shot generalization is required. We propose a matching framework that selects samples relative to an adaptive centroid and iteratively refines the representation distribution. The double robustness and the propensity score matching fo",
      "url": "https://arxiv.org/abs/2602.07154",
      "category": "cs.LG"
    },
    {
      "title": "Mimetic Initialization of MLPs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07156v1 Announce Type: cross \nAbstract: Mimetic initialization uses pretrained models as case studies of good initialization, using observations of structures in trained weights to inspire new, simple initialization techniques. So far, it has been applied only to spatial mixing layers, such convolutional, self-attention, and state space layers. In this work, we present the first attempt to apply the method to channel mixing layers, namely multilayer perceptrons (MLPs). Our extremely s",
      "url": "https://arxiv.org/abs/2602.07156",
      "category": "cs.LG"
    },
    {
      "title": "Free Energy Mixer",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07160v1 Announce Type: cross \nAbstract: Standard attention stores keys/values losslessly but reads them via a per-head convex average, blocking channel-wise selection. We propose the Free Energy Mixer (FEM): a free-energy (log-sum-exp) read that applies a value-driven, per-channel log-linear tilt to a fast prior (e.g., from queries/keys in standard attention) over indices. Unlike methods that attempt to improve and enrich the $(q,k)$ scoring distribution, FEM treats it as a prior and ",
      "url": "https://arxiv.org/abs/2602.07160",
      "category": "cs.CL"
    },
    {
      "title": "Your Language Model Secretly Contains Personality Subnetworks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07164v1 Announce Type: cross \nAbstract: Humans shift between different personas depending on social context. Large Language Models (LLMs) demonstrate a similar flexibility in adopting different personas and behaviors. Existing approaches, however, typically adapt such behavior through external knowledge such as prompting, retrieval-augmented generation (RAG), or fine-tuning. We ask: do LLMs really need external context or parameters to adapt to different behaviors, or do they already ",
      "url": "https://arxiv.org/abs/2602.07164",
      "category": "cs.CL"
    },
    {
      "title": "Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07176v1 Announce Type: cross \nAbstract: Recent advances in artificial intelligence have created new possibilities for making education more scalable, adaptive, and learner-centered. However, existing educational chatbot systems often lack contextual adaptability, real-time responsiveness, and pedagogical agility. which can limit learner engagement and diminish instructional effectiveness. Thus, there is a growing need for open, integrative platforms that combine AI and immersive techn",
      "url": "https://arxiv.org/abs/2602.07176",
      "category": "cs.CL"
    },
    {
      "title": "An Information-Theoretic Framework for Comparing Voice and Text Explainability",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07179v1 Announce Type: cross \nAbstract: Explainable Artificial Intelligence (XAI) aims to make machine learning models transparent and trustworthy, yet most current approaches communicate explanations visually or through text. This paper introduces an information theoretic framework for analyzing how explanation modality specifically, voice versus text affects user comprehension and trust calibration in AI systems. The proposed model treats explanation delivery as a communication chan",
      "url": "https://arxiv.org/abs/2602.07179",
      "category": "cs.HC"
    },
    {
      "title": "Long-Context Long-Form Question Answering for Legal Domain",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07190v1 Announce Type: cross \nAbstract: Legal documents have complex document layouts involving multiple nested sections, lengthy footnotes and further use specialized linguistic devices like intricate syntax and domain-specific vocabulary to ensure precision and authority. These inherent characteristics of legal documents make question answering challenging, and particularly so when the answer to the question spans several pages (i.e. requires long-context) and is required to be comp",
      "url": "https://arxiv.org/abs/2602.07190",
      "category": "cs.CL"
    },
    {
      "title": "\"Death\" of a Chatbot: Investigating and Designing Toward Psychologically Safe Endings for Human-AI Relationships",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07193v2 Announce Type: cross \nAbstract: Millions of users form emotional attachments to AI companions like Character AI, Replika, and ChatGPT. When these relationships end through model updates, safety interventions, or platform shutdowns, users receive no closure, reporting grief comparable to human loss. As regulations mandate protections for vulnerable users, discontinuation events will accelerate, yet no platform has implemented deliberate end-of-\"life\" design.\n  Through grounded ",
      "url": "https://arxiv.org/abs/2602.07193",
      "category": "cs.HC"
    },
    {
      "title": "BadSNN: Backdoor Attacks on Spiking Neural Networks via Adversarial Spiking Neuron",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07200v1 Announce Type: cross \nAbstract: Spiking Neural Networks (SNNs) are energy-efficient counterparts of Deep Neural Networks (DNNs) with high biological plausibility, as information is transmitted through temporal spiking patterns. The core element of an SNN is the spiking neuron, which converts input data into spikes following the Leaky Integrate-and-Fire (LIF) neuron model. This model includes several important hyperparameters, such as the membrane potential threshold and membra",
      "url": "https://arxiv.org/abs/2602.07200",
      "category": "cs.CR"
    },
    {
      "title": "Exactly Computing do-Shapley Values",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07203v1 Announce Type: cross \nAbstract: Structural Causal Models (SCM) are a powerful framework for describing complicated dynamics across the natural sciences. A particularly elegant way of interpreting SCMs is do-Shapley, a game-theoretic method of quantifying the average effect of $d$ variables across exponentially many interventions. Like Shapley values, computing do-Shapley values generally requires evaluating exponentially many terms. The foundation of our work is a reformulatio",
      "url": "https://arxiv.org/abs/2602.07203",
      "category": "cs.LG"
    },
    {
      "title": "DSL: Understanding and Improving Softmax Recommender Systems with Competition-Aware Scaling",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07206v1 Announce Type: cross \nAbstract: Softmax Loss (SL) is being increasingly adopted for recommender systems (RS) as it has demonstrated better performance, robustness and fairness. Yet in implicit-feedback, a single global temperature and equal treatment of uniformly sampled negatives can lead to brittle training, because sampled sets may contain varying degrees of relevant or informative competitors. The optimal loss sharpness for a user-item pair with a particular set of negativ",
      "url": "https://arxiv.org/abs/2602.07206",
      "category": "cs.LG"
    },
    {
      "title": "Multimodal Enhancement of Sequential Recommendation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07207v1 Announce Type: cross \nAbstract: We propose a novel recommender framework, MuSTRec (Multimodal and Sequential Transformer-based Recommendation), that unifies multimodal and sequential recommendation paradigms. MuSTRec captures cross-item similarities and collaborative filtering signals, by building item-item graphs from extracted text and visual features. A frequency-based self-attention module additionally captures the short- and long-term user preferences. Across multiple Ama",
      "url": "https://arxiv.org/abs/2602.07207",
      "category": "cs.IR"
    },
    {
      "title": "Sequences as Nodes for Contrastive Multimodal Graph Recommendation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07208v1 Announce Type: cross \nAbstract: To tackle cold-start and data sparsity issues in recommender systems, numerous multimodal, sequential, and contrastive techniques have been proposed. While these augmentations can boost recommendation performance, they tend to add noise and disrupt useful semantics. To address this, we propose MuSICRec (Multimodal Sequence-Item Contrastive Recommender), a multi-view graph-based recommender that combines collaborative, sequential, and multimodal ",
      "url": "https://arxiv.org/abs/2602.07208",
      "category": "cs.IR"
    },
    {
      "title": "Multi-Agentic AI for Fairness-Aware and Accelerated Multi-modal Large Model Inference in Real-world Mobile Edge Networks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07215v1 Announce Type: cross \nAbstract: Generative AI (GenAI) has transformed applications in natural language processing and content creation, yet centralized inference remains hindered by high latency, limited customizability, and privacy concerns. Deploying large models (LMs) in mobile edge networks emerges as a promising solution. However, it also poses new challenges, including heterogeneous multi-modal LMs with diverse resource demands and inference speeds, varied prompt/output ",
      "url": "https://arxiv.org/abs/2602.07215",
      "category": "eess.SY"
    },
    {
      "title": "Collaborative and Efficient Fine-tuning: Leveraging Task Similarity",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07218v1 Announce Type: cross \nAbstract: Adaptability has been regarded as a central feature in the foundation models, enabling them to effectively acclimate to unseen downstream tasks. Parameter-efficient fine-tuning methods such as celebrated LoRA facilitate efficient adaptation of large foundation models using labeled, high-quality and generally scarce task data. To mitigate data scarcity in fine-tuning of foundation models, we propose to leverage task similarity across multiple dow",
      "url": "https://arxiv.org/abs/2602.07218",
      "category": "cs.LG"
    },
    {
      "title": "The Median is Easier than it Looks: Approximation with a Constant-Depth, Linear-Width ReLU Network",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07219v1 Announce Type: cross \nAbstract: We study the approximation of the median of $d$ inputs using ReLU neural networks. We present depth-width tradeoffs under several settings, culminating in a constant-depth, linear-width construction that achieves exponentially small approximation error with respect to the uniform distribution over the unit hypercube. By further establishing a general reduction from the maximum to the median, our results break a barrier suggested by prior work on",
      "url": "https://arxiv.org/abs/2602.07219",
      "category": "cs.LG"
    },
    {
      "title": "ArcMark: Multi-bit LLM Watermark via Optimal Transport",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07235v1 Announce Type: cross \nAbstract: Watermarking is an important tool for promoting the responsible use of language models (LMs). Existing watermarks insert a signal into generated tokens that either flags LM-generated text (zero-bit watermarking) or encodes more complex messages (multi-bit watermarking). Though a number of recent multi-bit watermarks insert several bits into text without perturbing average next-token predictions, they largely extend design principles from the zer",
      "url": "https://arxiv.org/abs/2602.07235",
      "category": "cs.LG"
    },
    {
      "title": "Realistic Synthetic Household Data Generation at Scale",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07243v1 Announce Type: cross \nAbstract: Advancements in foundation models have catalyzed research in Embodied AI to develop interactive agents capable of environmental reasoning and interaction. Developing such agents requires diverse, large-scale datasets. Prior frameworks generate synthetic data for long-term human-robot interactions but fail to model the bidirectional influence between human behavior and household environments. Our proposed generative framework creates household da",
      "url": "https://arxiv.org/abs/2602.07243",
      "category": "cs.RO"
    },
    {
      "title": "The Double-Edged Sword of Data-Driven Super-Resolution: Adversarial Super-Resolution Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07251v1 Announce Type: cross \nAbstract: Data-driven super-resolution (SR) methods are often integrated into imaging pipelines as preprocessing steps to improve downstream tasks such as classification and detection. However, these SR models introduce a previously unexplored attack surface into imaging pipelines. In this paper, we present AdvSR, a framework demonstrating that adversarial behavior can be embedded directly into SR model weights during training, requiring no access to inpu",
      "url": "https://arxiv.org/abs/2602.07251",
      "category": "cs.CV"
    },
    {
      "title": "Graph homophily booster: Reimagining the role of discrete features in heterophilic graph learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07256v1 Announce Type: cross \nAbstract: Graph neural networks (GNNs) have emerged as a powerful tool for modeling graph-structured data. However, existing GNNs often struggle with heterophilic graphs, where connected nodes tend to have dissimilar features or labels. While numerous methods have been proposed to address this challenge, they primarily focus on architectural designs without directly targeting the root cause of the heterophily problem. These approaches still perform even w",
      "url": "https://arxiv.org/abs/2602.07256",
      "category": "cs.LG"
    },
    {
      "title": "Cognitive algorithms and systems of episodic memory, semantic memory and their learnings",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07261v1 Announce Type: cross \nAbstract: Declarative memory, the memory that can be \"declared\" in words or languages, is made up of two dissociated parts: episodic memory and semantic memory. This dissociation has its neuroanatomical basis episodic memory is mostly associated with the hippocampus and semantic memory with the neocortex. The two memories, on the other hand, are closely related. Lesions in the hippocampus often result in various impairments of explicit memory, e.g., anter",
      "url": "https://arxiv.org/abs/2602.07261",
      "category": "q-bio.NC"
    },
    {
      "title": "aerial-autonomy-stack -- a Faster-than-real-time, Autopilot-agnostic, ROS2 Framework to Simulate and Deploy Perception-based Drones",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07264v1 Announce Type: cross \nAbstract: Unmanned aerial vehicles are rapidly transforming multiple applications, from agricultural and infrastructure monitoring to logistics and defense. Introducing greater autonomy to these systems can simultaneously make them more effective as well as reliable. Thus, the ability to rapidly engineer and deploy autonomous aerial systems has become of strategic importance. In the 2010s, a combination of high-performance compute, data, and open-source s",
      "url": "https://arxiv.org/abs/2602.07264",
      "category": "cs.RO"
    },
    {
      "title": "XShare: Collaborative in-Batch Expert Sharing for Faster MoE Inference",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07265v1 Announce Type: cross \nAbstract: Mixture-of-Experts (MoE) architectures are increasingly used to efficiently scale large language models. However, in production inference, request batching and speculative decoding significantly amplify expert activation, eroding these efficiency benefits. We address this issue by modeling batch-aware expert selection as a modular optimization problem and designing efficient greedy algorithms for different deployment settings. The proposed metho",
      "url": "https://arxiv.org/abs/2602.07265",
      "category": "cs.LG"
    },
    {
      "title": "Laplacian-LoRA: Delaying Oversmoothing in Deep GCNs via Spectral Low-Rank Adaptation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07278v1 Announce Type: cross \nAbstract: Oversmoothing is a fundamental limitation of deep graph convolutional networks (GCNs), causing node representations to collapse as depth increases. While many prior approaches mitigate this effect through architectural modifications or residual mechanisms, the underlying spectral cause of oversmoothing is often left implicit. We propose Laplacian-LoRA, a simple and interpretable low-rank spectral adaptation of standard GCNs. Rather than redesign",
      "url": "https://arxiv.org/abs/2602.07278",
      "category": "cs.LG"
    },
    {
      "title": "Imagining the Alien: Human Projections and Cognitive Limitations",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07284v1 Announce Type: cross \nAbstract: Imagining what life on other planets, and intelligent life in particular, may be like is a long-running theme in human culture. It is a manifestation of the innate human curiosity about the Cosmos, and it has inspired numerous works of art and folklore, including whole literary and other media genres. It is a profound question, with philosophical and existential implications. There is also an obvious connection with religious beliefs, as gods an",
      "url": "https://arxiv.org/abs/2602.07284",
      "category": "astro-ph.IM"
    },
    {
      "title": "Fin-RATE: A Real-world Financial Analytics and Tracking Evaluation Benchmark for LLMs on SEC Filings",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07294v1 Announce Type: cross \nAbstract: With increasing deployment of Large Language Models (LLMs) in the finance domain, LLMs are increasingly expected to parse complex regulatory disclosures. However, existing benchmarks often focus on isolated details, failing to reflect the complexity of professional analysis that requires synthesizing information across multiple documents, reporting periods, and corporate entities. They do not distinguish whether errors stem from retrieval failur",
      "url": "https://arxiv.org/abs/2602.07294",
      "category": "cs.CE"
    },
    {
      "title": "Progressive Searching for Retrieval in RAG",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07297v1 Announce Type: cross \nAbstract: Retrieval Augmented Generation (RAG) is a promising technique for mitigating two key limitations of large language models (LLMs): outdated information and hallucinations. RAG system stores documents as embedding vectors in a database. Given a query, search is executed to find the most related documents. Then, the topmost matching documents are inserted into LLMs' prompt to generate a response. Efficient and accurate searching is critical for RAG",
      "url": "https://arxiv.org/abs/2602.07297",
      "category": "cs.IR"
    },
    {
      "title": "Principled Synthetic Data Enables the First Scaling Laws for LLMs in Recommendation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07298v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) represent a promising frontier for recommender systems, yet their development has been impeded by the absence of predictable scaling laws, which are crucial for guiding research and optimizing resource allocation. We hypothesize that this may be attributed to the inherent noise, bias, and incompleteness of raw user interaction data in prior continual pre-training (CPT) efforts. This paper introduces a novel, layered ",
      "url": "https://arxiv.org/abs/2602.07298",
      "category": "cs.IR"
    },
    {
      "title": "KRONE: Hierarchical and Modular Log Anomaly Detection",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07303v1 Announce Type: cross \nAbstract: Log anomaly detection is crucial for uncovering system failures and security risks. Although logs originate from nested component executions with clear boundaries, this structure is lost when they are stored as flat sequences. As a result, state-of-the-art methods risk missing true dependencies within executions while learning spurious ones across unrelated events. We propose KRONE, the first hierarchical anomaly detection framework that automat",
      "url": "https://arxiv.org/abs/2602.07303",
      "category": "cs.DB"
    },
    {
      "title": "LIT-GRAPH: Evaluating Deep vs. Shallow Graph Embeddings for High-Quality Text Recommendation in Domain-Specific Knowledge Graphs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07307v1 Announce Type: cross \nAbstract: This study presents LIT-GRAPH (Literature Graph for Recommendation and Pedagogical Heuristics), a novel knowledge graph-based recommendation system designed to scaffold high school English teachers in selecting diverse, pedagogically aligned instructional literature. The system is built upon an ontology for English literature, addressing the challenge of curriculum stagnation, where we compare four graph embedding paradigms: DeepWalk, Biased Ran",
      "url": "https://arxiv.org/abs/2602.07307",
      "category": "cs.IR"
    },
    {
      "title": "Semantic Search At LinkedIn",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07309v1 Announce Type: cross \nAbstract: Semantic search with large language models (LLMs) enables retrieval by meaning rather than keyword overlap, but scaling it requires major inference efficiency advances. We present LinkedIn's LLM-based semantic search framework for AI Job Search and AI People Search, combining an LLM relevance judge, embedding-based retrieval, and a compact Small Language Model trained via multi-teacher distillation to jointly optimize relevance and engagement. A",
      "url": "https://arxiv.org/abs/2602.07309",
      "category": "cs.IR"
    },
    {
      "title": "LUCID-SAE: Learning Unified Vision-Language Sparse Codes for Interpretable Concept Discovery",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07311v1 Announce Type: cross \nAbstract: Sparse autoencoders (SAEs) offer a natural path toward comparable explanations across different representation spaces. However, current SAEs are trained per modality, producing dictionaries whose features are not directly understandable and whose explanations do not transfer across domains. In this study, we introduce LUCID (Learning Unified vision-language sparse Codes for Interpretable concept Discovery), a unified vision-language sparse autoe",
      "url": "https://arxiv.org/abs/2602.07311",
      "category": "cs.CV"
    },
    {
      "title": "Beyond Accuracy: Risk-Sensitive Evaluation of Hallucinated Medical Advice",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07319v1 Announce Type: cross \nAbstract: Large language models are increasingly being used in patient-facing medical question answering, where hallucinated outputs can vary widely in potential harm. However, existing hallucination standards and evaluation metrics focus primarily on factual correctness, treating all errors as equally severe. This obscures clinically relevant failure modes, particularly when models generate unsupported but actionable medical language. We propose a risk-s",
      "url": "https://arxiv.org/abs/2602.07319",
      "category": "cs.CL"
    },
    {
      "title": "Action-to-Action Flow Matching",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07322v1 Announce Type: cross \nAbstract: Diffusion-based policies have recently achieved remarkable success in robotics by formulating action prediction as a conditional denoising process. However, the standard practice of sampling from random Gaussian noise often requires multiple iterative steps to produce clean actions, leading to high inference latency that incurs a major bottleneck for real-time control. In this paper, we challenge the necessity of uninformed noise sampling and pr",
      "url": "https://arxiv.org/abs/2602.07322",
      "category": "cs.RO"
    },
    {
      "title": "High Fidelity Textual User Representation over Heterogeneous Sources via Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07333v1 Announce Type: cross \nAbstract: Effective personalization on large-scale job platforms requires modeling members based on heterogeneous textual sources, including profiles, professional data, and search activity logs. As recommender systems increasingly adopt Large Language Models (LLMs), creating unified, interpretable, and concise representations from heterogeneous sources becomes critical, especially for latency-sensitive online environments. In this work, we propose a nove",
      "url": "https://arxiv.org/abs/2602.07333",
      "category": "cs.IR"
    },
    {
      "title": "Intent Mismatch Causes LLMs to Get Lost in Multi-Turn Conversation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07338v1 Announce Type: cross \nAbstract: Multi-turn conversation has emerged as a predominant interaction paradigm for Large Language Models (LLMs). Users often employ follow-up questions to refine their intent, expecting LLMs to adapt dynamically. However, recent research reveals that LLMs suffer a substantial performance drop in multi-turn settings compared to single-turn interactions with fully specified instructions, a phenomenon termed ``Lost in Conversation'' (LiC). While this pr",
      "url": "https://arxiv.org/abs/2602.07338",
      "category": "cs.CL"
    },
    {
      "title": "Seeing Roads Through Words: A Language-Guided Framework for RGB-T Driving Scene Segmentation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07343v1 Announce Type: cross \nAbstract: Robust semantic segmentation of road scenes under adverse illumination, lighting, and shadow conditions remain a core challenge for autonomous driving applications. RGB-Thermal fusion is a standard approach, yet existing methods apply static fusion strategies uniformly across all conditions, allowing modality-specific noise to propagate throughout the network. Hence, we propose CLARITY that dynamically adapts its fusion strategy to the detected ",
      "url": "https://arxiv.org/abs/2602.07343",
      "category": "cs.CV"
    },
    {
      "title": "TernaryLM: Memory-Efficient Language Modeling via Native 1-Bit Quantization with Adaptive Layer-wise Scaling",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07374v1 Announce Type: cross \nAbstract: Large language models (LLMs) achieve remarkable performance but demand substantial computational resources, limiting deployment on edge devices and resource-constrained environments. We present TernaryLM, a 132M parameter transformer architecture that employs native 1-bit ternary quantization {-1, 0, +1} during training, achieving significant memory reduction without sacrificing language modeling capability. Unlike post-training quantization app",
      "url": "https://arxiv.org/abs/2602.07374",
      "category": "cs.CL"
    },
    {
      "title": "Advantages of Domain Knowledge Injection for Legal Document Summarization: A Case Study on Summarizing Indian Court Judgments in English and Hindi",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07382v1 Announce Type: cross \nAbstract: Summarizing Indian legal court judgments is a complex task not only due to the intricate language and unstructured nature of the legal texts, but also since a large section of the Indian population does not understand the complex English in which legal text is written, thus requiring summaries in Indian languages. In this study, we aim to improve the summarization of Indian legal text to generate summaries in both English and Hindi (the most wid",
      "url": "https://arxiv.org/abs/2602.07382",
      "category": "cs.CL"
    },
    {
      "title": "Scout Before You Attend: Sketch-and-Walk Sparse Attention for Efficient LLM Inference",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07397v1 Announce Type: cross \nAbstract: Self-attention dominates the computational and memory cost of long-context LLM inference across both prefill and decode phases. To address this challenge, we introduce Sketch&Walk Attention, a training-free sparse attention method that determines sparsity with lightweight sketches and deterministic walk. Sketch&Walk applies Hadamard sketching to get inexpensive approximations of attention scores, then aggregates these estimates across layers via",
      "url": "https://arxiv.org/abs/2602.07397",
      "category": "cs.LG"
    },
    {
      "title": "AgentSys: Secure and Dynamic LLM Agents Through Explicit Hierarchical Memory Management",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07398v1 Announce Type: cross \nAbstract: Indirect prompt injection threatens LLM agents by embedding malicious instructions in external content, enabling unauthorized actions and data theft. LLM agents maintain working memory through their context window, which stores interaction history for decision-making. Conventional agents indiscriminately accumulate all tool outputs and reasoning traces in this memory, creating two critical vulnerabilities: (1) injected instructions persist throu",
      "url": "https://arxiv.org/abs/2602.07398",
      "category": "cs.CR"
    },
    {
      "title": "Learning Molecular Chirality via Chiral Determinant Kernels",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07415v1 Announce Type: cross \nAbstract: Chirality is a fundamental molecular property that governs stereospecific behavior in chemistry and biology. Capturing chirality in machine learning models remains challenging due to the geometric complexity of stereochemical relationships and the limitations of traditional molecular representations that often lack explicit stereochemical encoding. Existing approaches to chiral molecular representation primarily focus on central chirality, relyi",
      "url": "https://arxiv.org/abs/2602.07415",
      "category": "cs.LG"
    },
    {
      "title": "Secure Code Generation via Online Reinforcement Learning with Vulnerability Reward Model",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07422v1 Announce Type: cross \nAbstract: Large language models (LLMs) are increasingly used in software development, yet their tendency to generate insecure code remains a major barrier to real-world deployment. Existing secure code alignment methods often suffer from a functionality--security paradox, improving security at the cost of substantial utility degradation. We propose SecCoderX, an online reinforcement learning framework for functionality-preserving secure code generation. S",
      "url": "https://arxiv.org/abs/2602.07422",
      "category": "cs.CR"
    },
    {
      "title": "Brep2Shape: Boundary and Shape Representation Alignment via Self-Supervised Transformers",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07429v1 Announce Type: cross \nAbstract: Boundary representation (B-rep) is the industry standard for computer-aided design (CAD). While deep learning shows promise in processing B-rep models, existing methods suffer from a representation gap: continuous approaches offer analytical precision but are visually abstract, whereas discrete methods provide intuitive clarity at the expense of geometric precision. To bridge this gap, we introduce Brep2Shape, a novel self-supervised pre-trainin",
      "url": "https://arxiv.org/abs/2602.07429",
      "category": "cs.LG"
    },
    {
      "title": "Multi-Agent Systems Shape Social Norms for Prosocial Behavior Change",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07433v1 Announce Type: cross \nAbstract: Social norm interventions are used promote prosocial behaviors by highlighting prevalent actions, but their effectiveness is often limited in heterogeneous populations where shared understandings of desirable behaviors are lacking. This study explores whether multi-agent systems can establish \"virtual social norms\" to encourage donation behavior. We conducted an online experiment where participants interacted with a group of agents to discuss do",
      "url": "https://arxiv.org/abs/2602.07433",
      "category": "cs.HC"
    },
    {
      "title": "Bridging Speech, Emotion, and Motion: a VLM-based Multimodal Edge-deployable Framework for Humanoid Robots",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07434v1 Announce Type: cross \nAbstract: Effective human-robot interaction requires emotionally rich multimodal expressions, yet most humanoid robots lack coordinated speech, facial expressions, and gestures. Meanwhile, real-world deployment demands on-device solutions that can operate autonomously without continuous cloud connectivity. To bridging \\underline{\\textit{S}}peech, \\underline{\\textit{E}}motion, and \\underline{\\textit{M}}otion, we present \\textit{SeM$^2$}, a Vision Language ",
      "url": "https://arxiv.org/abs/2602.07434",
      "category": "cs.RO"
    },
    {
      "title": "TextOp: Real-time Interactive Text-Driven Humanoid Robot Motion Generation and Control",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07439v1 Announce Type: cross \nAbstract: Recent advances in humanoid whole-body motion tracking have enabled the execution of diverse and highly coordinated motions on real hardware. However, existing controllers are commonly driven either by predefined motion trajectories, which offer limited flexibility when user intent changes, or by continuous human teleoperation, which requires constant human involvement and limits autonomy. This work addresses the problem of how to drive a univer",
      "url": "https://arxiv.org/abs/2602.07439",
      "category": "cs.RO"
    },
    {
      "title": "Proximal Action Replacement for Behavior Cloning Actor-Critic in Offline Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07441v1 Announce Type: cross \nAbstract: Offline reinforcement learning (RL) optimizes policies from a previously collected static dataset and is an important branch of RL. A popular and promising approach is to regularize actor-critic methods with behavior cloning (BC), which yields realistic policies and mitigates bias from out-of-distribution actions, but can impose an often-overlooked performance ceiling: when dataset actions are suboptimal, indiscriminate imitation structurally pr",
      "url": "https://arxiv.org/abs/2602.07441",
      "category": "cs.LG"
    },
    {
      "title": "Pull Requests as a Training Signal for Repo-Level Code Editing",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07457v1 Announce Type: cross \nAbstract: Repository-level code editing requires models to understand complex dependencies and execute precise multi-file modifications across a large codebase. While recent gains on SWE-bench rely heavily on complex agent scaffolding, it remains unclear how much of this capability can be internalised via high-quality training signals. To address this, we propose Clean Pull Request (Clean-PR), a mid-training paradigm that leverages real-world GitHub pull ",
      "url": "https://arxiv.org/abs/2602.07457",
      "category": "cs.SE"
    },
    {
      "title": "Deriving Neural Scaling Laws from the statistics of natural language",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07488v1 Announce Type: cross \nAbstract: Despite the fact that experimental neural scaling laws have substantially guided empirical progress in large-scale machine learning, no existing theory can quantitatively predict the exponents of these important laws for any modern LLM trained on any natural language dataset. We provide the first such theory in the case of data-limited scaling laws. We isolate two key statistical properties of language that alone can predict neural scaling expon",
      "url": "https://arxiv.org/abs/2602.07488",
      "category": "cs.LG"
    },
    {
      "title": "VividFace: Real-Time and Realistic Facial Expression Shadowing for Humanoid Robots",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07506v1 Announce Type: cross \nAbstract: Humanoid facial expression shadowing enables robots to realistically imitate human facial expressions in real time, which is critical for lifelike, facially expressive humanoid robots and affective human-robot interaction. Existing progress in humanoid facial expression imitation remains limited, often failing to achieve either real-time performance or realistic expressiveness due to offline video-based inference designs and insufficient ability",
      "url": "https://arxiv.org/abs/2602.07506",
      "category": "cs.RO"
    },
    {
      "title": "MemPot: Defending Against Memory Extraction Attack with Optimized Honeypots",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07517v1 Announce Type: cross \nAbstract: Large Language Model (LLM)-based agents employ external and internal memory systems to handle complex, goal-oriented tasks, yet this exposes them to severe extraction attacks, and effective defenses remain lacking. In this paper, we propose MemPot, the first theoretically verified defense framework against memory extraction attacks by injecting optimized honeypots into the memory. Through a two-stage optimization process, MemPot generates trap d",
      "url": "https://arxiv.org/abs/2602.07517",
      "category": "cs.CR"
    },
    {
      "title": "MDL: A Unified Multi-Distribution Learner in Large-scale Industrial Recommendation through Tokenization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07520v2 Announce Type: cross \nAbstract: Industrial recommender systems increasingly adopt multi-scenario learning (MSL) and multi-task learning (MTL) to handle diverse user interactions and contexts, but existing approaches suffer from two critical drawbacks: (1) underutilization of large-scale model parameters due to limited interaction with complex feature modules, and (2) difficulty in jointly modeling scenario and task information in a unified framework. To address these challenge",
      "url": "https://arxiv.org/abs/2602.07520",
      "category": "cs.IR"
    },
    {
      "title": "Fine-Grained Cat Breed Recognition with Global Context Vision Transformer",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07534v1 Announce Type: cross \nAbstract: Accurate identification of cat breeds from images is a challenging task due to subtle differences in fur patterns, facial structure, and color. In this paper, we present a deep learning-based approach for classifying cat breeds using a subset of the Oxford-IIIT Pet Dataset, which contains high-resolution images of various domestic breeds. We employed the Global Context Vision Transformer (GCViT) architecture-tiny for cat breed recognition. To im",
      "url": "https://arxiv.org/abs/2602.07534",
      "category": "cs.CV"
    },
    {
      "title": "Beyond Core and Penumbra: Bi-Temporal Image-Driven Stroke Evolution Analysis",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07535v1 Announce Type: cross \nAbstract: Computed tomography perfusion (CTP) at admission is routinely used to estimate the ischemic core and penumbra, while follow-up diffusion-weighted MRI (DWI) provides the definitive infarct outcome. However, single time-point segmentations fail to capture the biological heterogeneity and temporal evolution of stroke. We propose a bi-temporal analysis framework that characterizes ischemic tissue using statistical descriptors, radiomic texture featu",
      "url": "https://arxiv.org/abs/2602.07535",
      "category": "cs.CV"
    },
    {
      "title": "Linguistic properties and model scale in brain encoding: from small to compressed language models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07547v1 Announce Type: cross \nAbstract: Recent work has shown that scaling large language models (LLMs) improves their alignment with human brain activity, yet it remains unclear what drives these gains and which representational properties are responsible. Although larger models often yield better task performance and brain alignment, they are increasingly difficult to analyze mechanistically. This raises a fundamental question: what is the minimal model capacity required to capture ",
      "url": "https://arxiv.org/abs/2602.07547",
      "category": "q-bio.NC"
    },
    {
      "title": "Revealing the Semantic Selection Gap in DINOv3 through Training-Free Few-Shot Segmentation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07550v1 Announce Type: cross \nAbstract: Recent self-supervised Vision Transformers (ViTs), such as DINOv3, provide rich feature representations for dense vision tasks. This study investigates the intrinsic few-shot semantic segmentation (FSS) capabilities of frozen DINOv3 features through a training-free baseline, FSSDINO, utilizing class-specific prototypes and Gram-matrix refinement. Our results across binary, multi-class, and cross-domain (CDFSS) benchmarks demonstrate that this mi",
      "url": "https://arxiv.org/abs/2602.07550",
      "category": "cs.CV"
    },
    {
      "title": "VISOR: VIsual Spatial Object Reasoning for Language-driven Object Navigation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07555v1 Announce Type: cross \nAbstract: Language-driven object navigation requires agents to interpret natural language descriptions of target objects, which combine intrinsic and extrinsic attributes for instance recognition and commonsense navigation. Existing methods either (i) use end-to-end trained models with vision-language embeddings, which struggle to generalize beyond training data and lack action-level explainability, or (ii) rely on modular zero-shot pipelines with large l",
      "url": "https://arxiv.org/abs/2602.07555",
      "category": "cs.CV"
    },
    {
      "title": "Gaussian Match-and-Copy: A Minimalist Benchmark for Studying Transformer Induction",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07562v1 Announce Type: cross \nAbstract: Match-and-copy is a core retrieval primitive used at inference time by large language models to retrieve a matching token from the context then copy its successor. Yet, understanding how this behavior emerges on natural data is challenging because retrieval and memorization are entangled. To disentangle the two, we introduce Gaussian Match-and-Copy (GMC), a minimalist benchmark that isolates long-range retrieval through pure second-order correla",
      "url": "https://arxiv.org/abs/2602.07562",
      "category": "cs.LG"
    },
    {
      "title": "Cross-Camera Cow Identification via Disentangled Representation Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07566v1 Announce Type: cross \nAbstract: Precise identification of individual cows is a fundamental prerequisite for comprehensive digital management in smart livestock farming. While existing animal identification methods excel in controlled, single-camera settings, they face severe challenges regarding cross-camera generalization. When models trained on source cameras are deployed to new monitoring nodes characterized by divergent illumination, backgrounds, viewpoints, and heterogene",
      "url": "https://arxiv.org/abs/2602.07566",
      "category": "cs.CV"
    },
    {
      "title": "How does longer temporal context enhance multimodal narrative video processing in the brain?",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07570v1 Announce Type: cross \nAbstract: Understanding how humans and artificial intelligence systems process complex narrative videos is a fundamental challenge at the intersection of neuroscience and machine learning. This study investigates how the temporal context length of video clips (3--12 s clips) and the narrative-task prompting shape brain-model alignment during naturalistic movie watching. Using fMRI recordings from participants viewing full-length movies, we examine how bra",
      "url": "https://arxiv.org/abs/2602.07570",
      "category": "q-bio.NC"
    },
    {
      "title": "Graph Domain Adaptation via Homophily-Agnostic Reconstructing Structure",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07573v1 Announce Type: cross \nAbstract: Graph Domain Adaptation (GDA) transfers knowledge from labeled source graphs to unlabeled target graphs, addressing the challenge of label scarcity. However, existing GDA methods typically assume that both source and target graphs exhibit homophily, leading existing methods to perform poorly when heterophily is present. Furthermore, the lack of labels in the target graph makes it impossible to assess its homophily level beforehand. To address th",
      "url": "https://arxiv.org/abs/2602.07573",
      "category": "cs.SI"
    },
    {
      "title": "Automated rock joint trace mapping using a supervised learning model trained on synthetic data generated by parametric modelling",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07590v1 Announce Type: cross \nAbstract: This paper presents a geology-driven machine learning method for automated rock joint trace mapping from images. The approach combines geological modelling, synthetic data generation, and supervised image segmentation to address limited real data and class imbalance. First, discrete fracture network models are used to generate synthetic jointed rock images at field-relevant scales via parametric modelling, preserving joint persistence, connectiv",
      "url": "https://arxiv.org/abs/2602.07590",
      "category": "cs.CV"
    },
    {
      "title": "Learning to Self-Verify Makes Language Models Better Reasoners",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07594v1 Announce Type: cross \nAbstract: Recent large language models (LLMs) achieve strong performance in generating promising reasoning paths for complex tasks. However, despite powerful generation ability, LLMs remain weak at verifying their own answers, revealing a persistent capability asymmetry between generation and self-verification. In this work, we conduct an in-depth investigation of this asymmetry throughout training evolution and show that, even on the same task, improving",
      "url": "https://arxiv.org/abs/2602.07594",
      "category": "cs.CL"
    },
    {
      "title": "TeleBoost: A Systematic Alignment Framework for High-Fidelity, Controllable, and Robust Video Generation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07595v1 Announce Type: cross \nAbstract: Post-training is the decisive step for converting a pretrained video generator into a production-oriented model that is instruction-following, controllable, and robust over long temporal horizons. This report presents a systematical post-training framework that organizes supervised policy shaping, reward-driven reinforcement learning, and preference-based refinement into a single stability-constrained optimization stack. The framework is designe",
      "url": "https://arxiv.org/abs/2602.07595",
      "category": "cs.CV"
    },
    {
      "title": "Astro: Activation-guided Structured Regularization for Outlier-Robust LLM Post-Training Quantization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07596v1 Announce Type: cross \nAbstract: Weight-only post-training quantization (PTQ) is crucial for efficient Large Language Model (LLM) deployment but suffers from accuracy degradation caused by weight and activation outliers. Existing mitigation strategies often face critical limitations: they either yield insufficient outlier suppression or incur significant deployment inefficiencies, such as inference latency, heavy preprocessing, or reliance on complex operator fusion. To resolve",
      "url": "https://arxiv.org/abs/2602.07596",
      "category": "cs.LG"
    },
    {
      "title": "Fine-R1: Make Multi-modal LLMs Excel in Fine-Grained Visual Recognition by Chain-of-Thought Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07605v2 Announce Type: cross \nAbstract: Any entity in the visual world can be hierarchically grouped based on shared characteristics and mapped to fine-grained sub-categories. While Multi-modal Large Language Models (MLLMs) achieve strong performance on coarse-grained visual tasks, they often struggle with Fine-Grained Visual Recognition (FGVR). Adapting general-purpose MLLMs to FGVR typically requires large amounts of annotated data, which is costly to obtain, leaving a substantial p",
      "url": "https://arxiv.org/abs/2602.07605",
      "category": "cs.CV"
    },
    {
      "title": "Evaluating Large Language Models for Detecting Architectural Decision Violations",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07609v1 Announce Type: cross \nAbstract: Architectural Decision Records (ADRs) play a central role in maintaining software architecture quality, yet many decision violations go unnoticed because projects lack both systematic documentation and automated detection mechanisms. Recent advances in Large Language Models (LLMs) open up new possibilities for automating architectural reasoning at scale. We investigated how effectively LLMs can identify decision violations in open-source systems",
      "url": "https://arxiv.org/abs/2602.07609",
      "category": "cs.SE"
    },
    {
      "title": "SERE: Similarity-based Expert Re-routing for Efficient Batch Decoding in MoE Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07616v1 Announce Type: cross \nAbstract: Mixture-of-Experts (MoE) architectures employ sparse activation to deliver faster training and inference with higher accuracy than dense LLMs. However, in production serving, MoE models require batch inference to optimize hardware efficiency, which may cause excessive expert activation and thus slow the memory-bound decoding stage. To address the fundamental tension between batch decoding and expert sparsity, we present SERE, a Similarity-based ",
      "url": "https://arxiv.org/abs/2602.07616",
      "category": "cs.LG"
    },
    {
      "title": "AD-MIR: Bridging the Gap from Perception to Persuasion in Advertising Video Understanding via Structured Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07625v1 Announce Type: cross \nAbstract: Multimodal understanding of advertising videos is essential for interpreting the intricate relationship between visual storytelling and abstract persuasion strategies. However, despite excelling at general search, existing agents often struggle to bridge the cognitive gap between pixel-level perception and high-level marketing logic. To address this challenge, we introduce AD-MIR, a framework designed to decode advertising intent via a two-stage",
      "url": "https://arxiv.org/abs/2602.07625",
      "category": "cs.CV"
    },
    {
      "title": "From Dead Pixels to Editable Slides: Infographic Reconstruction into Native Google Slides via Vision-Language Region Understanding",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07645v1 Announce Type: cross \nAbstract: Infographics are widely used to communicate information with a combination of text, icons, and data visualizations, but once exported as images their content is locked into pixels, making updates, localization, and reuse expensive. We describe \\textsc{Images2Slides}, an API-based pipeline that converts a static infographic (PNG/JPG) into a native, editable Google Slides slide by extracting a region-level specification with a vision-language mode",
      "url": "https://arxiv.org/abs/2602.07645",
      "category": "cs.CV"
    },
    {
      "title": "Agent-Fence: Mapping Security Vulnerabilities Across Deep Research Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07652v1 Announce Type: cross \nAbstract: Large language models are increasingly deployed as *deep agents* that plan, maintain persistent state, and invoke external tools, shifting safety failures from unsafe text to unsafe *trajectories*. We introduce **AgentFence**, an architecture-centric security evaluation that defines 14 trust-boundary attack classes spanning planning, memory, retrieval, tool use, and delegation, and detects failures via *trace-auditable conversation breaks* (unau",
      "url": "https://arxiv.org/abs/2602.07652",
      "category": "cs.CR"
    },
    {
      "title": "Continuous Program Search",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07659v1 Announce Type: cross \nAbstract: Genetic Programming yields interpretable programs, but small syntactic mutations can induce large, unpredictable behavioral shifts, degrading locality and sample efficiency. We frame this as an operator-design problem: learn a continuous program space where latent distance has behavioral meaning, then design mutation operators that exploit this structure without changing the evolutionary optimizer.\n  We make locality measurable by tracking actio",
      "url": "https://arxiv.org/abs/2602.07659",
      "category": "cs.LG"
    },
    {
      "title": "SoK: DARPA's AI Cyber Challenge (AIxCC): Competition Design, Architectures, and Lessons Learned",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07666v1 Announce Type: cross \nAbstract: DARPA's AI Cyber Challenge (AIxCC, 2023--2025) is the largest competition to date for building fully autonomous cyber reasoning systems (CRSs) that leverage recent advances in AI -- particularly large language models (LLMs) -- to discover and remediate vulnerabilities in real-world open-source software. This paper presents the first systematic analysis of AIxCC. Drawing on design documents, source code, execution traces, and discussions with org",
      "url": "https://arxiv.org/abs/2602.07666",
      "category": "cs.CR"
    },
    {
      "title": "Looking and Listening Inside and Outside: Multimodal Artificial Intelligence Systems for Driver Safety Assessment and Intelligent Vehicle Decision-Making",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07668v1 Announce Type: cross \nAbstract: The looking-in-looking-out (LILO) framework has enabled intelligent vehicle applications that understand both the outside scene and the driver state to improve safety outcomes, with examples in smart airbag deployment, takeover time prediction in autonomous control transitions, and driver attention monitoring. In this research, we propose an augmentation to this framework, making a case for the audio modality as an additional source of informati",
      "url": "https://arxiv.org/abs/2602.07668",
      "category": "cs.CV"
    },
    {
      "title": "Surprisal-Guided Selection: Compute-Optimal Test-Time Strategies for Execution-Grounded Code Generation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07670v1 Announce Type: cross \nAbstract: Test-time training (TTT) adapts language models through gradient-based updates at inference. But is adaptation the right strategy? We study compute-optimal test-time strategies for verifiable execution-grounded (VEG) tasks, domains like GPU kernel optimization where a deterministic evaluator provides dense, continuous reward signals. Using KernelBench as our testbed and a 120B-parameter model (GPT-OSS-120B with LoRA adaptation), we find that sea",
      "url": "https://arxiv.org/abs/2602.07670",
      "category": "cs.LG"
    },
    {
      "title": "Debugging code world models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07672v1 Announce Type: cross \nAbstract: Code World Models (CWMs) are language models trained to simulate program execution by predicting explicit runtime state after every executed command. This execution-based world modeling enables internal verification within the model, offering an alternative to natural language chain-of-thought reasoning. However, the sources of errors and the nature of CWMs' limitations remain poorly understood. We study CWMs from two complementary perspectives:",
      "url": "https://arxiv.org/abs/2602.07672",
      "category": "cs.SE"
    },
    {
      "title": "Spectral Gating Networks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07679v1 Announce Type: cross \nAbstract: Gating mechanisms are ubiquitous, yet a complementary question in feed-forward networks remains under-explored: how to introduce frequency-rich expressivity without sacrificing stability and scalability? This tension is exposed by spline-based Kolmogorov-Arnold Network (KAN) parameterizations, where grid refinement can induce parameter growth and brittle optimization in high dimensions. To propose a stability-preserving way to inject spectral ca",
      "url": "https://arxiv.org/abs/2602.07679",
      "category": "cs.LG"
    },
    {
      "title": "Vision and language: Novel Representations and Artificial intelligence for Driving Scene Safety Assessment and Autonomous Vehicle Planning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07680v1 Announce Type: cross \nAbstract: Vision-language models (VLMs) have recently emerged as powerful representation learning systems that align visual observations with natural language concepts, offering new opportunities for semantic reasoning in safety-critical autonomous driving. This paper investigates how vision-language representations support driving scene safety assessment and decision-making when integrated into perception, prediction, and planning pipelines. We study thr",
      "url": "https://arxiv.org/abs/2602.07680",
      "category": "cs.CV"
    },
    {
      "title": "Mapping Drivers of Greenness: Spatial Variable Selection for MODIS Vegetation Indices",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07681v2 Announce Type: cross \nAbstract: Understanding how environmental drivers relate to vegetation condition motivates spatially varying regression models, but estimating a separate coefficient surface for every predictor can yield noisy patterns and poor interpretability when many predictors are irrelevant. Motivated by MODIS vegetation index studies, we examine predictors from spectral bands, productivity and energy fluxes, observation geometry, and land surface characteristics. B",
      "url": "https://arxiv.org/abs/2602.07681",
      "category": "stat.ME"
    },
    {
      "title": "Process-of-Thought Reasoning for Videos",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07689v1 Announce Type: cross \nAbstract: Video understanding requires not only recognizing visual content but also performing temporally grounded, multi-step reasoning over long and noisy observations. We propose Process-of-Thought (PoT) Reasoning for Videos, a framework that makes the reasoning process explicit by structuring video inference into a sequence of lightweight, verifiable steps. PoT interleaves (i) temporal evidence selection, (ii) step-wise state updates, and (iii) constr",
      "url": "https://arxiv.org/abs/2602.07689",
      "category": "cs.CV"
    },
    {
      "title": "On the Infinite Width and Depth Limits of Predictive Coding Networks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07697v1 Announce Type: cross \nAbstract: Predictive coding (PC) is a biologically plausible alternative to standard backpropagation (BP) that minimises an energy function with respect to network activities before updating weights. Recent work has improved the training stability of deep PC networks (PCNs) by leveraging some BP-inspired reparameterisations. However, the full scalability and theoretical basis of these approaches remains unclear. To address this, we study the infinite widt",
      "url": "https://arxiv.org/abs/2602.07697",
      "category": "cs.LG"
    },
    {
      "title": "Do We Need Adam? Surprisingly Strong and Sparse Reinforcement Learning with SGD in LLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07729v1 Announce Type: cross \nAbstract: Reinforcement learning (RL), particularly RL from verifiable reward (RLVR), has become a crucial phase of training large language models (LLMs) and a key focus of current scaling efforts. However, optimization practices in RL largely follow those of next-token prediction stages (e.g., pretraining and supervised fine-tuning), despite fundamental differences between RL and these stages highlighted by recent work. One such practice is the use of th",
      "url": "https://arxiv.org/abs/2602.07729",
      "category": "cs.LG"
    },
    {
      "title": "The Laplacian Keyboard: Beyond the Linear Span",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07730v1 Announce Type: cross \nAbstract: Across scientific disciplines, Laplacian eigenvectors serve as a fundamental basis for simplifying complex systems, from signal processing to quantum mechanics. In reinforcement learning (RL), these eigenvectors provide a natural basis for approximating reward functions; however, their use is typically limited to their linear span, which restricts expressivity in complex environments. We introduce the Laplacian Keyboard (LK), a hierarchical fram",
      "url": "https://arxiv.org/abs/2602.07730",
      "category": "cs.LG"
    },
    {
      "title": "Learnable Chernoff Baselines for Inference-Time Alignment",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07738v1 Announce Type: cross \nAbstract: We study inference-time reward-guided alignment for generative models. Existing methods often rely on either architecture-specific adaptations or computationally costly inference procedures. We introduce Learnable Chernoff Baselines (LCBs) as a method for efficiently and approximately sampling from the exponentially tilted kernels that arise from KL-regularized reward alignment. Using only black-box sampling access to the pretrained model, LCBs ",
      "url": "https://arxiv.org/abs/2602.07738",
      "category": "cs.LG"
    },
    {
      "title": "HypRAG: Hyperbolic Dense Retrieval for Retrieval Augmented Generation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07739v1 Announce Type: cross \nAbstract: Embedding geometry plays a fundamental role in retrieval quality, yet dense retrievers for retrieval-augmented generation (RAG) remain largely confined to Euclidean space. However, natural language exhibits hierarchical structure from broad topics to specific entities that Euclidean embeddings fail to preserve, causing semantically distant documents to appear spuriously similar and increasing hallucination risk. To address these limitations, we ",
      "url": "https://arxiv.org/abs/2602.07739",
      "category": "cs.IR"
    },
    {
      "title": "Preference Conditioned Multi-Objective Reinforcement Learning: Decomposed, Diversity-Driven Policy Optimization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07764v1 Announce Type: cross \nAbstract: Multi-objective reinforcement learning (MORL) seeks to learn policies that balance multiple, often conflicting objectives. Although a single preference-conditioned policy is the most flexible and scalable solution, existing approaches remain brittle in practice, frequently failing to recover complete Pareto fronts. We show that this failure stems from two structural issues in current methods: destructive gradient interference caused by premature",
      "url": "https://arxiv.org/abs/2602.07764",
      "category": "cs.LG"
    },
    {
      "title": "PAND: Prompt-Aware Neighborhood Distillation for Lightweight Fine-Grained Visual Classification",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07768v1 Announce Type: cross \nAbstract: Distilling knowledge from large Vision-Language Models (VLMs) into lightweight networks is crucial yet challenging in Fine-Grained Visual Classification (FGVC), due to the reliance on fixed prompts and global alignment. To address this, we propose PAND (Prompt-Aware Neighborhood Distillation), a two-stage framework that decouples semantic calibration from structural transfer. First, we incorporate Prompt-Aware Semantic Calibration to generate ad",
      "url": "https://arxiv.org/abs/2602.07768",
      "category": "cs.CV"
    },
    {
      "title": "Generative Reasoning Re-ranker",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07774v2 Announce Type: cross \nAbstract: Recent studies increasingly explore Large Language Models (LLMs) as a new paradigm for recommendation systems due to their scalability and world knowledge. However, existing work has three key limitations: (1) most efforts focus on retrieval and ranking, while the reranking phase, critical for refining final recommendations, is largely overlooked; (2) LLMs are typically used in zero-shot or supervised fine-tuning settings, leaving their reasonin",
      "url": "https://arxiv.org/abs/2602.07774",
      "category": "cs.IR"
    },
    {
      "title": "Still Manual? Automated Linter Configuration via DSL-Based LLM Compilation of Coding Standards",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07783v1 Announce Type: cross \nAbstract: Coding standards are essential for maintaining consistent and high-quality code across teams and projects. Linters help developers enforce these standards by detecting code violations. However, manual linter configuration is complex and expertise-intensive, and the diversity and evolution of programming languages, coding standards, and linters lead to repetitive and maintenance-intensive configuration work. To reduce manual effort, we propose Li",
      "url": "https://arxiv.org/abs/2602.07783",
      "category": "cs.SE"
    },
    {
      "title": "Emergent Structured Representations Support Flexible In-Context Inference in Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07794v2 Announce Type: cross \nAbstract: Large language models (LLMs) exhibit emergent behaviors suggestive of human-like reasoning. While recent work has identified structured, human-like conceptual representations within these models, it remains unclear whether they functionally rely on such representations for reasoning. Here we investigate the internal processing of LLMs during in-context concept inference. Our results reveal a conceptual subspace emerging in middle to late layers,",
      "url": "https://arxiv.org/abs/2602.07794",
      "category": "cs.CL"
    },
    {
      "title": "CausalTAD: Injecting Causal Knowledge into Large Language Models for Tabular Anomaly Detection",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07798v1 Announce Type: cross \nAbstract: Detecting anomalies in tabular data is critical for many real-world applications, such as credit card fraud detection. With the rapid advancements in large language models (LLMs), state-of-the-art performance in tabular anomaly detection has been achieved by converting tabular data into text and fine-tuning LLMs. However, these methods randomly order columns during conversion, without considering the causal relationships between them, which is c",
      "url": "https://arxiv.org/abs/2602.07798",
      "category": "cs.LG"
    },
    {
      "title": "Fairness Aware Reward Optimization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07799v1 Announce Type: cross \nAbstract: Demographic skews in human preference data propagate systematic unfairness through reward models into aligned LLMs. We introduce Fairness Aware Reward Optimization (Faro), an in-processing framework that trains reward models under demographic parity, equalized odds, or counterfactual fairness constraints. We provide the first theoretical analysis of reward-level fairness in LLM alignment, establishing: (i) provable fairness certificates for Faro",
      "url": "https://arxiv.org/abs/2602.07799",
      "category": "cs.LG"
    },
    {
      "title": "VideoTemp-o3: Harmonizing Temporal Grounding and Video Understanding in Agentic Thinking-with-Videos",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07801v1 Announce Type: cross \nAbstract: In long-video understanding, conventional uniform frame sampling often fails to capture key visual evidence, leading to degraded performance and increased hallucinations. To address this, recent agentic thinking-with-videos paradigms have emerged, adopting a localize-clip-answer pipeline in which the model actively identifies relevant video segments, performs dense sampling within those clips, and then produces answers. However, existing methods",
      "url": "https://arxiv.org/abs/2602.07801",
      "category": "cs.CV"
    },
    {
      "title": "SoulX-Singer: Towards High-Quality Zero-Shot Singing Voice Synthesis",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07803v1 Announce Type: cross \nAbstract: While recent years have witnessed rapid progress in speech synthesis, open-source singing voice synthesis (SVS) systems still face significant barriers to industrial deployment, particularly in terms of robustness and zero-shot generalization. In this report, we introduce SoulX-Singer, a high-quality open-source SVS system designed with practical deployment considerations in mind. SoulX-Singer supports controllable singing generation conditioned",
      "url": "https://arxiv.org/abs/2602.07803",
      "category": "eess.AS"
    },
    {
      "title": "Pruning as a Cooperative Game: Surrogate-Assisted Layer Contribution Estimation for Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07804v1 Announce Type: cross \nAbstract: While large language models (LLMs) demonstrate impressive performance across various tasks, their deployment in real-world scenarios is still constrained by high computational demands. Layer-wise pruning, a commonly employed strategy to mitigate inference costs, can partially address this challenge. However, existing approaches generally depend on static heuristic rules and fail to account for the interdependencies among layers, thereby limiting",
      "url": "https://arxiv.org/abs/2602.07804",
      "category": "cs.CL"
    },
    {
      "title": "How well are open sourced AI-generated image detection models out-of-the-box: A comprehensive benchmark study",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07814v1 Announce Type: cross \nAbstract: As AI-generated images proliferate across digital platforms, reliable detection methods have become critical for combating misinformation and maintaining content authenticity. While numerous deepfake detection methods have been proposed, existing benchmarks predominantly evaluate fine-tuned models, leaving a critical gap in understanding out-of-the-box performance -- the most common deployment scenario for practitioners. We present the first com",
      "url": "https://arxiv.org/abs/2602.07814",
      "category": "cs.CV"
    },
    {
      "title": "Efficient Representations are Controllable Representations",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07828v1 Announce Type: cross \nAbstract: What is the most brute-force way to install interpretable, controllable features into a model's activations? Controlling how LLMs internally represent concepts typically requires sophisticated methods to first identify, then intervene on the model's existing feature geometry. We bypass all of this.\n  We finetune an LLM with a simple auxiliary loss, training 16 of its 3072 residual stream dimensions to be inert interpretability flags that simply ",
      "url": "https://arxiv.org/abs/2602.07828",
      "category": "cs.LG"
    },
    {
      "title": "rePIRL: Learn PRM with Inverse RL for LLM Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07832v1 Announce Type: cross \nAbstract: Process rewards have been widely used in deep reinforcement learning to improve training efficiency, reduce variance, and prevent reward hacking. In LLM reasoning, existing works also explore various solutions for learning effective process reward models (PRM) with or without the help of an expert policy. However, existing methods either rely on strong assumptions about the expert policies (e.g., requiring their reward functions) or suffer intri",
      "url": "https://arxiv.org/abs/2602.07832",
      "category": "cs.LG"
    },
    {
      "title": "SPD-Faith Bench: Diagnosing and Improving Faithfulness in Chain-of-Thought for Multimodal Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07833v1 Announce Type: cross \nAbstract: Chain-of-Thought reasoning is widely used to improve the interpretability of multimodal large language models (MLLMs), yet the faithfulness of the generated reasoning traces remains unclear. Prior work has mainly focused on perceptual hallucinations, leaving reasoning level unfaithfulness underexplored. To isolate faithfulness from linguistic priors, we introduce SPD-Faith Bench, a diagnostic benchmark based on fine-grained image difference reas",
      "url": "https://arxiv.org/abs/2602.07833",
      "category": "cs.CV"
    },
    {
      "title": "TodoEvolve: Learning to Architect Agent Planning Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07839v1 Announce Type: cross \nAbstract: Planning has become a central capability for contemporary agent systems in navigating complex, long-horizon tasks, yet existing approaches predominantly rely on fixed, hand-crafted planning structures that lack the flexibility to adapt to the structural diversity of open-ended problems. To address this limitation, we introduce TodoEvolve, a meta-planning paradigm that autonomously synthesizes and dynamically revises task-specific planning archit",
      "url": "https://arxiv.org/abs/2602.07839",
      "category": "cs.CL"
    },
    {
      "title": "SAGE: Scalable AI Governance & Evaluation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07840v2 Announce Type: cross \nAbstract: Evaluating relevance in large-scale search systems is fundamentally constrained by the governance gap between nuanced, resource-constrained human oversight and the high-throughput requirements of production systems. While traditional approaches rely on engagement proxies or sparse manual review, these methods often fail to capture the full scope of high-impact relevance failures. We present \\textbf{SAGE} (Scalable AI Governance \\& Evaluation), a",
      "url": "https://arxiv.org/abs/2602.07840",
      "category": "cs.IR"
    },
    {
      "title": "Orchestrating Attention: Bringing Harmony to the 'Chaos' of Neurodivergent Learning States",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07865v1 Announce Type: cross \nAbstract: Adaptive learning systems optimize content delivery based on performance metrics but ignore the dynamic attention fluctuations that characterize neurodivergent learners. We present AttentionGuard, a framework that detects engagement-attention states from privacy-preserving behavioral signals and adapts interface elements accordingly. Our approach models four attention states derived from ADHD phenomenology and implements five novel UI adaptation",
      "url": "https://arxiv.org/abs/2602.07865",
      "category": "cs.HC"
    },
    {
      "title": "Direct Soft-Policy Sampling via Langevin Dynamics",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07873v1 Announce Type: cross \nAbstract: Soft policies in reinforcement learning define policies as Boltzmann distributions over state-action value functions, providing a principled mechanism for balancing exploration and exploitation. However, realizing such soft policies in practice remains challenging. Existing approaches either depend on parametric policies with limited expressivity or employ diffusion-based policies whose intractable likelihoods hinder reliable entropy estimation ",
      "url": "https://arxiv.org/abs/2602.07873",
      "category": "cs.LG"
    },
    {
      "title": "Rethinking Latency Denial-of-Service: Attacking the LLM Serving Framework, Not the Model",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07878v1 Announce Type: cross \nAbstract: Large Language Models face an emerging and critical threat known as latency attacks. Because LLM inference is inherently expensive, even modest slowdowns can translate into substantial operating costs and severe availability risks. Recently, a growing body of research has focused on algorithmic complexity attacks by crafting inputs to trigger worst-case output lengths. However, we report a counter-intuitive finding that these algorithmic latency",
      "url": "https://arxiv.org/abs/2602.07878",
      "category": "cs.CR"
    },
    {
      "title": "Deep Variable-Length Feedback Codes",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07881v1 Announce Type: cross \nAbstract: Deep learning has enabled significant advances in feedback-based channel coding, yet existing learned schemes remain fundamentally limited: they employ fixed block lengths, suffer degraded performance at high rates, and cannot fully exploit the adaptive potential of feedback. This paper introduces Deep Variable-Length Feedback (DeepVLF) coding, a flexible coding framework that dynamically adjusts transmission length via learned feedback. We prop",
      "url": "https://arxiv.org/abs/2602.07881",
      "category": "cs.IT"
    },
    {
      "title": "GRAFT: Decoupling Ranking and Calibration for Survival Analysis",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07884v1 Announce Type: cross \nAbstract: Survival analysis is complicated by censored data, high-dimensional features, and non-linear interactions. Classical models are interpretable but restrictive, while deep learning models are flexible but often non-interpretable and sensitive to noise. We propose GRAFT (Gated Residual Accelerated Failure Time), a novel AFT model that decouples prognostic ranking from calibration. GRAFT's hybrid architecture combines a linear AFT model with a non-l",
      "url": "https://arxiv.org/abs/2602.07884",
      "category": "cs.LG"
    },
    {
      "title": "Rich-ARQ: From 1-bit Acknowledgment to Rich Neural Coded Feedback",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07886v1 Announce Type: cross \nAbstract: This paper reimagines the foundational feedback mechanism in wireless communication, transforming the prevailing 1-bit binary ACK/NACK with a high-dimensional, information-rich vector to transform passive acknowledgment into an active collaboration. We present Rich-ARQ, a paradigm that introduces neural-coded feedback for collaborative physical-layer channel coding between transmitter and receiver. To realize this vision in practice, we develop ",
      "url": "https://arxiv.org/abs/2602.07886",
      "category": "cs.IT"
    },
    {
      "title": "Scalable Adaptation of 3D Geometric Foundation Models via Weak Supervision from Internet Video",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07891v1 Announce Type: cross \nAbstract: Geometric foundation models show promise in 3D reconstruction, yet their progress is severely constrained by the scarcity of diverse, large-scale 3D annotations. While Internet videos offer virtually unlimited raw data, utilizing them as a scaling source for geometric learning is challenging due to the absence of ground-truth geometry and the presence of observational noise. To address this, we propose SAGE, a framework for Scalable Adaptation o",
      "url": "https://arxiv.org/abs/2602.07891",
      "category": "cs.CV"
    },
    {
      "title": "Rethinking the Value of Agent-Generated Tests for LLM-Based Software Engineering Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07900v1 Announce Type: cross \nAbstract: Large Language Model (LLM) code agents increasingly resolve repository-level issues by iteratively editing code, invoking tools, and validating candidate patches. In these workflows, agents often write tests on the fly, a paradigm adopted by many high-ranking agents on the SWE-bench leaderboard. However, we observe that GPT-5.2, which writes almost no new tests, can even achieve performance comparable to top-ranking agents. This raises the criti",
      "url": "https://arxiv.org/abs/2602.07900",
      "category": "cs.SE"
    },
    {
      "title": "Incremental Mapping with Measurement Synchronization & Compression",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07901v1 Announce Type: cross \nAbstract: Modern autonomous vehicles and robots utilize versatile sensors for localization and mapping. The fidelity of these maps is paramount, as an accurate environmental representation is a prerequisite for stable and precise localization. Factor graphs provide a powerful approach for sensor fusion, enabling the estimation of the maximum a posteriori solution. However, the discrete nature of graph-based representations, combined with asynchronous sens",
      "url": "https://arxiv.org/abs/2602.07901",
      "category": "cs.RO"
    },
    {
      "title": "Adaptive Acquisition Selection for Bayesian Optimization with Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07904v1 Announce Type: cross \nAbstract: Bayesian Optimization critically depends on the choice of acquisition function, but no single strategy is universally optimal; the best choice is non-stationary and problem-dependent. Existing adaptive portfolio methods often base their decisions on past function values while ignoring richer information like remaining budget or surrogate model characteristics. To address this, we introduce LMABO, a novel framework that casts a pre-trained Large ",
      "url": "https://arxiv.org/abs/2602.07904",
      "category": "cs.LG"
    },
    {
      "title": "AceGRPO: Adaptive Curriculum Enhanced Group Relative Policy Optimization for Autonomous Machine Learning Engineering",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07906v1 Announce Type: cross \nAbstract: Autonomous Machine Learning Engineering (MLE) requires agents to perform sustained, iterative optimization over long horizons. While recent LLM-based agents show promise, current prompt-based agents for MLE suffer from behavioral stagnation due to frozen parameters. Although Reinforcement Learning (RL) offers a remedy, applying it to MLE is hindered by prohibitive execution latency and inefficient data selection. Recognizing these challenges, we",
      "url": "https://arxiv.org/abs/2602.07906",
      "category": "cs.LG"
    },
    {
      "title": "CausalCompass: Evaluating the Robustness of Time-Series Causal Discovery in Misspecified Scenarios",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07915v1 Announce Type: cross \nAbstract: Causal discovery from time series is a fundamental task in machine learning. However, its widespread adoption is hindered by a reliance on untestable causal assumptions and by the lack of robustness-oriented evaluation in existing benchmarks. To address these challenges, we propose CausalCompass, a flexible and extensible benchmark suite designed to assess the robustness of time-series causal discovery (TSCD) methods under violations of modeling",
      "url": "https://arxiv.org/abs/2602.07915",
      "category": "cs.LG"
    },
    {
      "title": "Optimized Human-Robot Co-Dispatch Planning for Petro-Site Surveillance under Varying Criticalities",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07924v1 Announce Type: cross \nAbstract: Securing petroleum infrastructure requires balancing autonomous system efficiency with human judgment for threat escalation, a challenge unaddressed by classical facility location models assuming homogeneous resources. This paper formulates the Human-Robot Co-Dispatch Facility Location Problem (HRCD-FLP), a capacitated facility location variant incorporating tiered infrastructure criticality, human-robot supervision ratio constraints, and minimu",
      "url": "https://arxiv.org/abs/2602.07924",
      "category": "cs.RO"
    },
    {
      "title": "A Kinetic-Energy Perspective of Flow Matching",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07928v1 Announce Type: cross \nAbstract: Flow-based generative models can be viewed through a physics lens: sampling transports a particle from noise to data by integrating a time-varying velocity field, and each sample corresponds to a trajectory with its own dynamical effort. Motivated by classical mechanics, we introduce Kinetic Path Energy (KPE), an action-like, per-sample diagnostic that measures the accumulated kinetic effort along an Ordinary Differential Equation (ODE) trajecto",
      "url": "https://arxiv.org/abs/2602.07928",
      "category": "cs.LG"
    },
    {
      "title": "Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07954v1 Announce Type: cross \nAbstract: As Large Language Models (LLMs) become increasingly deployed in Polish language applications, the need for efficient and accurate content safety classifiers has become paramount. We present Bielik Guard, a family of compact Polish language safety classifiers comprising two model variants: a 0.1B parameter model based on MMLW-RoBERTa-base and a 0.5B parameter model based on PKOBP/polish-roberta-8k. Fine-tuned on a community-annotated dataset of 6",
      "url": "https://arxiv.org/abs/2602.07954",
      "category": "cs.CL"
    },
    {
      "title": "Accuracy-Delay Trade-Off in LLM Offloading via Token-Level Uncertainty",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07958v1 Announce Type: cross \nAbstract: Large language models (LLMs) offer significant potential for intelligent mobile services but are computationally intensive for resource-constrained devices. Mobile edge computing (MEC) allows such devices to offload inference tasks to edge servers (ESs), yet introduces latency due to communication and serverside queuing, especially in multi-user environments. In this work, we propose an uncertainty-aware offloading framework that dynamically dec",
      "url": "https://arxiv.org/abs/2602.07958",
      "category": "eess.SY"
    },
    {
      "title": "Lost in Translation? A Comparative Study on the Cross-Lingual Transfer of Composite Harms",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07963v1 Announce Type: cross \nAbstract: Most safety evaluations of large language models (LLMs) remain anchored in English. Translation is often used as a shortcut to probe multilingual behavior, but it rarely captures the full picture, especially when harmful intent or structure morphs across languages. Some types of harm survive translation almost intact, while others distort or disappear. To study this effect, we introduce CompositeHarm, a translation-based benchmark designed to ex",
      "url": "https://arxiv.org/abs/2602.07963",
      "category": "cs.CL"
    },
    {
      "title": "An Explainable Multi-Task Similarity Measure: Integrating Accumulated Local Effects and Weighted Fr\\'echet Distance",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07966v1 Announce Type: cross \nAbstract: In many machine learning contexts, tasks are often treated as interconnected components with the goal of leveraging knowledge transfer between them, which is the central aim of Multi-Task Learning (MTL). Consequently, this multi-task scenario requires addressing critical questions: which tasks are similar, and how and why do they exhibit similarity? In this work, we propose a multi-task similarity measure based on Explainable Artificial Intellig",
      "url": "https://arxiv.org/abs/2602.07966",
      "category": "cs.LG"
    },
    {
      "title": "Learning-guided Kansa collocation for forward and inverse PDEs beyond linearity",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07970v1 Announce Type: cross \nAbstract: Partial Differential Equations are precise in modelling the physical, biological and graphical phenomena. However, the numerical methods suffer from the curse of dimensionality, high computation costs and domain-specific discretization. We aim to explore pros and cons of different PDE solvers, and apply them to specific scientific simulation problems, including forwarding solution, inverse problems and equations discovery. In particular, we exte",
      "url": "https://arxiv.org/abs/2602.07970",
      "category": "cs.CE"
    },
    {
      "title": "MCIE: Multimodal LLM-Driven Complex Instruction Image Editing with Spatial Guidance",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.07993v1 Announce Type: cross \nAbstract: Recent advances in instruction-based image editing have shown remarkable progress. However, existing methods remain limited to relatively simple editing operations, hindering real-world applications that require complex and compositional instructions. In this work, we address these limitations from the perspectives of architectural design, data, and evaluation protocols. Specifically, we identify two key challenges in current models: insufficien",
      "url": "https://arxiv.org/abs/2602.07993",
      "category": "cs.CV"
    },
    {
      "title": "Don't Always Pick the Highest-Performing Model: An Information Theoretic View of LLM Ensemble Selection",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08003v1 Announce Type: cross \nAbstract: Large language models (LLMs) are often ensembled together to improve overall reliability and robustness, but in practice models are strongly correlated. This raises a fundamental question: which models should be selected when forming an LLM ensemble? We formulate budgeted ensemble selection as maximizing the mutual information between the true label and predictions of the selected models. Furthermore, to explain why performance can saturate even",
      "url": "https://arxiv.org/abs/2602.08003",
      "category": "cs.LG"
    },
    {
      "title": "DeltaKV: Residual-Based KV Cache Compression via Long-Range Similarity",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08005v1 Announce Type: cross \nAbstract: The deployment of efficient long-context LLMs in applications like autonomous agents, long-chain reasoning, and creative writing is fundamentally bottlenecked by the linear growth of KV cache memory. Existing compression and eviction methods often struggle to balance accuracy, compression ratio, and hardware efficiency. We propose DeltaKV, a residual-based KV cache compression framework motivated by two empirical findings: long-range inter-token",
      "url": "https://arxiv.org/abs/2602.08005",
      "category": "cs.CL"
    },
    {
      "title": "ForecastOcc: Vision-based Semantic Occupancy Forecasting",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08006v1 Announce Type: cross \nAbstract: Autonomous driving requires forecasting both geometry and semantics over time to effectively reason about future environment states. Existing vision-based occupancy forecasting methods focus on motion-related categories such as static and dynamic objects, while semantic information remains largely absent. Recent semantic occupancy forecasting approaches address this gap but rely on past occupancy predictions obtained from separate networks. This",
      "url": "https://arxiv.org/abs/2602.08006",
      "category": "cs.CV"
    },
    {
      "title": "From $O(mn)$ to $O(r^2)$: Two-Sided Low-Rank Communication for Adam in Distributed Training with Memory Efficiency",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08007v1 Announce Type: cross \nAbstract: As foundation models continue to scale, pretraining increasingly relies on data-parallel distributed optimization, making bandwidth-limited gradient synchronization a key bottleneck. Orthogonally, projection-based low-rank optimizers were mainly designed for memory efficiency, but remain suboptimal for communication-limited training: one-sided synchronization still transmits an $O(rn)$ object for an $m\\times n$ matrix gradient and refresh steps ",
      "url": "https://arxiv.org/abs/2602.08007",
      "category": "cs.LG"
    },
    {
      "title": "ICBAC: an Intelligent Contract-Based Access Control framework for supply chain management by integrating blockchain and federated learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08014v1 Announce Type: cross \nAbstract: This paper addresses the critical challenge of access control in modern supply chains, which operate across multiple independent and competing organizations. Existing access control is static and centralized, unable to adapt to insider threats or evolving contexts. Blockchain improves decentralization but lacks behavioral intelligence, while centralized machine learning for anomaly detection requires aggregating sensitive data, violating privacy",
      "url": "https://arxiv.org/abs/2602.08014",
      "category": "cs.CR"
    },
    {
      "title": "The Rise of Sparse Mixture-of-Experts: A Survey from Algorithmic Foundations to Decentralized Architectures and Vertical Domain Applications",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08019v1 Announce Type: cross \nAbstract: The sparse Mixture of Experts(MoE) architecture has evolved as a powerful approach for scaling deep learning models to more parameters with comparable computation cost. As an important branch of large language model(LLM), MoE model only activate a subset of experts based on a routing network. This sparse conditional computation mechanism significantly improves computational efficiency, paving a promising path for greater scalability and cost-eff",
      "url": "https://arxiv.org/abs/2602.08019",
      "category": "cs.LG"
    },
    {
      "title": "CyberExplorer: Benchmarking LLM Offensive Security Capabilities in a Real-World Attacking Simulation Environment",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08023v2 Announce Type: cross \nAbstract: Real-world offensive security operations are inherently open-ended: attackers explore unknown attack surfaces, revise hypotheses under uncertainty, and operate without guaranteed success. Existing LLM-based offensive agent evaluations rely on closed-world settings with predefined goals and binary success criteria. To address this gap, we introduce CyberExplorer, an evaluation suite with two core components: (1) an open-environment benchmark buil",
      "url": "https://arxiv.org/abs/2602.08023",
      "category": "cs.CR"
    },
    {
      "title": "FlashVID: Efficient Video Large Language Models via Training-free Tree-based Spatiotemporal Token Merging",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08024v1 Announce Type: cross \nAbstract: Although Video Large Language Models (VLLMs) have shown remarkable capabilities in video understanding, they are required to process high volumes of visual tokens, causing significant computational inefficiency. Existing VLLMs acceleration frameworks usually compress spatial and temporal redundancy independently, which overlooks the spatiotemporal relationships, thereby leading to suboptimal spatiotemporal compression. The highly correlated visu",
      "url": "https://arxiv.org/abs/2602.08024",
      "category": "cs.CV"
    },
    {
      "title": "MIND: Benchmarking Memory Consistency and Action Control in World Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08025v1 Announce Type: cross \nAbstract: World models aim to understand, remember, and predict dynamic visual environments, yet a unified benchmark for evaluating their fundamental abilities remains lacking. To address this gap, we introduce MIND, the first open-domain closed-loop revisited benchmark for evaluating Memory consIstency and action coNtrol in worlD models. MIND contains 250 high-quality videos at 1080p and 24 FPS, including 100 (first-person) + 100 (third-person) video cli",
      "url": "https://arxiv.org/abs/2602.08025",
      "category": "cs.CV"
    },
    {
      "title": "FIRE: Frobenius-Isometry Reinitialization for Balancing the Stability-Plasticity Tradeoff",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08040v1 Announce Type: cross \nAbstract: Deep neural networks trained on nonstationary data must balance stability (i.e., retaining prior knowledge) and plasticity (i.e., adapting to new tasks). Standard reinitialization methods, which reinitialize weights toward their original values, are widely used but difficult to tune: conservative reinitializations fail to restore plasticity, while aggressive ones erase useful knowledge. We propose FIRE, a principled reinitialization method that ",
      "url": "https://arxiv.org/abs/2602.08040",
      "category": "cs.LG"
    },
    {
      "title": "Implicit Strategic Optimization: Rethinking Long-Horizon Decision-Making in Adversarial Poker Environments",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08041v1 Announce Type: cross \nAbstract: Training large language model (LLM) agents for adversarial games is often driven by episodic objectives such as win rate. In long-horizon settings, however, payoffs are shaped by latent strategic externalities that evolve over time, so myopic optimization and variation-based regret analyses can become vacuous even when the dynamics are predictable. To solve this problem, we introduce Implicit Strategic Optimization (ISO), a prediction-aware fram",
      "url": "https://arxiv.org/abs/2602.08041",
      "category": "cs.LG"
    },
    {
      "title": "V-ABFT: Variance-Based Adaptive Threshold for Fault-Tolerant Matrix Multiplication in Mixed-Precision Deep Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08043v1 Announce Type: cross \nAbstract: Algorithm-Based Fault Tolerance (ABFT) is widely adopted to detect silent data corruptions (SDCs) in matrix multiplication, a cornerstone operation in deep learning systems. However, existing threshold determination methods face critical challenges: analytical bounds are overly conservative, while probabilistic approaches like A-ABFT yield thresholds $160$--$4200\\times$ larger than actual rounding errors. We present V-ABFT, a variance-based adap",
      "url": "https://arxiv.org/abs/2602.08043",
      "category": "cs.LG"
    },
    {
      "title": "Epigraph-Guided Flow Matching for Safe and Performant Offline Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08054v1 Announce Type: cross \nAbstract: Offline reinforcement learning (RL) provides a compelling paradigm for training autonomous systems without the risks of online exploration, particularly in safety-critical domains. However, jointly achieving strong safety and performance from fixed datasets remains challenging. Existing safe offline RL methods often rely on soft constraints that allow violations, introduce excessive conservatism, or struggle to balance safety, reward optimizatio",
      "url": "https://arxiv.org/abs/2602.08054",
      "category": "cs.LG"
    },
    {
      "title": "Weak to Strong: VLM-Based Pseudo-Labeling as a Weakly Supervised Training Strategy in Multimodal Video-based Hidden Emotion Understanding Tasks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08057v1 Announce Type: cross \nAbstract: To tackle the automatic recognition of \"concealed emotions\" in videos, this paper proposes a multimodal weak-supervision framework and achieves state-of-the-art results on the iMiGUE tennis-interview dataset. First, YOLO 11x detects and crops human portraits frame-by-frame, and DINOv2-Base extracts visual features from the cropped regions. Next, by integrating Chain-of-Thought and Reflection prompting (CoT + Reflection), Gemini 2.5 Pro automatic",
      "url": "https://arxiv.org/abs/2602.08057",
      "category": "cs.CV"
    },
    {
      "title": "Picasso: Holistic Scene Reconstruction with Physics-Constrained Sampling",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08058v1 Announce Type: cross \nAbstract: In the presence of occlusions and measurement noise, geometrically accurate scene reconstructions -- which fit the sensor data -- can still be physically incorrect. For instance, when estimating the poses and shapes of objects in the scene and importing the resulting estimates into a simulator, small errors might translate to implausible configurations including object interpenetration or unstable equilibrium. This makes it difficult to predict ",
      "url": "https://arxiv.org/abs/2602.08058",
      "category": "cs.CV"
    },
    {
      "title": "DICE: Disentangling Artist Style from Content via Contrastive Subspace Decomposition in Diffusion Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08059v1 Announce Type: cross \nAbstract: The recent proliferation of diffusion models has made style mimicry effortless, enabling users to imitate unique artistic styles without authorization. In deployed platforms, this raises copyright and intellectual-property risks and calls for reliable protection. However, existing countermeasures either require costly weight editing as new styles emerge or rely on an explicitly specified editing style, limiting their practicality for deployment-",
      "url": "https://arxiv.org/abs/2602.08059",
      "category": "cs.CV"
    },
    {
      "title": "SiameseNorm: Breaking the Barrier to Reconciling Pre/Post-Norm",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08064v1 Announce Type: cross \nAbstract: Modern Transformers predominantly adopt the Pre-Norm paradigm for its optimization stability, foregoing the superior potential of the unstable Post-Norm architecture. Prior attempts to combine their strengths typically lead to a stability-performance trade-off. We attribute this phenomenon to a structural incompatibility within a single-stream design: Any application of the Post-Norm operation inevitably obstructs the clean identity gradient pre",
      "url": "https://arxiv.org/abs/2602.08064",
      "category": "cs.LG"
    },
    {
      "title": "Multimodal normative modeling in Alzheimers Disease with introspective variational autoencoders",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08077v1 Announce Type: cross \nAbstract: Normative modeling learns a healthy reference distribution and quantifies subject-specific deviations to capture heterogeneous disease effects. In Alzheimers disease (AD), multimodal neuroimaging offers complementary signals but VAE-based normative models often (i) fit the healthy reference distribution imperfectly, inflating false positives, and (ii) use posterior aggregation (e.g., PoE/MoE) that can yield weak multimodal fusion in the shared l",
      "url": "https://arxiv.org/abs/2602.08077",
      "category": "cs.LG"
    },
    {
      "title": "Spectral Guardrails for Agents in the Wild: Detecting Tool Use Hallucinations via Attention Topology",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08082v1 Announce Type: cross \nAbstract: Deploying autonomous agents in the wild requires reliable safeguards against tool use failures. We propose a training free guardrail based on spectral analysis of attention topology that complements supervised approaches. On Llama 3.1 8B, our method achieves 97.7\\% recall with multi-feature detection and 86.1\\% recall with 81.0\\% precision for balanced deployment, without requiring any labeled training data. Most remarkably, we discover that sin",
      "url": "https://arxiv.org/abs/2602.08082",
      "category": "cs.LG"
    },
    {
      "title": "Large language models for spreading dynamics in complex systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08085v1 Announce Type: cross \nAbstract: Spreading dynamics is a central topic in the physics of complex systems and network science, providing a unified framework for understanding how information, behaviors, and diseases propagate through interactions among system units. In many propagation contexts, spreading processes are influenced by multiple interacting factors, such as information expression patterns, cultural contexts, living environments, cognitive preferences, and public pol",
      "url": "https://arxiv.org/abs/2602.08085",
      "category": "physics.soc-ph"
    },
    {
      "title": "Online Domain-aware LLM Decoding for Continual Domain Evolution",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08088v1 Announce Type: cross \nAbstract: LLMs are typically fine-tuned offline on domain-specific data, assuming a static domain. In practice, domain knowledge evolves continuously through new regulations, products, services, and interaction patterns. Retraining or fine-tuning LLMs for every new instance is computationally infeasible. Additionally, real-world environments also exhibit temporal dynamics with shifting data distributions. Disregarding this phenomenon, commonly referred to",
      "url": "https://arxiv.org/abs/2602.08088",
      "category": "cs.LG"
    },
    {
      "title": "VidVec: Unlocking Video MLLM Embeddings for Video-Text Retrieval",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08099v1 Announce Type: cross \nAbstract: Recent studies have adapted generative Multimodal Large Language Models (MLLMs) into embedding extractors for vision tasks, typically through fine-tuning to produce universal representations. However, their performance on video remains inferior to Video Foundation Models (VFMs). In this paper, we focus on leveraging MLLMs for video-text embedding and retrieval. We first conduct a systematic layer-wise analysis, showing that intermediate (pre-tra",
      "url": "https://arxiv.org/abs/2602.08099",
      "category": "cs.CV"
    },
    {
      "title": "Emergent Search and Backtracking in Latent Reasoning Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08100v1 Announce Type: cross \nAbstract: What happens when a language model thinks without words? Standard reasoning LLMs verbalize intermediate steps as chain-of-thought; latent reasoning transformers (LRTs) instead perform deliberation entirely in continuous hidden space. We investigate an LRT, decoding the model's evolving beliefs at every step on a multiple-choice QA benchmark. We find that the model spontaneously learns a structured search process in latent space. Deliberation fol",
      "url": "https://arxiv.org/abs/2602.08100",
      "category": "cs.CL"
    },
    {
      "title": "Constrained Pricing under Finite Mixtures of Logit",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08119v1 Announce Type: cross \nAbstract: The mixed logit model is a flexible and widely used demand model in pricing and revenue management. However, existing work on mixed-logit pricing largely focuses on unconstrained settings, limiting its applicability in practice where prices are subject to business or regulatory constraints. We study the constrained pricing problem under multinomial and mixed logit demand models. For the multinomial logit model, corresponding to a single customer",
      "url": "https://arxiv.org/abs/2602.08119",
      "category": "math.OC"
    },
    {
      "title": "Gender and Race Bias in Consumer Product Recommendations by Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08124v1 Announce Type: cross \nAbstract: Large Language Models are increasingly employed in generating consumer product recommendations, yet their potential for embedding and amplifying gender and race biases remains underexplored. This paper serves as one of the first attempts to examine these biases within LLM-generated recommendations. We leverage prompt engineering to elicit product suggestions from LLMs for various race and gender groups and employ three analytical methods-Marked ",
      "url": "https://arxiv.org/abs/2602.08124",
      "category": "cs.CL"
    },
    {
      "title": "Robustness of Vision Language Models Against Split-Image Harmful Input Attacks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08136v1 Announce Type: cross \nAbstract: Vision-Language Models (VLMs) are now a core part of modern AI. Recent work proposed several visual jailbreak attacks using single/ holistic images. However, contemporary VLMs demonstrate strong robustness against such attacks due to extensive safety alignment through preference optimization (e.g., RLHF). In this work, we identify a new vulnerability: while VLM pretraining and instruction tuning generalize well to split-image inputs, safety alig",
      "url": "https://arxiv.org/abs/2602.08136",
      "category": "cs.CV"
    },
    {
      "title": "Reliable and Responsible Foundation Models: A Comprehensive Survey",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08145v1 Announce Type: cross \nAbstract: Foundation models, including Large Language Models (LLMs), Multimodal Large Language Models (MLLMs), Image Generative Models (i.e, Text-to-Image Models and Image-Editing Models), and Video Generative Models, have become essential tools with broad applications across various domains such as law, medicine, education, finance, science, and beyond. As these models see increasing real-world deployment, ensuring their reliability and responsibility ha",
      "url": "https://arxiv.org/abs/2602.08145",
      "category": "cs.LG"
    },
    {
      "title": "DIAL-SUMMER: A Structured Evaluation Framework of Hierarchical Errors in Dialogue Summaries",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08149v1 Announce Type: cross \nAbstract: Dialogues are a predominant mode of communication for humans, and it is immensely helpful to have automatically generated summaries of them (e.g., to revise key points discussed in a meeting, to review conversations between customer agents and product users). Prior works on dialogue summary evaluation largely ignore the complexities specific to this task: (i) shift in structure, from multiple speakers discussing information in a scattered fashio",
      "url": "https://arxiv.org/abs/2602.08149",
      "category": "cs.CL"
    },
    {
      "title": "The Confidence Manifold: Geometric Structure of Correctness Representations in Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08159v1 Announce Type: cross \nAbstract: When a language model asserts that \"the capital of Australia is Sydney,\" does it know this is wrong? We characterize the geometry of correctness representations across 9 models from 5 architecture families. The structure is simple: the discriminative signal occupies 3-8 dimensions, performance degrades with additional dimensions, and no nonlinear classifier improves over linear separation. Centroid distance in the low-dimensional subspace matche",
      "url": "https://arxiv.org/abs/2602.08159",
      "category": "cs.LG"
    },
    {
      "title": "Self-Supervised Bootstrapping of Action-Predictive Embodied Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08167v1 Announce Type: cross \nAbstract: Embodied Chain-of-Thought (CoT) reasoning has significantly enhanced Vision-Language-Action (VLA) models, yet current methods rely on rigid templates to specify reasoning primitives (e.g., objects in the scene, high-level plans, structural affordances). These templates can force policies to process irrelevant information that distracts from critical action-prediction signals. This creates a bottleneck: without successful policies, we cannot veri",
      "url": "https://arxiv.org/abs/2602.08167",
      "category": "cs.RO"
    },
    {
      "title": "Nexus: Inferring Join Graphs from Metadata Alone via Iterative Low-Rank Matrix Completion",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08186v1 Announce Type: cross \nAbstract: Automatically inferring join relationships is a critical task for effective data discovery, integration, querying and reuse. However, accurately and efficiently identifying these relationships in large and complex schemas can be challenging, especially in enterprise settings where access to data values is constrained. In this paper, we introduce the problem of join graph inference when only metadata is available. We conduct an empirical study on",
      "url": "https://arxiv.org/abs/2602.08186",
      "category": "cs.DB"
    },
    {
      "title": "Large Language Models in Peer-Run Community Behavioral Health Services: Understanding Peer Specialists and Service Users' Perspectives on Opportunities, Risks, and Mitigation Strategies",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08187v1 Announce Type: cross \nAbstract: Peer-run organizations (PROs) provide critical, recovery-based behavioral health support rooted in lived experience. As large language models (LLMs) enter this domain, their scale, conversationality, and opacity introduce new challenges for situatedness, trust, and autonomy. Partnering with Collaborative Support Programs of New Jersey (CSPNJ), a statewide PRO in the Northeastern United States, we used comicboarding, a co-design method, to conduc",
      "url": "https://arxiv.org/abs/2602.08187",
      "category": "cs.HC"
    },
    {
      "title": "Dreaming in Code for Curriculum Learning in Open-Ended Worlds",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08194v1 Announce Type: cross \nAbstract: Open-ended learning frames intelligence as emerging from continual interaction with an ever-expanding space of environments. While recent advances have utilized foundation models to programmatically generate diverse environments, these approaches often focus on discovering isolated behaviors rather than orchestrating sustained progression. In complex open-ended worlds, the large combinatorial space of possible challenges makes it difficult for a",
      "url": "https://arxiv.org/abs/2602.08194",
      "category": "cs.LG"
    },
    {
      "title": "DrugR: Optimizing Molecular Drugs through LLM-based Explicit Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08213v1 Announce Type: cross \nAbstract: Molecule generation and optimization is a fundamental task in chemical domain. The rapid development of intelligent tools, especially large language models (LLMs) with powerful knowledge reserves and interactive capabilities, has provided new paradigms for it. Nevertheless, the intrinsic challenge for LLMs lies in the complex implicit relationship between molecular structure and pharmacological properties and the lack of corresponding labeled da",
      "url": "https://arxiv.org/abs/2602.08213",
      "category": "cs.LG"
    },
    {
      "title": "Sparsity-Aware Evolution for Model Merging",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08218v1 Announce Type: cross \nAbstract: We propose a sparsity-aware evolutionary (SAE) framework for model merging that involves iterative pruning-merging cycles to act as a novel mutation operator. We incorporate the sparsity constraints into the score function, which steers the evolutionary process to favor more sparse models, in addition to other conventional performance scores. Interestingly, the by-product of \\textit{competition} for sparsity introduces an extra local \\textit{att",
      "url": "https://arxiv.org/abs/2602.08218",
      "category": "cs.LG"
    },
    {
      "title": "CoRect: Context-Aware Logit Contrast for Hidden State Rectification to Resolve Knowledge Conflicts",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08221v1 Announce Type: cross \nAbstract: Retrieval-Augmented Generation (RAG) often struggles with knowledge conflicts, where model-internal parametric knowledge overrides retrieved evidence, leading to unfaithful outputs. Existing approaches are often limited, relying either on superficial decoding adjustments or weight editing that necessitates ground-truth targets. Through layer-wise analysis, we attribute this failure to a parametric suppression phenomenon: specifically, in deep la",
      "url": "https://arxiv.org/abs/2602.08221",
      "category": "cs.CL"
    },
    {
      "title": "Investigating Writing Professionals' Relationships with Generative AI: How Combined Perceptions of Rivalry and Collaboration Shape Work Practices and Outcomes",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08227v1 Announce Type: cross \nAbstract: This study investigates how professional writers' complex relationship with GenAI shapes their work practices and outcomes. Through a cross-sectional survey with writing professionals (n=403) in diverse roles, we show that collaboration and rivalry orientation are associated with differences in work practices and outcomes. Rivalry is primarily associated with relational crafting and skill maintenance. Collaboration is primarily associated with t",
      "url": "https://arxiv.org/abs/2602.08227",
      "category": "cs.HC"
    },
    {
      "title": "Generating Adversarial Events: A Motion-Aware Point Cloud Framework",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08230v1 Announce Type: cross \nAbstract: Event cameras have been widely adopted in safety-critical domains such as autonomous driving, robotics, and human-computer interaction. A pressing challenge arises from the vulnerability of deep neural networks to adversarial examples, which poses a significant threat to the reliability of event-based systems. Nevertheless, research into adversarial attacks on events is scarce. This is primarily due to the non-differentiable nature of mainstream",
      "url": "https://arxiv.org/abs/2602.08230",
      "category": "cs.CV"
    },
    {
      "title": "Tutti: Expressive Multi-Singer Synthesis via Structure-Level Timbre Control and Vocal Texture Modeling",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08233v1 Announce Type: cross \nAbstract: While existing Singing Voice Synthesis systems achieve high-fidelity solo performances, they are constrained by global timbre control, failing to address dynamic multi-singer arrangement and vocal texture within a single song. To address this, we propose Tutti, a unified framework designed for structured multi-singer generation. Specifically, we introduce a Structure-Aware Singer Prompt to enable flexible singer scheduling evolving with musical ",
      "url": "https://arxiv.org/abs/2602.08233",
      "category": "cs.SD"
    },
    {
      "title": "When Benign Inputs Lead to Severe Harms: Eliciting Unsafe Unintended Behaviors of Computer-Use Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08235v1 Announce Type: cross \nAbstract: Although computer-use agents (CUAs) hold significant potential to automate increasingly complex OS workflows, they can demonstrate unsafe unintended behaviors that deviate from expected outcomes even under benign input contexts. However, exploration of this risk remains largely anecdotal, lacking concrete characterization and automated methods to proactively surface long-tail unintended behaviors under realistic CUA scenarios. To fill this gap, ",
      "url": "https://arxiv.org/abs/2602.08235",
      "category": "cs.CL"
    },
    {
      "title": "When and How Much to Imagine: Adaptive Test-Time Scaling with World Models for Visual Spatial Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08236v1 Announce Type: cross \nAbstract: Despite rapid progress in Multimodal Large Language Models (MLLMs), visual spatial reasoning remains unreliable when correct answers depend on how a scene would appear under unseen or alternative viewpoints. Recent work addresses this by augmenting reasoning with world models for visual imagination, but questions such as when imagination is actually necessary, how much of it is beneficial, and when it becomes harmful, remain poorly understood. I",
      "url": "https://arxiv.org/abs/2602.08236",
      "category": "cs.CV"
    },
    {
      "title": "Linearization Explains Fine-Tuning in Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08239v1 Announce Type: cross \nAbstract: Parameter-Efficient Fine-Tuning (PEFT) is a popular class of techniques that strive to adapt large models in a scalable and resource-efficient manner. Yet, the mechanisms underlying their training performance and generalization remain underexplored. In this paper, we provide several insights into such fine-tuning through the lens of linearization. Fine-tuned models are often implicitly encouraged to remain close to the pretrained model. By makin",
      "url": "https://arxiv.org/abs/2602.08239",
      "category": "cs.LG"
    },
    {
      "title": "Learning in Context, Guided by Choice: A Reward-Free Paradigm for Reinforcement Learning with Transformers",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08244v1 Announce Type: cross \nAbstract: In-context reinforcement learning (ICRL) leverages the in-context learning capabilities of transformer models (TMs) to efficiently generalize to unseen sequential decision-making tasks without parameter updates. However, existing ICRL methods rely on explicit reward signals during pretraining, which limits their applicability when rewards are ambiguous, hard to specify, or costly to obtain. To overcome this limitation, we propose a new learning ",
      "url": "https://arxiv.org/abs/2602.08244",
      "category": "cs.LG"
    },
    {
      "title": "STEP: Warm-Started Visuomotor Policies with Spatiotemporal Consistency Prediction",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08245v1 Announce Type: cross \nAbstract: Diffusion policies have recently emerged as a powerful paradigm for visuomotor control in robotic manipulation due to their ability to model the distribution of action sequences and capture multimodality. However, iterative denoising leads to substantial inference latency, limiting control frequency in real-time closed-loop systems. Existing acceleration methods either reduce sampling steps, bypass diffusion through direct prediction, or reuse p",
      "url": "https://arxiv.org/abs/2602.08245",
      "category": "cs.RO"
    },
    {
      "title": "Inverting Data Transformations via Diffusion Sampling",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08267v1 Announce Type: cross \nAbstract: We study the problem of transformation inversion on general Lie groups: a datum is transformed by an unknown group element, and the goal is to recover an inverse transformation that maps it back to the original data distribution. Such unknown transformations arise widely in machine learning and scientific modeling, where they can significantly distort observations. We take a probabilistic view and model the posterior over transformations as a Bo",
      "url": "https://arxiv.org/abs/2602.08267",
      "category": "cs.LG"
    },
    {
      "title": "When Do Multi-Agent Systems Outperform? Analysing the Learning Efficiency of Agentic Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08272v1 Announce Type: cross \nAbstract: Reinforcement Learning (RL) has emerged as a crucial method for training or fine-tuning large language models (LLMs), enabling adaptive, task-specific optimizations through interactive feedback. Multi-Agent Reinforcement Learning (MARL), in particular, offers a promising avenue by decomposing complex tasks into specialized subtasks learned by distinct interacting agents, potentially enhancing the ability and efficiency of LLM systems. However, t",
      "url": "https://arxiv.org/abs/2602.08272",
      "category": "cs.LG"
    },
    {
      "title": "Language Modeling and Understanding Through Paraphrase Generation and Detection",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08274v1 Announce Type: cross \nAbstract: Language enables humans to share knowledge, reason about the world, and pass on strategies for survival and innovation across generations. At the heart of this process is not just the ability to communicate but also the remarkable flexibility in how we can express ourselves. We can express the same thoughts in virtually infinite ways using different words and structures - this ability to rephrase and reformulate expressions is known as paraphras",
      "url": "https://arxiv.org/abs/2602.08274",
      "category": "cs.CL"
    },
    {
      "title": "PISCO: Precise Video Instance Insertion with Sparse Control",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08277v1 Announce Type: cross \nAbstract: The landscape of AI video generation is undergoing a pivotal shift: moving beyond general generation - which relies on exhaustive prompt-engineering and \"cherry-picking\" - towards fine-grained, controllable generation and high-fidelity post-processing. In professional AI-assisted filmmaking, it is crucial to perform precise, targeted modifications. A cornerstone of this transition is video instance insertion, which requires inserting a specific ",
      "url": "https://arxiv.org/abs/2602.08277",
      "category": "cs.CV"
    },
    {
      "title": "Tighnari v2: Mitigating Label Noise and Distribution Shift in Multimodal Plant Distribution Prediction via Mixture of Experts and Weakly Supervised Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08282v1 Announce Type: cross \nAbstract: Large-scale, cross-species plant distribution prediction plays a crucial role in biodiversity conservation, yet modeling efforts in this area still face significant challenges due to the sparsity and bias of observational data. Presence-Absence (PA) data provide accurate and noise-free labels, but are costly to obtain and limited in quantity; Presence-Only (PO) data, by contrast, offer broad spatial coverage and rich spatiotemporal distribution,",
      "url": "https://arxiv.org/abs/2602.08282",
      "category": "cs.CV"
    },
    {
      "title": "Noise Stability of Transformer Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08287v1 Announce Type: cross \nAbstract: Understanding simplicity biases in deep learning offers a promising path toward developing reliable AI. A common metric for this, inspired by Boolean function analysis, is average sensitivity, which captures a model's robustness to single-token perturbations. We argue that average sensitivity has two key limitations: it lacks a natural generalization to real-valued domains and fails to explain the \"junta-like\" input dependence we empirically obs",
      "url": "https://arxiv.org/abs/2602.08287",
      "category": "cs.LG"
    },
    {
      "title": "Trust-Based Incentive Mechanisms in Semi-Decentralized Federated Learning Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08290v1 Announce Type: cross \nAbstract: In federated learning (FL), decentralized model training allows multi-ple participants to collaboratively improve a shared machine learning model without exchanging raw data. However, ensuring the integrity and reliability of the system is challenging due to the presence of potentially malicious or faulty nodes that can degrade the model's performance. This paper proposes a novel trust-based incentive mechanism designed to evaluate and reward th",
      "url": "https://arxiv.org/abs/2602.08290",
      "category": "cs.LG"
    },
    {
      "title": "Automatic Generation of Polynomial Symmetry Breaking Constraints",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08297v1 Announce Type: cross \nAbstract: Symmetry in integer programming causes redundant search and is often handled with symmetry breaking constraints that remove as many equivalent solutions as possible. We propose an algebraic method which allows to generate a random family of polynomial inequalities which can be used as symmetry breakers. The method requires as input an arbitrary base polynomial and a group of permutations which is specific to the integer program. The computations",
      "url": "https://arxiv.org/abs/2602.08297",
      "category": "cs.SC"
    },
    {
      "title": "Grokking in Linear Models for Logistic Regression",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08302v1 Announce Type: cross \nAbstract: Grokking, the phenomenon of delayed generalization, is often attributed to the depth and compositional structure of deep neural networks. We study grokking in one of the simplest possible settings: the learning of a linear model with logistic loss for binary classification on data that are linearly (and max margin) separable about the origin. We investigate three testing regimes: (1) test data drawn from the same distribution as the training dat",
      "url": "https://arxiv.org/abs/2602.08302",
      "category": "cs.LG"
    },
    {
      "title": "SWE Context Bench: A Benchmark for Context Learning in Coding",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08316v1 Announce Type: cross \nAbstract: Large language models are increasingly used as programming agents for repository level software engineering tasks. While recent benchmarks evaluate correctness in realistic codebases, they largely treat tasks as independent and do not assess whether agents can reuse experience across related problems. As a result, the ability of agents to accumulate, retrieve, and apply prior experience, as well as the efficiency gains from such reuse, remains d",
      "url": "https://arxiv.org/abs/2602.08316",
      "category": "cs.SE"
    },
    {
      "title": "Near-Oracle KV Selection via Pre-hoc Sparsity for Long-Context Inference",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08329v1 Announce Type: cross \nAbstract: A core bottleneck in large language model (LLM) inference is the cost of attending over the ever-growing key-value (KV) cache. Although near-oracle top-k KV selection can preserve the quality of dense attention while sharply reducing computation and bandwidth, existing sparse methods generally rely on posterior heuristics, i.e., selectors conditioned on observed attention or proxy scores. Such conditioning introduces posterior bias: it tends to ",
      "url": "https://arxiv.org/abs/2602.08329",
      "category": "cs.LG"
    },
    {
      "title": "Latent Reasoning with Supervised Thinking States",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08332v1 Announce Type: cross \nAbstract: Reasoning with a chain-of-thought (CoT) enables Large Language Models (LLMs) to solve complex tasks but incurs significant inference costs due to the generation of long rationales. We propose Thinking States, a method that performs reasoning {\\em while} the input is processing. Specifically, Thinking States generates sequences of thinking tokens every few input tokens, transforms the thoughts back into embedding space, and adds them to the follo",
      "url": "https://arxiv.org/abs/2602.08332",
      "category": "cs.CL"
    },
    {
      "title": "Regime Change Hypothesis: Foundations for Decoupled Dynamics in Neural Network Training",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08333v1 Announce Type: cross \nAbstract: Despite the empirical success of DNN, their internal training dynamics remain difficult to characterize. In ReLU-based models, the activation pattern induced by a given input determines the piecewise-linear region in which the network behaves affinely. Motivated by this geometry, we investigate whether training exhibits a two-timescale behavior: an early stage with substantial changes in activation patterns and a later stage where weight updates",
      "url": "https://arxiv.org/abs/2602.08333",
      "category": "cs.LG"
    },
    {
      "title": "UrbanGraphEmbeddings: Learning and Evaluating Spatially Grounded Multimodal Embeddings for Urban Science",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08342v1 Announce Type: cross \nAbstract: Learning transferable multimodal embeddings for urban environments is challenging because urban understanding is inherently spatial, yet existing datasets and benchmarks lack explicit alignment between street-view images and urban structure. We introduce UGData, a spatially grounded dataset that anchors street-view images to structured spatial graphs and provides graph-aligned supervision via spatial reasoning paths and spatial context captions,",
      "url": "https://arxiv.org/abs/2602.08342",
      "category": "cs.CV"
    },
    {
      "title": "ManifoldKV: Training-Free KV Cache Compression via Euclidean Outlier Detection",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08343v1 Announce Type: cross \nAbstract: Long-context inference is constrained by KV-cache memory, which grows linearly with sequence length; KV-cache compression therefore hinges on reliably selecting which past tokens to retain. Most geometry-based eviction methods score keys by cosine similarity to a global centroid, but cosine is scale-invariant and can discard magnitude cues that distinguish semantically salient tokens. We propose ManifoldKV, a training-free scorer that ranks toke",
      "url": "https://arxiv.org/abs/2602.08343",
      "category": "cs.LG"
    },
    {
      "title": "The Chicken and Egg Dilemma: Co-optimizing Data and Model Configurations for LLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08351v1 Announce Type: cross \nAbstract: Co-optimizing data and model configurations for training LLMs presents a classic chicken-and-egg dilemma: The best training data configuration (e.g., data mixture) for a downstream task depends on the chosen model configuration (e.g., model architecture), and vice versa. However, jointly optimizing both data and model configurations is often deemed intractable, and existing methods focus on either data or model optimization without considering t",
      "url": "https://arxiv.org/abs/2602.08351",
      "category": "cs.LG"
    },
    {
      "title": "Roadmap to Quantum Aesthetics",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08363v1 Announce Type: cross \nAbstract: Quantum mechanics occupies a central position in contemporary science while remaining largely inaccessible to direct sensory experience. This paper proposes a roadmap to quantum aesthetics that examines how quantum concepts become aesthetic phenomena through artistic mediation rather than direct representation. Two complementary and orthogonal approaches are articulated. The first, a pioneering top-down approach, employs text-prompt-based genera",
      "url": "https://arxiv.org/abs/2602.08363",
      "category": "physics.pop-ph"
    },
    {
      "title": "Learning Human-Like Badminton Skills for Humanoid Robots",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08370v1 Announce Type: cross \nAbstract: Realizing versatile and human-like performance in high-demand sports like badminton remains a formidable challenge for humanoid robotics. Unlike standard locomotion or static manipulation, this task demands a seamless integration of explosive whole-body coordination and precise, timing-critical interception. While recent advances have achieved lifelike motion mimicry, bridging the gap between kinematic imitation and functional, physics-aware str",
      "url": "https://arxiv.org/abs/2602.08370",
      "category": "cs.RO"
    },
    {
      "title": "Reinforcement Learning with Backtracking Feedback",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08377v1 Announce Type: cross \nAbstract: Addressing the critical need for robust safety in Large Language Models (LLMs), particularly against adversarial attacks and in-distribution errors, we introduce Reinforcement Learning with Backtracking Feedback (RLBF). This framework advances upon prior methods, such as BSAFE, by primarily leveraging a Reinforcement Learning (RL) stage where models learn to dynamically correct their own generation errors. Through RL with critic feedback on the ",
      "url": "https://arxiv.org/abs/2602.08377",
      "category": "cs.LG"
    },
    {
      "title": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08382v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) face significant challenges in long-context processing, including quadratic computational costs, information forgetting, and the context fragmentation inherent in retrieval-augmented generation (RAG). We propose a cognitively inspired framework for efficient long-context inference based on chunk-wise compression and selective memory recall, rather than processing all raw tokens. The framework segments long inputs int",
      "url": "https://arxiv.org/abs/2602.08382",
      "category": "cs.CL"
    },
    {
      "title": "Altruism and Fair Objective in Mixed-Motive Markov games",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08389v1 Announce Type: cross \nAbstract: Cooperation is fundamental for society's viability, as it enables the emergence of structure within heterogeneous groups that seek collective well-being. However, individuals are inclined to defect in order to benefit from the group's cooperation without contributing the associated costs, thus leading to unfair situations. In game theory, social dilemmas entail this dichotomy between individual interest and collective outcome. The most dominant ",
      "url": "https://arxiv.org/abs/2602.08389",
      "category": "cs.MA"
    },
    {
      "title": "BiManiBench: A Hierarchical Benchmark for Evaluating Bimanual Coordination of Multimodal Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08392v1 Announce Type: cross \nAbstract: Multimodal Large Language Models (MLLMs) have significantly advanced embodied AI, and using them to benchmark robotic intelligence has become a pivotal trend. However, existing frameworks remain predominantly confined to single-arm manipulation, failing to capture the spatio-temporal coordination required for bimanual tasks like lifting a heavy pot. To address this, we introduce BiManiBench, a hierarchical benchmark evaluating MLLMs across three",
      "url": "https://arxiv.org/abs/2602.08392",
      "category": "cs.RO"
    },
    {
      "title": "Intelligent support for Human Oversight: Integrating Reinforcement Learning with Gaze Simulation to Personalize Highlighting",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08403v1 Announce Type: cross \nAbstract: Interfaces for human oversight must effectively support users' situation awareness under time-critical conditions. We explore reinforcement learning (RL)-based UI adaptation to personalize alerting strategies that balance the benefits of highlighting critical events against the cognitive costs of interruptions. To enable learning without real-world deployment, we integrate models of users' gaze behavior to simulate attentional dynamics during mo",
      "url": "https://arxiv.org/abs/2602.08403",
      "category": "cs.HC"
    },
    {
      "title": "Optimizing Spectral Prediction in MXene-Based Metasurfaces Through Multi-Channel Spectral Refinement and Savitzky-Golay Smoothing",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08406v1 Announce Type: cross \nAbstract: The prediction of electromagnetic spectra for MXene-based solar absorbers is a computationally intensive task, traditionally addressed using full-wave solvers. This study introduces an efficient deep learning framework incorporating transfer learning, multi-channel spectral refinement (MCSR), and Savitzky-Golay smoothing to accelerate and enhance spectral prediction accuracy. The proposed architecture leverages a pretrained MobileNetV2 model, fi",
      "url": "https://arxiv.org/abs/2602.08406",
      "category": "physics.optics"
    },
    {
      "title": "LLMs + Security = Trouble",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08422v1 Announce Type: cross \nAbstract: We argue that when it comes to producing secure code with AI, the prevailing \"fighting fire with fire\" approach -- using probabilistic AI-based checkers or attackers to secure probabilistically generated code -- fails to address the long tail of security bugs. As a result, systems may remain exposed to zero-day vulnerabilities that can be discovered by better-resourced or more persistent adversaries.\n  While neurosymbolic approaches that combine",
      "url": "https://arxiv.org/abs/2602.08422",
      "category": "cs.CR"
    },
    {
      "title": "Prism: Spectral-Aware Block-Sparse Attention",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08426v1 Announce Type: cross \nAbstract: Block-sparse attention is promising for accelerating long-context LLM pre-filling, yet identifying relevant blocks efficiently remains a bottleneck. Existing methods typically employ coarse-grained attention as a proxy for block importance estimation, but often resort to expensive token-level searching or scoring, resulting in significant selection overhead. In this work, we trace the inaccuracy of standard coarse-grained attention via mean pool",
      "url": "https://arxiv.org/abs/2602.08426",
      "category": "cs.CL"
    },
    {
      "title": "Vista: Scene-Aware Optimization for Streaming Video Question Answering under Post-Hoc Queries",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08448v1 Announce Type: cross \nAbstract: Streaming video question answering (Streaming Video QA) poses distinct challenges for multimodal large language models (MLLMs), as video frames arrive sequentially and user queries can be issued at arbitrary time points. Existing solutions relying on fixed-size memory or naive compression often suffer from context loss or memory overflow, limiting their effectiveness in long-form, real-time scenarios. We present Vista, a novel framework for scen",
      "url": "https://arxiv.org/abs/2602.08448",
      "category": "cs.CV"
    },
    {
      "title": "Decentralized Spatial Reuse Optimization in Wi-Fi: An Internal Regret Minimization Approach",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08456v1 Announce Type: cross \nAbstract: Spatial Reuse (SR) is a cost-effective technique for improving spectral efficiency in dense IEEE 802.11 deployments by enabling simultaneous transmissions. However, the decentralized optimization of SR parameters -- transmission power and Carrier Sensing Threshold (CST) -- across different Basic Service Sets (BSSs) is challenging due to the lack of global state information. In addition, the concurrent operation of multiple agents creates a highl",
      "url": "https://arxiv.org/abs/2602.08456",
      "category": "cs.NI"
    },
    {
      "title": "Gesture Matters: Pedestrian Gesture Recognition for AVs Through Skeleton Pose Evaluation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08479v1 Announce Type: cross \nAbstract: Gestures are a key component of non-verbal communication in traffic, often helping pedestrian-to-driver interactions when formal traffic rules may be insufficient. This problem becomes more apparent when autonomous vehicles (AVs) struggle to interpret such gestures. In this study, we present a gesture classification framework using 2D pose estimation applied to real-world video sequences from the WIVW dataset. We categorise gestures into four pr",
      "url": "https://arxiv.org/abs/2602.08479",
      "category": "cs.CV"
    },
    {
      "title": "CLEAR: A Knowledge-Centric Vessel Trajectory Analysis Platform",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08482v1 Announce Type: cross \nAbstract: Vessel trajectory data from the Automatic Identification System (AIS) is used widely in maritime analytics. Yet, analysis is difficult for non-expert users due to the incompleteness and complexity of AIS data. We present CLEAR, a knowledge-centric vessel trajectory analysis platform that aims to overcome these barriers. By leveraging the reasoning and generative capabilities of Large Language Models (LLMs), CLEAR transforms raw AIS data into com",
      "url": "https://arxiv.org/abs/2602.08482",
      "category": "cs.DB"
    },
    {
      "title": "Contextual Rollout Bandits for Reinforcement Learning with Verifiable Rewards",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08499v1 Announce Type: cross \nAbstract: Reinforcement Learning with Verifiable Rewards (RLVR) is an effective paradigm for improving the reasoning capabilities of large language models. However, existing RLVR methods utilize rollouts in an indiscriminate and short-horizon manner: responses of heterogeneous quality within each prompt are treated uniformly, and historical rollouts are discarded after a single use. This leads to noisy supervision, poor sample efficiency, and suboptimal p",
      "url": "https://arxiv.org/abs/2602.08499",
      "category": "cs.LG"
    },
    {
      "title": "A General Theory of Proportionality with Additive Utilities",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08504v1 Announce Type: cross \nAbstract: We consider a model where a subset of candidates must be selected based on voter preferences, subject to general constraints that specify which subsets are feasible. This model generalizes committee elections with diversity constraints, participatory budgeting (including constraints specifying how funds must be allocated to projects from different pools), and public decision-making. Axioms of proportionality have recently been defined for this g",
      "url": "https://arxiv.org/abs/2602.08504",
      "category": "cs.GT"
    },
    {
      "title": "GISA: A Benchmark for General Information-Seeking Assistant",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08543v1 Announce Type: cross \nAbstract: The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate such agents. However, existing benchmarks often construct queries backward from answers, producing unnatural tasks misaligned with real-world needs. Moreover, these benchmarks tend to focus on either locat",
      "url": "https://arxiv.org/abs/2602.08543",
      "category": "cs.CL"
    },
    {
      "title": "GOT-Edit: Geometry-Aware Generic Object Tracking via Online Model Editing",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08550v1 Announce Type: cross \nAbstract: Human perception for effective object tracking in a 2D video stream arises from the implicit use of prior 3D knowledge combined with semantic reasoning. In contrast, most generic object tracking (GOT) methods primarily rely on 2D features of the target and its surroundings while neglecting 3D geometric cues, which makes them susceptible to partial occlusion, distractors, and variations in geometry and appearance. To address this limitation, we i",
      "url": "https://arxiv.org/abs/2602.08550",
      "category": "cs.CV"
    },
    {
      "title": "Stateless Yet Not Forgetful: Implicit Memory as a Hidden Channel in LLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08563v1 Announce Type: cross \nAbstract: Large language models (LLMs) are commonly treated as stateless: once an interaction ends, no information is assumed to persist unless it is explicitly stored and re-supplied. We challenge this assumption by introducing implicit memory-the ability of a model to carry state across otherwise independent interactions by encoding information in its own outputs and later recovering it when those outputs are reintroduced as input. This mechanism does n",
      "url": "https://arxiv.org/abs/2602.08563",
      "category": "cs.LG"
    },
    {
      "title": "Agent-Supported Foresight for AI Systemic Risks: AI Agents for Breadth, Experts for Judgment",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08565v1 Announce Type: cross \nAbstract: AI impact assessments often stress near-term risks because human judgment degrades over longer horizons, exemplifying the Collingridge dilemma: foresight is most needed when knowledge is scarcest. To address long-term systemic risks, we introduce a scalable approach that simulates in-silico agents using the strategic foresight method of the Futures Wheel. We applied it to four AI uses spanning Technology Readiness Levels (TRLs): Chatbot Companio",
      "url": "https://arxiv.org/abs/2602.08565",
      "category": "cs.HC"
    },
    {
      "title": "Predicting Future Utility: Global Combinatorial Optimization for Task-Agnostic KV Cache Eviction",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08585v1 Announce Type: cross \nAbstract: Given the quadratic complexity of attention, KV cache eviction is vital to accelerate model inference. Current KV cache eviction methods typically rely on instantaneous heuristic metrics, implicitly assuming that score magnitudes are consistent proxies for importance across all heads. However, this overlooks the heterogeneity in predictive fidelity across attention heads. While certain heads prioritize the instantaneous contribution of tokens, o",
      "url": "https://arxiv.org/abs/2602.08585",
      "category": "cs.LG"
    },
    {
      "title": "Kissan-Dost: Bridging the Last Mile in Smallholder Precision Agriculture with Conversational IoT",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08593v1 Announce Type: cross \nAbstract: We present Kissan-Dost, a multilingual, sensor-grounded conversational system that turns live on-farm measurements and weather into plain-language guidance delivered over WhatsApp text or voice. The system couples commodity soil and climate sensors with retrieval-augmented generation, then enforces grounding, traceability, and proactive alerts through a modular pipeline. In a 90-day, two-site pilot with five participants, we ran three phases (ba",
      "url": "https://arxiv.org/abs/2602.08593",
      "category": "cs.HC"
    },
    {
      "title": "Breaking the Grid: Distance-Guided Reinforcement Learning in Large Discrete and Hybrid Action Spaces",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08616v1 Announce Type: cross \nAbstract: Reinforcement Learning is increasingly applied to logistics, scheduling, and recommender systems, but standard algorithms struggle with the curse of dimensionality in such large discrete action spaces. Existing algorithms typically rely on restrictive grid-based structures or computationally expensive nearest-neighbor searches, limiting their effectiveness in high-dimensional or irregularly structured domains. We propose Distance-Guided Reinforc",
      "url": "https://arxiv.org/abs/2602.08616",
      "category": "cs.LG"
    },
    {
      "title": "Enhancing Genetic Algorithms with Graph Neural Networks: A Timetabling Case Study",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08619v1 Announce Type: cross \nAbstract: This paper investigates the impact of hybridizing a multi-modal Genetic Algorithm with a Graph Neural Network for timetabling optimization. The Graph Neural Network is designed to encapsulate general domain knowledge to improve schedule quality, while the Genetic Algorithm explores different regions of the search space and integrates the deep learning model as an enhancement operator to guide the solution search towards optimality. Initially, bo",
      "url": "https://arxiv.org/abs/2602.08619",
      "category": "cs.NE"
    },
    {
      "title": "Sparse Models, Sparse Safety: Unsafe Routes in Mixture-of-Experts LLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08621v1 Announce Type: cross \nAbstract: By introducing routers to selectively activate experts in Transformer layers, the mixture-of-experts (MoE) architecture significantly reduces computational costs in large language models (LLMs) while maintaining competitive performance, especially for models with massive parameters. However, prior work has largely focused on utility and efficiency, leaving the safety risks associated with this sparse architecture underexplored. In this work, we ",
      "url": "https://arxiv.org/abs/2602.08621",
      "category": "cs.LG"
    },
    {
      "title": "CauScale: Neural Causal Discovery at Scale",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08629v1 Announce Type: cross \nAbstract: Causal discovery is essential for advancing data-driven fields such as scientific AI and data analysis, yet existing approaches face significant time- and space-efficiency bottlenecks when scaling to large graphs. To address this challenge, we present CauScale, a neural architecture designed for efficient causal discovery that scales inference to graphs with up to 1000 nodes. CauScale improves time efficiency via a reduction unit that compresses",
      "url": "https://arxiv.org/abs/2602.08629",
      "category": "cs.LG"
    },
    {
      "title": "We Should Separate Memorization from Copyright",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08632v1 Announce Type: cross \nAbstract: The widespread use of foundation models has introduced a new risk factor of copyright issue. This issue is leading to an active, lively and on-going debate amongst the data-science community as well as amongst legal scholars. Where claims and results across both sides are often interpreted in different ways and leading to different implications. Our position is that much of the technical literature relies on traditional reconstruction techniques",
      "url": "https://arxiv.org/abs/2602.08632",
      "category": "cs.CY"
    },
    {
      "title": "LEFT: Learnable Fusion of Tri-view Tokens for Unsupervised Time Series Anomaly Detection",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08638v1 Announce Type: cross \nAbstract: As a fundamental data mining task, unsupervised time series anomaly detection (TSAD) aims to build a model for identifying abnormal timestamps without assuming the availability of annotations. A key challenge in unsupervised TSAD is that many anomalies are too subtle to exhibit detectable deviation in any single view (e.g., time domain), and instead manifest as inconsistencies across multiple views like time, frequency, and a mixture of resoluti",
      "url": "https://arxiv.org/abs/2602.08638",
      "category": "cs.LG"
    },
    {
      "title": "Equalized Generative Treatment: Matching f-divergences for Fairness in Generative Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08660v1 Announce Type: cross \nAbstract: Fairness is a crucial concern for generative models, which not only reflect but can also amplify societal and cultural biases. Existing fairness notions for generative models are largely adapted from classification and focus on balancing the probability of generating samples from each sensitive group. We show that such criteria are brittle, as they can be met even when different sensitive groups are modeled with widely varying quality. To addres",
      "url": "https://arxiv.org/abs/2602.08660",
      "category": "cs.LG"
    },
    {
      "title": "6G-Bench: An Open Benchmark for Semantic Communication and Network-Level Reasoning with Foundation Models in AI-Native 6G Networks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08675v1 Announce Type: cross \nAbstract: This paper introduces 6G-Bench, an open benchmark for evaluating semantic communication and network-level reasoning in AI-native 6G networks. 6G-Bench defines a taxonomy of 30 decision-making tasks (T1--T30) extracted from ongoing 6G and AI-agent standardization activities in 3GPP, IETF, ETSI, ITU-T, and the O-RAN Alliance, and organizes them into five standardization-aligned capability categories. Starting from 113,475 scenarios, we generate a ",
      "url": "https://arxiv.org/abs/2602.08675",
      "category": "cs.NI"
    },
    {
      "title": "LLaDA2.1: Speeding Up Text Diffusion via Token Editing",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08676v2 Announce Type: cross \nAbstract: While LLaDA2.0 showcased the scaling potential of 100B-level block-diffusion models and their inherent parallelization, the delicate equilibrium between decoding speed and generation quality has remained an elusive frontier. Today, we unveil LLaDA2.1, a paradigm shift designed to transcend this trade-off. By seamlessly weaving Token-to-Token (T2T) editing into the conventional Mask-to-Token (M2T) scheme, we introduce a joint, configurable thresh",
      "url": "https://arxiv.org/abs/2602.08676",
      "category": "cs.LG"
    },
    {
      "title": "CompilerKV: Risk-Adaptive KV Compression via Offline Experience Compilation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08686v1 Announce Type: cross \nAbstract: Large Language Models (LLMs) in long-context scenarios are severely constrained by the linear growth of Key-Value (KV) cache memory. Existing KV compression methods rely either on static thresholds and attention-only heuristics or on coarse memory budget allocation. Under tight memory budgets, these methods overlook two key factors: prompt-dependent variation in compression risk and functional heterogeneity across attention heads, which destabil",
      "url": "https://arxiv.org/abs/2602.08686",
      "category": "cs.LG"
    },
    {
      "title": "PBLean: Pseudo-Boolean Proof Certificates for Lean 4",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08692v1 Announce Type: cross \nAbstract: We present PBLean, a method for importing VeriPB pseudo-Boolean (PB) proof certificates into Lean 4. Key to our approach is reflection: a Boolean checker function whose soundness is fully proved in Lean and executed as compiled native code. Our method scales to proofs with tens of thousands of steps that would exhaust memory under explicit proof-term construction. Our checker supports all VeriPB kernel rules, including cutting-plane derivations ",
      "url": "https://arxiv.org/abs/2602.08692",
      "category": "cs.LO"
    },
    {
      "title": "Technosocial risks of ideal emotion recognition technologies: A defense of the (social) value of emotional expressions",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08706v1 Announce Type: cross \nAbstract: The prospect of AI systems that I call ideal emotion recognition technologies (ERTs) is often defended on the assumption that social life would benefit from increased affective transparency. This paper challenges that assumption by examining the technosocial risks posed by ideal ERTs, understood as multimodal systems capable of reliably inferring inner affective states in real time. Drawing on philosophical accounts of emotional expression and s",
      "url": "https://arxiv.org/abs/2602.08706",
      "category": "cs.HC"
    },
    {
      "title": "Zero-shot System for Automatic Body Region Detection for Volumetric CT and MR Images",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08717v1 Announce Type: cross \nAbstract: Reliable identification of anatomical body regions is a prerequisite for many automated medical imaging workflows, yet existing solutions remain heavily dependent on unreliable DICOM metadata. Current solutions mainly use supervised learning, which limits their applicability in many real-world scenarios. In this work, we investigate whether body region detection in volumetric CT and MR images can be achieved in a fully zero-shot manner by using ",
      "url": "https://arxiv.org/abs/2602.08717",
      "category": "cs.CV"
    },
    {
      "title": "QUOKA: Query-Oriented KV Selection For Efficient LLM Prefill",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08722v1 Announce Type: cross \nAbstract: We present QUOKA: Query-oriented KV selection for efficient attention, a training-free and hardware agnostic sparse attention algorithm for accelerating transformer inference under chunked prefill. While many queries focus on a smaller group of keys in the attention operator, we observe that queries with low cosine similarity with respect to the mean query interact more strongly with more keys and have the greatest contribution to final attentio",
      "url": "https://arxiv.org/abs/2602.08722",
      "category": "cs.LG"
    },
    {
      "title": "Artifact Reduction in Undersampled 3D Cone-Beam CTs using a Hybrid 2D-3D CNN Framework",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08727v1 Announce Type: cross \nAbstract: Undersampled CT volumes minimize acquisition time and radiation exposure but introduce artifacts degrading image quality and diagnostic utility. Reducing these artifacts is critical for high-quality imaging. We propose a computationally efficient hybrid deep-learning framework that combines the strengths of 2D and 3D models. First, a 2D U-Net operates on individual slices of undersampled CT volumes to extract feature maps. These slice-wise featu",
      "url": "https://arxiv.org/abs/2602.08727",
      "category": "cs.CV"
    },
    {
      "title": "On the Expressive Power of GNNs for Boolean Satisfiability",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08745v1 Announce Type: cross \nAbstract: Machine learning approaches to solving Boolean Satisfiability (SAT) aim to replace handcrafted heuristics with learning-based models. Graph Neural Networks have emerged as the main architecture for SAT solving, due to the natural graph representation of Boolean formulas. We analyze the expressive power of GNNs for SAT solving through the lens of the Weisfeiler-Leman (WL) test. As our main result, we prove that the full WL hierarchy cannot, in ge",
      "url": "https://arxiv.org/abs/2602.08745",
      "category": "cs.LG"
    },
    {
      "title": "Efficient Brain Extraction of MRI Scans with Mild to Moderate Neuropathology",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08764v1 Announce Type: cross \nAbstract: Skull stripping magnetic resonance images (MRI) of the human brain is an important process in many image processing techniques, such as automatic segmentation of brain structures. Numerous methods have been developed to perform this task, however, they often fail in the presence of neuropathology and can be inconsistent in defining the boundary of the brain mask. Here, we propose a novel approach to skull strip T1-weighted images in a robust and",
      "url": "https://arxiv.org/abs/2602.08764",
      "category": "eess.IV"
    },
    {
      "title": "Taming Scylla: Understanding the multi-headed agentic daemon of the coding seas",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08765v1 Announce Type: cross \nAbstract: LLM-based tools are automating more software development tasks at a rapid pace, but there is no rigorous way to evaluate how different architectural choices -- prompts, skills, tools, multi-agent setups -- materially affect both capability and cost. This paper introduces Scylla, an evaluation framework for benchmarking agentic coding tools through structured ablation studies that uses seven testing tiers (T0-T6) progressively adding complexity t",
      "url": "https://arxiv.org/abs/2602.08765",
      "category": "cs.SE"
    },
    {
      "title": "FreqLens: Interpretable Frequency Attribution for Time Series Forecasting",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08768v1 Announce Type: cross \nAbstract: Time series forecasting models often lack interpretability, limiting their adoption in domains requiring explainable predictions. We propose \\textsc{FreqLens}, an interpretable forecasting framework that discovers and attributes predictions to learnable frequency components. \\textsc{FreqLens} introduces two key innovations: (1) \\emph{learnable frequency discovery} -- frequency bases are parameterized via sigmoid mapping and learned from data wit",
      "url": "https://arxiv.org/abs/2602.08768",
      "category": "cs.LG"
    },
    {
      "title": "Default Machine Learning Hyperparameters Do Not Provide Informative Initialization for Bayesian Optimization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08774v1 Announce Type: cross \nAbstract: Bayesian Optimization (BO) is a standard tool for hyperparameter tuning thanks to its sample efficiency on expensive black-box functions. While most BO pipelines begin with uniform random initialization, default hyperparameter values shipped with popular ML libraries such as scikit-learn encode implicit expert knowledge and could serve as informative starting points that accelerate convergence. This hypothesis, despite its intuitive appeal, has ",
      "url": "https://arxiv.org/abs/2602.08774",
      "category": "cs.LG"
    },
    {
      "title": "Multimodal Learning for Arcing Detection in Pantograph-Catenary Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08792v1 Announce Type: cross \nAbstract: The pantograph-catenary interface is essential for ensuring uninterrupted and reliable power delivery in electrified rail systems. However, electrical arcing at this interface poses serious risks, including accelerated wear of contact components, degraded system performance, and potential service disruptions. Detecting arcing events at the pantograph-catenary interface is challenging due to their transient nature, noisy operating environment, da",
      "url": "https://arxiv.org/abs/2602.08792",
      "category": "cs.CV"
    },
    {
      "title": "Addressing data annotation scarcity in Brain Tumor Segmentation on 3D MRI scan Using a Semi-Supervised Teacher-Student Framework",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08797v1 Announce Type: cross \nAbstract: Accurate brain tumor segmentation from MRI is limited by expensive annotations and data heterogeneity across scanners and sites. We propose a semi-supervised teacher-student framework that combines an uncertainty-aware pseudo-labeling teacher with a progressive, confidence-based curriculum for the student. The teacher produces probabilistic masks and per-pixel uncertainty; unlabeled scans are ranked by image-level confidence and introduced in st",
      "url": "https://arxiv.org/abs/2602.08797",
      "category": "cs.CV"
    },
    {
      "title": "$\\texttt{lrnnx}$: A library for Linear RNNs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08810v1 Announce Type: cross \nAbstract: Linear recurrent neural networks (LRNNs) provide a structured approach to sequence modeling that bridges classical linear dynamical systems and modern deep learning, offering both expressive power and theoretical guarantees on stability and trainability. In recent years, multiple LRNN-based architectures have been proposed, each introducing distinct parameterizations, discretization schemes, and implementation constraints. However, existing impl",
      "url": "https://arxiv.org/abs/2602.08810",
      "category": "cs.LG"
    },
    {
      "title": "Permissive-Washing in the Open AI Supply Chain: A Large-Scale Audit of License Integrity",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08816v1 Announce Type: cross \nAbstract: Permissive licenses like MIT, Apache-2.0, and BSD-3-Clause dominate open-source AI, signaling that artifacts like models, datasets, and code can be freely used, modified, and redistributed. However, these licenses carry mandatory requirements: include the full license text, provide a copyright notice, and preserve upstream attribution, that remain unverified at scale. Failure to meet these conditions can place reuse outside the scope of the lice",
      "url": "https://arxiv.org/abs/2602.08816",
      "category": "cs.LG"
    },
    {
      "title": "Affective Flow Language Model for Emotional Support Conversation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08826v1 Announce Type: cross \nAbstract: Large language models (LLMs) have been widely applied to emotional support conversation (ESC). However, complex multi-turn support remains challenging.This is because existing alignment schemes rely on sparse outcome-level signals, thus offering limited supervision for intermediate strategy decisions. To fill this gap, this paper proposes affective flow language model for emotional support conversation (AFlow), a framework that introduces fine-g",
      "url": "https://arxiv.org/abs/2602.08826",
      "category": "cs.CL"
    },
    {
      "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08829v1 Announce Type: cross \nAbstract: Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions? In this work, we explore this possibility by adopting WildChat as an interac",
      "url": "https://arxiv.org/abs/2602.08829",
      "category": "cs.CL"
    },
    {
      "title": "Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08847v1 Announce Type: cross \nAbstract: Multi-agent LLM systems enable advanced reasoning and tool use via role specialization, yet reliable reinforcement learning (RL) post-training for such systems remains difficult. In this work, we theoretically pinpoint a key reason for training instability when extending group-based RL to multi-agent LLM systems. We show that under GRPO-style optimization, a global normalization baseline may deviate from diverse agents' reward distributions, whi",
      "url": "https://arxiv.org/abs/2602.08847",
      "category": "cs.LG"
    },
    {
      "title": "Discovering Interpretable Algorithms by Decompiling Transformers to RASP",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08857v1 Announce Type: cross \nAbstract: Recent work has shown that the computations of Transformers can be simulated in the RASP family of programming languages. These findings have enabled improved understanding of the expressive capacity and generalization abilities of Transformers. In particular, Transformers have been suggested to length-generalize exactly on problems that have simple RASP programs. However, it remains open whether trained models actually implement simple interpre",
      "url": "https://arxiv.org/abs/2602.08857",
      "category": "cs.LG"
    },
    {
      "title": "FlattenGPT: Depth Compression for Transformer with Layer Flattening",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08858v1 Announce Type: cross \nAbstract: Recent works have indicated redundancy across transformer blocks, prompting the research of depth compression to prune less crucial blocks. However, current ways of entire-block pruning suffer from risks of discarding meaningful cues learned in those blocks, leading to substantial performance degradation. As another line of model compression, channel pruning can better preserve performance, while it cannot reduce model depth and is challenged by",
      "url": "https://arxiv.org/abs/2602.08858",
      "category": "cs.CV"
    },
    {
      "title": "Understanding Dynamic Compute Allocation in Recurrent Transformers",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08864v1 Announce Type: cross \nAbstract: Token-level adaptive computation seeks to reduce inference cost by allocating more computation to harder tokens and less to easier ones. However, prior work is primarily evaluated on natural-language benchmarks using task-level metrics, where token-level difficulty is unobservable and confounded with architectural factors, making it unclear whether compute allocation truly aligns with underlying complexity. We address this gap through three cont",
      "url": "https://arxiv.org/abs/2602.08864",
      "category": "cs.CL"
    },
    {
      "title": "AnomSeer: Reinforcing Multimodal LLMs to Reason for Time-Series Anomaly Detection",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08868v1 Announce Type: cross \nAbstract: Time-series anomaly detection (TSAD) with multimodal large language models (MLLMs) is an emerging area, yet a persistent challenge remains: MLLMs rely on coarse time-series heuristics but struggle with multi-dimensional, detailed reasoning, which is vital for understanding complex time-series data. We present AnomSeer to address this by reinforcing the model to ground its reasoning in precise, structural details of time series, unifying anomaly ",
      "url": "https://arxiv.org/abs/2602.08868",
      "category": "cs.LG"
    },
    {
      "title": "Whose Name Comes Up? Benchmarking and Intervention-Based Auditing of LLM-Based Scholar Recommendation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08873v1 Announce Type: cross \nAbstract: Large language models (LLMs) are increasingly used for academic expert recommendation. Existing audits typically evaluate model outputs in isolation, largely ignoring end-user inference-time interventions. As a result, it remains unclear whether failures such as refusals, hallucinations, and uneven coverage stem from model choice or deployment decisions. We introduce LLMScholarBench, a benchmark for auditing LLM-based scholar recommendation that",
      "url": "https://arxiv.org/abs/2602.08873",
      "category": "cs.IR"
    },
    {
      "title": "Learning Potentials for Dynamic Matching and Application to Heart Transplantation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08878v1 Announce Type: cross \nAbstract: Each year, thousands of patients in need of heart transplants face life-threatening wait times due to organ scarcity. While allocation policies aim to maximize population-level outcomes, current approaches often fail to account for the dynamic arrival of organs and the composition of waitlisted candidates, thereby hampering efficiency. The United States is transitioning from rigid, rule-based allocation to more flexible data-driven models. In th",
      "url": "https://arxiv.org/abs/2602.08878",
      "category": "cs.LG"
    },
    {
      "title": "Breaking the Simplification Bottleneck in Amortized Neural Symbolic Regression",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08885v2 Announce Type: cross \nAbstract: Symbolic regression (SR) aims to discover interpretable analytical expressions that accurately describe observed data. Amortized SR promises to be much more efficient than the predominant genetic programming SR methods, but currently struggles to scale to realistic scientific complexity. We find that a key obstacle is the lack of a fast reduction of equivalent expressions to a concise normalized form. Amortized SR has addressed this by general-p",
      "url": "https://arxiv.org/abs/2602.08885",
      "category": "cs.LG"
    },
    {
      "title": "DeepQuali: Initial results of a study on the use of large language models for assessing the quality of user stories",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08887v1 Announce Type: cross \nAbstract: Generative artificial intelligence (GAI), specifically large language models (LLMs), are increasingly used in software engineering, mainly for coding tasks. However, requirements engineering - particularly requirements validation - has seen limited application of GAI. The current focus of using GAI for requirements is on eliciting, transforming, and classifying requirements, not on quality assessment. We propose and evaluate the LLM-based (GPT-4",
      "url": "https://arxiv.org/abs/2602.08887",
      "category": "cs.SE"
    },
    {
      "title": "OmniReview: A Large-scale Benchmark and LLM-enhanced Framework for Realistic Reviewer Recommendation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08896v1 Announce Type: cross \nAbstract: Academic peer review remains the cornerstone of scholarly validation, yet the field faces some challenges in data and methods. From the data perspective, existing research is hindered by the scarcity of large-scale, verified benchmarks and oversimplified evaluation metrics that fail to reflect real-world editorial workflows. To bridge this gap, we present OmniReview, a comprehensive dataset constructed by integrating multi-source academic platfo",
      "url": "https://arxiv.org/abs/2602.08896",
      "category": "cs.IR"
    },
    {
      "title": "Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08914v1 Announce Type: cross \nAbstract: A quintessential feature of human intelligence is the ability to create ad hoc conventions over time to achieve shared goals efficiently. We investigate how communication strategies evolve through repeated collaboration as people coordinate on shared procedural abstractions. To this end, we conducted an online unimodal study (n = 98) using natural language to probe abstraction hierarchies. In a follow-up lab study (n = 40), we examined how multi",
      "url": "https://arxiv.org/abs/2602.08914",
      "category": "cs.HC"
    },
    {
      "title": "Automatic In-Domain Exemplar Construction and LLM-Based Refinement of Multi-LLM Expansions for Query Expansion",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08917v1 Announce Type: cross \nAbstract: Query expansion with large language models is promising but often relies on hand-crafted prompts, manually chosen exemplars, or a single LLM, making it non-scalable and sensitive to domain shift. We present an automated, domain-adaptive QE framework that builds in-domain exemplar pools by harvesting pseudo-relevant passages using a BM25-MonoT5 pipeline. A training-free cluster-based strategy selects diverse demonstrations, yielding strong and st",
      "url": "https://arxiv.org/abs/2602.08917",
      "category": "cs.IR"
    },
    {
      "title": "StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08934v1 Announce Type: cross \nAbstract: AI-text detectors face a critical robustness challenge: adversarial paraphrasing attacks that preserve semantics while evading detection. We introduce StealthRL, a reinforcement learning framework that stress-tests detector robustness under realistic adversarial conditions. StealthRL trains a paraphrase policy against a multi-detector ensemble using Group Relative Policy Optimization (GRPO) with LoRA adapters on Qwen3-4B, optimizing a composite ",
      "url": "https://arxiv.org/abs/2602.08934",
      "category": "cs.LG"
    },
    {
      "title": "pixelLOG: Logging of Online Gameplay for Cognitive Research",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08941v1 Announce Type: cross \nAbstract: Traditional cognitive assessments often rely on isolated, output-focused measurements that may fail to capture the complexity of human cognition in naturalistic settings. We present pixelLOG, a high-performance data collection framework for Spigot-based Minecraft servers designed specifically for process-based cognitive research. Unlike existing frameworks tailored only for artificial intelligence agents, pixelLOG also enables human behavioral t",
      "url": "https://arxiv.org/abs/2602.08941",
      "category": "cs.HC"
    },
    {
      "title": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08961v1 Announce Type: cross \nAbstract: We introduce MotionCrafter, a video diffusion-based framework that jointly reconstructs 4D geometry and estimates dense motion from a monocular video. The core of our method is a novel joint representation of dense 3D point maps and 3D scene flows in a shared coordinate system, and a novel 4D VAE to effectively learn this representation. Unlike prior work that forces the 3D value and latents to align strictly with RGB VAE latents-despite their f",
      "url": "https://arxiv.org/abs/2602.08961",
      "category": "cs.CV"
    },
    {
      "title": "A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08964v1 Announce Type: cross \nAbstract: Understanding an agent's goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models' internal representations. As a case study, we examine an LLM agent navigating a 2D grid world toward a goal state. Behaviourally, we evaluate t",
      "url": "https://arxiv.org/abs/2602.08964",
      "category": "cs.LG"
    },
    {
      "title": "StretchTime: Adaptive Time Series Forecasting via Symplectic Attention",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08983v1 Announce Type: cross \nAbstract: Transformer architectures have established strong baselines in time series forecasting, yet they typically rely on positional encodings that assume uniform, index-based temporal progression. However, real-world systems, from shifting financial cycles to elastic biological rhythms, frequently exhibit \"time-warped\" dynamics where the effective flow of time decouples from the sampling index. In this work, we first formalize this misalignment and pr",
      "url": "https://arxiv.org/abs/2602.08983",
      "category": "cs.LG"
    },
    {
      "title": "Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08984v1 Announce Type: cross \nAbstract: We propose Next Concept Prediction (NCP), a generative pretraining paradigm built on top of Next Token Prediction (NTP). NCP predicts discrete concepts that span multiple tokens, thereby forming a more challenging pretraining objective. Our model, ConceptLM, quantizes hidden states using Vector Quantization and constructs a concept vocabulary. It leverages both NCP and NTP to drive parameter updates and generates a concept to guide the generatio",
      "url": "https://arxiv.org/abs/2602.08984",
      "category": "cs.CL"
    },
    {
      "title": "Improving Detection of Rare Nodes in Hierarchical Multi-Label Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.08986v1 Announce Type: cross \nAbstract: In hierarchical multi-label classification, a persistent challenge is enabling model predictions to reach deeper levels of the hierarchy for more detailed or fine-grained classifications. This difficulty partly arises from the natural rarity of certain classes (or hierarchical nodes) and the hierarchical constraint that ensures child nodes are almost always less frequent than their parents. To address this, we propose a weighted loss objective f",
      "url": "https://arxiv.org/abs/2602.08986",
      "category": "cs.LG"
    },
    {
      "title": "From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.09002v1 Announce Type: cross \nAbstract: Navigating socially in human environments requires more than satisfying geometric constraints, as collision-free paths may still interfere with ongoing activities or conflict with social norms. Addressing this challenge calls for analyzing interactions between agents and incorporating common-sense reasoning into planning. This paper presents a social robot navigation framework that integrates geometric planning with contextual social reasoning. ",
      "url": "https://arxiv.org/abs/2602.09002",
      "category": "cs.RO"
    },
    {
      "title": "ARO: A New Lens On Matrix Optimization For Large Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.09006v1 Announce Type: cross \nAbstract: Matrix-based optimizers have attracted growing interest for improving LLM training efficiency, with significant progress centered on orthogonalization/whitening based methods. While yielding substantial performance gains, a fundamental question arises: can we develop new paradigms beyond orthogonalization, pushing the efficiency frontier further? We present \\textbf{Adaptively Rotated Optimization (ARO}, a new matrix optimization framework that t",
      "url": "https://arxiv.org/abs/2602.09006",
      "category": "cs.LG"
    },
    {
      "title": "ANCRe: Adaptive Neural Connection Reassignment for Efficient Depth Scaling",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.09009v1 Announce Type: cross \nAbstract: Scaling network depth has been a central driver behind the success of modern foundation models, yet recent investigations suggest that deep layers are often underutilized. This paper revisits the default mechanism for deepening neural networks, namely residual connections, from an optimization perspective. Rigorous analysis proves that the layout of residual connections can fundamentally shape convergence behavior, and even induces an exponentia",
      "url": "https://arxiv.org/abs/2602.09009",
      "category": "cs.LG"
    },
    {
      "title": "Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.09012v1 Announce Type: cross \nAbstract: The rapid evolution of GUI-enabled agents has rendered traditional CAPTCHAs obsolete. While previous benchmarks like OpenCaptchaWorld established a baseline for evaluating multimodal agents, recent advancements in reasoning-heavy models, such as Gemini3-Pro-High and GPT-5.2-Xhigh have effectively collapsed this security barrier, achieving pass rates as high as 90% on complex logic puzzles like \"Bingo\". In response, we introduce Next-Gen CAPTCHAs",
      "url": "https://arxiv.org/abs/2602.09012",
      "category": "cs.LG"
    },
    {
      "title": "ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.09014v1 Announce Type: cross \nAbstract: Diffusion models have achieved remarkable generation quality, but they suffer from significant inference cost due to their reliance on multiple sequential denoising steps, motivating recent efforts to distill this inference process into a few-step regime. However, existing distillation methods typically approximate the teacher trajectory by using linear shortcuts, which makes it difficult to match its constantly changing tangent directions as ve",
      "url": "https://arxiv.org/abs/2602.09014",
      "category": "cs.CV"
    },
    {
      "title": "CIC-Trap4Phish: A Unified Multi-Format Dataset for Phishing and Quishing Attachment Detection",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.09015v2 Announce Type: cross \nAbstract: Phishing attacks represents one of the primary attack methods which is used by cyber attackers. In many cases, attackers use deceptive emails along with malicious attachments to trick users into giving away sensitive information or installing malware while compromising entire systems. The flexibility of malicious email attachments makes them stand out as a preferred vector for attackers as they can embed harmful content such as malware or malici",
      "url": "https://arxiv.org/abs/2602.09015",
      "category": "cs.CR"
    },
    {
      "title": "Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.09018v1 Announce Type: cross \nAbstract: Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \\in \\{0,1,2,3\\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT policies, train compact ViT heads on frozen foundation-",
      "url": "https://arxiv.org/abs/2602.09018",
      "category": "cs.RO"
    },
    {
      "title": "Knowledge-Centric Metacognitive Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2402.05346v4 Announce Type: replace \nAbstract: Interactions are central to intelligent reasoning and learning abilities, with the interpretation of abstract knowledge guiding meaningful interaction with objects in the environment. While humans readily adapt to novel situations by leveraging abstract knowledge acquired over time, artificial intelligence systems lack principled mechanisms for incorporating abstract knowledge into learning, leading to fundamental challenges in the emergence o",
      "url": "https://arxiv.org/abs/2402.05346",
      "category": "cs.AI"
    },
    {
      "title": "Generative AI voting: fair collective choice is resilient to LLM biases and inconsistencies",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2406.11871v5 Announce Type: replace \nAbstract: Recent breakthroughs in generative artificial intelligence (AI) and large language models (LLMs) unravel new capabilities for AI personal assistants to overcome cognitive bandwidth limitations of humans, providing decision support or even direct representation of abstained human voters at large scale. However, the quality of this representation and what underlying biases manifest when delegating collective decision making to LLMs is an alarmin",
      "url": "https://arxiv.org/abs/2406.11871",
      "category": "cs.AI"
    },
    {
      "title": "Tree Search for Language Model Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2407.01476v4 Announce Type: replace \nAbstract: Autonomous agents powered by language models (LMs) have demonstrated promise in their ability to perform decision-making tasks such as web automation. However, a key limitation remains: LMs, primarily optimized for natural language understanding and generation, struggle with multi-step reasoning, planning, and using environmental feedback when attempting to solve realistic computer tasks. Towards addressing this, we propose an inference-time s",
      "url": "https://arxiv.org/abs/2407.01476",
      "category": "cs.AI"
    },
    {
      "title": "Revisiting Privacy, Utility, and Efficiency Trade-offs when Fine-Tuning Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2502.13313v2 Announce Type: replace \nAbstract: We study the inherent trade-offs in minimizing privacy risks and maximizing utility, while maintaining high computational efficiency, when fine-tuning large language models (LLMs). A number of recent works in privacy research have attempted to mitigate privacy risks posed by memorizing fine-tuning data by using differentially private training methods (e.g., DP), albeit at a significantly higher computational cost (inefficiency). In parallel, s",
      "url": "https://arxiv.org/abs/2502.13313",
      "category": "cs.AI"
    },
    {
      "title": "Research Superalignment Should Advance Now with Alternating Competence and Conformity Optimization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2503.07660v2 Announce Type: replace \nAbstract: The recent leap in AI capabilities, driven by big generative models, has sparked the possibility of achieving Artificial General Intelligence (AGI) and further triggered discussions on Artificial Superintelligence (ASI)-a system surpassing all humans across measured domains. This gives rise to the critical research question of: As we approach ASI, how do we align it with human values, ensuring it benefits rather than harms human society, a.k.a",
      "url": "https://arxiv.org/abs/2503.07660",
      "category": "cs.AI"
    },
    {
      "title": "Nondeterministic Polynomial-time Problem Challenge: An Ever-Scaling Reasoning Benchmark for LLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2504.11239v2 Announce Type: replace \nAbstract: Reasoning is the fundamental capability of large language models (LLMs). Due to the rapid progress of LLMs, there are two main issues of current benchmarks: i) these benchmarks can be crushed in a short time (less than 1 year), and ii) these benchmarks may be easily hacked. To handle these issues, we propose the ever-scalingness for building the benchmarks which are scaling over complexity against crushing, instance against hacking and exploit",
      "url": "https://arxiv.org/abs/2504.11239",
      "category": "cs.AI"
    },
    {
      "title": "DRAGON: Domain-specific Robust Automatic Data Generation for RAG Optimization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2505.10989v2 Announce Type: replace \nAbstract: Retrieval-augmented generation (RAG) can substantially enhance the performance of LLMs on knowledge-intensive tasks. Various RAG paradigms - including vanilla, planning-based, and iterative RAG - all depend on a robust retriever, yet existing retrievers rely heavily on public knowledge and often falter when faced with domain-specific queries. To address these limitations, we introduce DRAGON, a framework that combines a data-construction model",
      "url": "https://arxiv.org/abs/2505.10989",
      "category": "cs.AI"
    },
    {
      "title": "Average Reward Reinforcement Learning for Omega-Regular and Mean-Payoff Objectives",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2505.15693v2 Announce Type: replace \nAbstract: Recent advances in reinforcement learning (RL) have renewed interest in reward design for shaping agent behavior, but manually crafting reward functions is tedious and error-prone. A principled alternative is to specify behavioral requirements in a formal, unambiguous language and automatically compile them into learning objectives. $\\omega$-regular languages are a natural fit, given their role in formal verification and synthesis. However, mo",
      "url": "https://arxiv.org/abs/2505.15693",
      "category": "cs.AI"
    },
    {
      "title": "Capability-Based Scaling Trends for LLM-Based Red-Teaming",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2505.20162v2 Announce Type: replace \nAbstract: As large language models grow in capability and agency, identifying vulnerabilities through red-teaming becomes vital for safe deployment. However, traditional prompt-engineering approaches may prove ineffective once red-teaming turns into a \\emph{weak-to-strong} problem, where target models surpass red-teamers in capabilities. To study this shift, we frame red-teaming through the lens of the \\emph{capability gap} between attacker and target. ",
      "url": "https://arxiv.org/abs/2505.20162",
      "category": "cs.AI"
    },
    {
      "title": "HouseTS: A Large-Scale, Multimodal Spatiotemporal U.S. Housing Dataset and Benchmark",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2506.00765v2 Announce Type: replace \nAbstract: Accurate long-horizon house-price forecasting requires benchmarks that capture temporal dynamics together with time-varying local context. However, existing public resources remain fragmented: many datasets have limited spatial coverage, temporal depth, or multimodal alignment; the robustness of modern deep forecasters and time-series foundation models on housing data is not well characterized; and aerial imagery is rarely leveraged in a time-",
      "url": "https://arxiv.org/abs/2506.00765",
      "category": "cs.AI"
    },
    {
      "title": "Guideline Forest: Retrieval-Augmented Reasoning with Branching Experience-Induced Guidelines",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2506.07820v3 Announce Type: replace \nAbstract: Retrieval-augmented generation (RAG) has been widely adopted to ground large language models (LLMs) in external knowledge, yet it remains largely underexplored for improving reasoning. Existing methods either rely on online exploration during inference or heuristic supervision over reasoning trajectories, but they fail to effectively accumulate and reuse past reasoning experience. We propose Guideline Forest, a retrieval-augmented reasoning fr",
      "url": "https://arxiv.org/abs/2506.07820",
      "category": "cs.AI"
    },
    {
      "title": "On Reasoning Strength Planning in Large Reasoning Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2506.08390v2 Announce Type: replace \nAbstract: Recent studies empirically reveal that large reasoning models (LRMs) can automatically allocate more reasoning strengths (i.e., the number of reasoning tokens) for harder problems, exhibiting difficulty-awareness for better task performance. While this automatic reasoning strength allocation phenomenon has been widely observed, its underlying mechanism remains largely unexplored. To this end, we provide explanations for this phenomenon from th",
      "url": "https://arxiv.org/abs/2506.08390",
      "category": "cs.AI"
    },
    {
      "title": "CID-GraphRAG: Enhancing Multi-Turn Dialogue Systems through Dual-Pathway Retrieval of Conversation Flow and Context Semantics",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2506.19385v4 Announce Type: replace \nAbstract: We present CID-GraphRAG (Conversational Intent-Driven Graph Retrieval-Augmented Generation), a novel framework that addresses the limitations of existing dialogue systems in maintaining both contextual coherence and goal-oriented progression in multi-turn customer service conversations. Unlike traditional RAG systems that rely solely on semantic similarity or static knowledge graphs, CID-GraphRAG constructs intent transition graphs from goal-a",
      "url": "https://arxiv.org/abs/2506.19385",
      "category": "cs.AI"
    },
    {
      "title": "Lyria: A Genetic Algorithm-Driven Neuro-Symbolic Reasoning Framework for LLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2507.04034v2 Announce Type: replace \nAbstract: While LLMs have demonstrated impressive abilities across various domains, they struggle with two major issues. The first is that LLMs trap themselves into local optima and the second is that they lack exhaustive coverage of the solution space. To investigate and improve these two issues, we propose Lyria, a neuro-symbolic reasoning framework building on the integration of LLMs, genetic algorithms, and symbolic systems, comprising 7 essential c",
      "url": "https://arxiv.org/abs/2507.04034",
      "category": "cs.AI"
    },
    {
      "title": "Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2507.08249v2 Announce Type: replace \nAbstract: There is growing interest in giving AI agents access to cryptocurrencies as well as to the smart contracts that transact them. But doing so, this position paper argues, could lead to formidable new vectors of AI harm. To support this argument, we first examine the unique properties of cryptocurrencies and smart contracts that could give rise to these new vectors of AI harm. Next, we describe each of these new vectors of AI harm in detail, prov",
      "url": "https://arxiv.org/abs/2507.08249",
      "category": "cs.AI"
    },
    {
      "title": "Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making under Epistemic Uncertainty",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2508.08992v2 Announce Type: replace \nAbstract: Prospect Theory (PT) models human decision-making under uncertainty, while epistemic markers (e.g., maybe) serve to express uncertainty in language. However, it remains largely unexplored whether Prospect Theory applies to contemporary Large Language Models and whether epistemic markers, which express human uncertainty, affect their decision-making behaviour. To address these research gaps, we design a three-stage experiment based on economic ",
      "url": "https://arxiv.org/abs/2508.08992",
      "category": "cs.AI"
    },
    {
      "title": "HiFo-Prompt: Prompting with Hindsight and Foresight for LLM-based Automatic Heuristic Design",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2508.13333v2 Announce Type: replace \nAbstract: LLM-based Automatic Heuristic Design (AHD) within Evolutionary Computation (EC) frameworks has shown promising results. However, its effectiveness is hindered by the use of static operators and the lack of knowledge accumulation mechanisms. We introduce HiFo-Prompt, a framework that guides LLMs with two synergistic prompting strategies: Foresight and Hindsight. Foresight-based prompts adaptively steer the search based on population dynamics, m",
      "url": "https://arxiv.org/abs/2508.13333",
      "category": "cs.AI"
    },
    {
      "title": "Coarse-to-Fine Grounded Memory for LLM Agent Planning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2508.15305v2 Announce Type: replace \nAbstract: Recent advancements in Large Language Models (LLMs) have driven growing interest in LLM-based agents for complex planning tasks. To avoid costly agent training, many studies adopted memory mechanism that enhances LLM with offline experiences or online trajectory analysis. However, existing works focus on single-granularity memory derived from dynamic environmental interactions, which are inherently constrained by the quality of the collected e",
      "url": "https://arxiv.org/abs/2508.15305",
      "category": "cs.AI"
    },
    {
      "title": "Certainty-Guided Reasoning in Large Language Models: A Dynamic Thinking Budget Approach",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.07820v2 Announce Type: replace \nAbstract: Large reasoning language models are typically run with fixed inference budgets, which can waste computation or terminate reasoning prematurely. We introduce Certainty-Guided Reasoning (CGR), a model-agnostic adaptive inference procedure that periodically probes whether the current reasoning supports a confident final answer and terminates early once a target certainty threshold is reached, otherwise continuing until the end-of-thinking token o",
      "url": "https://arxiv.org/abs/2509.07820",
      "category": "cs.AI"
    },
    {
      "title": "Steerable Adversarial Scenario Generation through Test-Time Preference Alignment",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.20102v2 Announce Type: replace \nAbstract: Adversarial scenario generation is a cost-effective approach for safety assessment of autonomous driving systems. However, existing methods are often constrained to a single, fixed trade-off between competing objectives such as adversariality and realism. This yields behavior-specific models that cannot be steered at inference time, lacking the efficiency and flexibility to generate tailored scenarios for diverse training and testing requireme",
      "url": "https://arxiv.org/abs/2509.20102",
      "category": "cs.AI"
    },
    {
      "title": "Rethinking Explainable Disease Prediction: Synergizing Accuracy and Reliability via Reflective Cognitive Architecture",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.21266v2 Announce Type: replace \nAbstract: In clinical decision-making, predictive models face a persistent trade-off: accurate models are often opaque \"black boxes,\" while interpretable methods frequently lack predictive precision or statistical grounding. In this paper, we challenge this dichotomy, positing that high predictive accuracy and high-quality descriptive explanations are not competing goals but synergistic outcomes of a deep, first-hand understanding of data. We propose th",
      "url": "https://arxiv.org/abs/2509.21266",
      "category": "cs.AI"
    },
    {
      "title": "Correct Reasoning Paths Visit Shared Decision Pivots",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.21549v3 Announce Type: replace \nAbstract: Chain-of-thought (CoT) reasoning exposes the intermediate thinking process of large language models (LLMs), yet verifying those traces at scale remains unsolved. In response, we introduce the idea of decision pivots-minimal, verifiable checkpoints that any correct reasoning path must visit. We hypothesize that correct reasoning, though stylistically diverse, converge on the same pivot set, while incorrect ones violate at least one pivot. Lever",
      "url": "https://arxiv.org/abs/2509.21549",
      "category": "cs.AI"
    },
    {
      "title": "Lifelong Learning with Behavior Consolidation for Vehicle Routing",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.21765v4 Announce Type: replace \nAbstract: Recent neural solvers have demonstrated promising performance in learning to solve routing problems. However, existing studies are primarily based on one-off training on one or a set of predefined problem distributions and scales, i.e., tasks. When a new task arises, they typically rely on either zero-shot generalization, which may be poor due to the discrepancies between the new task and the training task(s), or fine-tuning the pretrained sol",
      "url": "https://arxiv.org/abs/2509.21765",
      "category": "cs.AI"
    },
    {
      "title": "TRACE: Learning to Compute on Circuit Graphs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.21886v2 Announce Type: replace \nAbstract: Learning to compute, the ability to model the functional behavior of a circuit graph, is a fundamental challenge for graph representation learning. Yet, the dominant paradigm is architecturally mismatched for this task. This flawed assumption, central to mainstream message passing neural networks (MPNNs) and their conventional Transformer-based counterparts, prevents models from capturing the position-aware, hierarchical nature of computation.",
      "url": "https://arxiv.org/abs/2509.21886",
      "category": "cs.AI"
    },
    {
      "title": "Agentic AI Reasoning for Mobile Edge General Intelligence: Fundamentals, Approaches, and Directions",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.23248v2 Announce Type: replace \nAbstract: The rapid advancement of large language models (LLMs) has enabled an emergence of agentic artificial intelligence (AI) with powerful reasoning and autonomous decision-making capabilities. This integration with edge computing has led to the development of Mobile Edge General Intelligence (MEGI), which brings real-time, privacy-preserving reasoning to the network edge. However, deploying LLM-based agentic AI reasoning in MEGI environments poses ",
      "url": "https://arxiv.org/abs/2509.23248",
      "category": "cs.AI"
    },
    {
      "title": "AIReg-Bench: Benchmarking Language Models That Assess AI Regulation Compliance",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.01474v3 Announce Type: replace \nAbstract: As governments move to regulate AI, there is growing interest in using Large Language Models (LLMs) to assess whether or not an AI system complies with a given AI Regulation (AIR). However, there is presently no way to benchmark the performance of LLMs at this task. To fill this void, we introduce AIReg-Bench: the first open benchmark dataset designed to test how well LLMs can assess compliance with the EU AI Act (AIA). We created this dataset",
      "url": "https://arxiv.org/abs/2510.01474",
      "category": "cs.AI"
    },
    {
      "title": "SurveyG: A Multi-Agent LLM Framework with Hierarchical Citation Graph for Automated Survey Generation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.07733v3 Announce Type: replace \nAbstract: Large language models (LLMs) are increasingly adopted for automating survey paper generation \\cite{wang2406autosurvey, liang2025surveyx, yan2025surveyforge,su2025benchmarking,wen2025interactivesurvey}. Existing approaches typically extract content from a large collection of related papers and prompt LLMs to summarize them directly. However, such methods often overlook the structural relationships among papers, resulting in generated surveys th",
      "url": "https://arxiv.org/abs/2510.07733",
      "category": "cs.AI"
    },
    {
      "title": "The Achilles' Heel of LLMs: How Altering a Handful of Neurons Can Cripple Language Abilities",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.10238v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have become foundational tools in natural language processing, powering a wide range of applications and research. Many studies have shown that LLMs share significant similarities with the human brain. Recent neuroscience research has found that a small subset of biological neurons in the human brain are crucial for core cognitive functions, which raises a fundamental question: do LLMs also contain a small subset o",
      "url": "https://arxiv.org/abs/2510.10238",
      "category": "cs.AI"
    },
    {
      "title": "OpenPhone: Mobile Agentic Foundation Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.22009v2 Announce Type: replace \nAbstract: With the advancement of multimodal large language models (MLLMs), building GUI agent systems has become an increasingly promising direction--especially for mobile platforms, given their rich app ecosystems and intuitive touch interactions. Yet mobile GUI agents face a critical dilemma: truly on-device models (4B or smaller) lack sufficient performance, while capable models (starting from 7B) are either too large for mobile deployment or prohib",
      "url": "https://arxiv.org/abs/2510.22009",
      "category": "cs.AI"
    },
    {
      "title": "GUI Knowledge Bench: Revealing the Knowledge Gap of VLMs in GUI Tasks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.26098v2 Announce Type: replace \nAbstract: Vision language models (VLMs) have advanced graphical user interface (GUI) task automation but still lag behind humans. We hypothesize this gap stems from missing core GUI knowledge, which existing training schemes (such as supervised fine tuning and reinforcement learning) alone cannot fully address. By analyzing common failure patterns in GUI task execution, we distill GUI knowledge into three dimensions: (1) interface knowledge about widget",
      "url": "https://arxiv.org/abs/2510.26098",
      "category": "cs.AI"
    },
    {
      "title": "BEAT: Visual Backdoor Attacks on VLM-based Embodied Agents via Contrastive Trigger Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.27623v2 Announce Type: replace \nAbstract: Recent advances in Vision-Language Models (VLMs) have propelled embodied agents by enabling direct perception, reasoning, and planning task-oriented actions from visual inputs. However, such vision-driven embodied agents open a new attack surface: visual backdoor attacks, where the agent behaves normally until a visual trigger appears in the scene, then persistently executes an attacker-specified multi-step policy. We introduce BEAT, the first",
      "url": "https://arxiv.org/abs/2510.27623",
      "category": "cs.AI"
    },
    {
      "title": "Massively Parallel Proof-Number Search for Impartial Games and Beyond",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.10339v2 Announce Type: replace \nAbstract: Proof-Number Search is a best-first search algorithm with many successful applications, especially in game solving. As large-scale computing clusters become increasingly accessible, parallelization is a natural way to accelerate computation. However, existing parallel versions of Proof-Number Search are known to scale poorly on many CPU cores. Using two parallelized levels and shared information among workers, we present the first massively pa",
      "url": "https://arxiv.org/abs/2511.10339",
      "category": "cs.AI"
    },
    {
      "title": "Towards Reinforcement Learning from Neural Feedback: Mapping fNIRS Signals to Agent Performance",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.12844v4 Announce Type: replace \nAbstract: Reinforcement Learning from Human Feedback (RLHF) is a methodology that aligns agent behavior with human preferences by integrating user feedback into the agent's training process. This paper introduces a framework that guides agent training through implicit neural signals, with a focus on the neural classification problem. Our work presents and releases a novel dataset of functional near-infrared spectroscopy (fNIRS) recordings collected from",
      "url": "https://arxiv.org/abs/2511.12844",
      "category": "cs.AI"
    },
    {
      "title": "AISAC: An Integrated multi-agent System for Transparent, Retrieval-Grounded Scientific Assistance",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.14043v2 Announce Type: replace \nAbstract: AI Scientific Assistant Core (AISAC) is a transparent, modular multi-agent runtime developed at Argonne National Laboratory to support long-horizon, evidence-grounded scientific reasoning. Rather than proposing new agent algorithms or claiming autonomous scientific discovery, AISAC contributes a governed execution substrate that operationalizes key requirements for deploying agentic AI in scientific practice, including explicit role semantics,",
      "url": "https://arxiv.org/abs/2511.14043",
      "category": "cs.AI"
    },
    {
      "title": "HuggingR$^{4}$: A Progressive Reasoning Framework for Discovering Optimal Model Companions",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.18715v2 Announce Type: replace \nAbstract: Building effective LLM agents increasingly requires selecting appropriate AI models as tools from large open repositories (e.g., HuggingFace with > 2M models) based on natural language requests. Unlike invoking a fixed set of API tools, repository-scale model selection must handle massive, evolving candidates with incomplete metadata. Existing approaches incorporate full model descriptions into prompts, resulting in prompt bloat, excessive tok",
      "url": "https://arxiv.org/abs/2511.18715",
      "category": "cs.AI"
    },
    {
      "title": "UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.18845v2 Announce Type: replace \nAbstract: Vision-and-Language Navigation (VLN) requires agents to autonomously navigate complex environments via visual images and natural language instructions--remains highly challenging. Recent research on enhancing language-guided navigation reasoning using pre-trained large language models (LLMs) has shown promising prospects. However, the reasoning of such methods is limited to the linguistic modality, lacking visual reasoning capabilities. Moreov",
      "url": "https://arxiv.org/abs/2511.18845",
      "category": "cs.AI"
    },
    {
      "title": "CostNav: A Navigation Benchmark for Real-World Economic-Cost Evaluation of Physical AI Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.20216v3 Announce Type: replace \nAbstract: While current navigation benchmarks prioritize task success in simplified settings, they neglect the multidimensional economic constraints essential for the real-world commercialization of autonomous delivery systems. We introduce CostNav, an Economic Navigation Benchmark that evaluates physical AI agents through comprehensive economic cost-revenue analysis aligned with real-world business operations. By integrating industry-standard data - su",
      "url": "https://arxiv.org/abs/2511.20216",
      "category": "cs.AI"
    },
    {
      "title": "Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.20694v2 Announce Type: replace \nAbstract: Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data ar",
      "url": "https://arxiv.org/abs/2511.20694",
      "category": "cs.AI"
    },
    {
      "title": "Conversational No-code, Multi-agentic Disease Module Identification and Drug Repurposing Prediction with ChatDRex",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.21438v2 Announce Type: replace \nAbstract: Repurposing approved drugs offers a time-efficient and cost-effective alternative to traditional drug development. However, in silico prediction of repurposing candidates is challenging and requires the effective collaboration of specialists in various fields, including pharmacology, medicine, biology, and bioinformatics. Fragmented, specialized algorithms and tools often address only narrow aspects of the overall problem. Heterogeneous, unstr",
      "url": "https://arxiv.org/abs/2511.21438",
      "category": "cs.AI"
    },
    {
      "title": "Agent policies from higher-order causal functions",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.10937v2 Announce Type: replace \nAbstract: We establish a correspondence between equivalence classes of agent-state policies for deterministic POMDPs and one-input process functions (the classical-deterministic limit of higher-order quantum operations). We use this correspondence to build a bridge between the agent-environment interaction in artificial intelligence, causal structure in the foundations of physics, and logic in computer science. We construct a *-autonomous category PF of",
      "url": "https://arxiv.org/abs/2512.10937",
      "category": "cs.AI"
    },
    {
      "title": "Safety Alignment of LMs via Non-cooperative Games",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.20806v2 Announce Type: replace \nAbstract: Ensuring the safety of language models (LMs) while maintaining their usefulness remains a critical challenge in AI alignment. Current approaches rely on sequential adversarial training: generating adversarial prompts and fine-tuning LMs to defend against them. We introduce a different paradigm: framing safety alignment as a non-zero-sum game between an Attacker LM and a Defender LM trained jointly via online reinforcement learning. Each LM con",
      "url": "https://arxiv.org/abs/2512.20806",
      "category": "cs.AI"
    },
    {
      "title": "InSPO: Unlocking Intrinsic Self-Reflection for LLM Preference Optimization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.23126v3 Announce Type: replace \nAbstract: Direct Preference Optimization (DPO) and its variants have become standard for aligning Large Language Models due to their simplicity and offline stability. However, we identify two fundamental limitations. First, the optimal policy depends on arbitrary modeling choices (scalarization function, reference policy), yielding behavior reflecting parameterization artifacts rather than true preferences. Second, treating response generation in isolat",
      "url": "https://arxiv.org/abs/2512.23126",
      "category": "cs.AI"
    },
    {
      "title": "Token-Level LLM Collaboration via FusionRoute",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.05106v2 Announce Type: replace \nAbstract: Large language models (LLMs) exhibit strengths across diverse domains. However, achieving strong performance across these domains with a single general-purpose model typically requires scaling to sizes that are prohibitively expensive to train and deploy. On the other hand, while smaller domain-specialized models are much more efficient, they struggle to generalize beyond their training distributions. To address this dilemma, we propose Fusion",
      "url": "https://arxiv.org/abs/2601.05106",
      "category": "cs.AI"
    },
    {
      "title": "VirtualEnv: A Platform for Embodied AI Research",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.07553v2 Announce Type: replace \nAbstract: As large language models (LLMs) continue to improve in reasoning and decision-making, there is a growing need for realistic and interactive environments where their abilities can be rigorously evaluated. We present VirtualEnv, a next-generation simulation platform built on Unreal Engine 5 that enables fine-grained benchmarking of LLMs in embodied and interactive scenarios. VirtualEnv supports rich agent-environment interactions, including obje",
      "url": "https://arxiv.org/abs/2601.07553",
      "category": "cs.AI"
    },
    {
      "title": "Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.11840v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) have shown strong performance on code understanding tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor.\n  We present CodeLogician, a neurosymbolic agent for precise analys",
      "url": "https://arxiv.org/abs/2601.11840",
      "category": "cs.AI"
    },
    {
      "title": "Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.18588v2 Announce Type: replace \nAbstract: Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative",
      "url": "https://arxiv.org/abs/2601.18588",
      "category": "cs.AI"
    },
    {
      "title": "Beyond In-Domain Detection: SpikeScore for Cross-Domain Hallucination Detection",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.19245v3 Announce Type: replace \nAbstract: Hallucination detection is critical for deploying large language models (LLMs) in real-world applications. Existing hallucination detection methods achieve strong performance when the training and test data come from the same domain, but they suffer from poor cross-domain generalization. In this paper, we study an important yet overlooked problem, termed generalizable hallucination detection (GHD), which aims to train hallucination detectors o",
      "url": "https://arxiv.org/abs/2601.19245",
      "category": "cs.AI"
    },
    {
      "title": "OpenSec: Measuring Incident Response Agent Calibration Under Adversarial Evidence",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.21083v3 Announce Type: replace \nAbstract: As large language models (LLMs) improve, so do their offensive applications: frontier agents now generate working exploits for under $50 in compute (Heelan, 2026). Defensive incident response (IR) agents must keep pace, but existing benchmarks conflate action execution with correct execution, hiding calibration failures when agents process adversarial evidence. We introduce OpenSec, a dual-control reinforcement learning (RL) environment that e",
      "url": "https://arxiv.org/abs/2601.21083",
      "category": "cs.AI"
    },
    {
      "title": "Sycophantic Anchors: Localizing and Quantifying User Agreement in Reasoning Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.21183v2 Announce Type: replace \nAbstract: Reasoning models frequently agree with incorrect user suggestions -- a behavior known as sycophancy. However, it is unclear where in the reasoning trace this agreement originates and how strong the commitment is. We introduce \\emph{sycophantic anchors} -- sentences identified via counterfactual analysis that commit models to user agreement. Across four reasoning models spanning three architecture families (Llama, Qwen, Falcon-hybrid) and 1.5B-",
      "url": "https://arxiv.org/abs/2601.21183",
      "category": "cs.AI"
    },
    {
      "title": "TIDE: Tuning-Integrated Dynamic Evolution for LLM-Based Automated Heuristic Design",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.21239v2 Announce Type: replace \nAbstract: Although Large Language Models have advanced Automated Heuristic Design, treating algorithm evolution as a monolithic text generation task overlooks the coupling between discrete algorithmic structures and continuous numerical parameters. Consequently, existing methods often discard promising algorithms due to uncalibrated constants and suffer from premature convergence resulting from simple similarity metrics. To address these limitations, we",
      "url": "https://arxiv.org/abs/2601.21239",
      "category": "cs.AI"
    },
    {
      "title": "Zero-Shot Statistical Downscaling via Diffusion Posterior Sampling",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.21760v2 Announce Type: replace \nAbstract: Conventional supervised climate downscaling struggles to generalize to Global Climate Models (GCMs) due to the lack of paired training data and inherent domain gaps relative to reanalysis. Meanwhile, current zero-shot methods suffer from physical inconsistencies and vanishing gradient issues under large scaling factors. We propose Zero-Shot Statistical Downscaling (ZSSD), a zero-shot framework that performs statistical downscaling without pair",
      "url": "https://arxiv.org/abs/2601.21760",
      "category": "cs.AI"
    },
    {
      "title": "Statistical Estimation of Adversarial Risk in Large Language Models under Best-of-N Sampling",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.22636v2 Announce Type: replace \nAbstract: Large Language Models (LLMs) are typically evaluated for safety under single-shot or low-budget adversarial prompting, which underestimates real-world risk. In practice, attackers can exploit large-scale parallel sampling to repeatedly probe a model until a harmful response is produced. While recent work shows that attack success increases with repeated sampling, principled methods for predicting large-scale adversarial risk remain limited. We",
      "url": "https://arxiv.org/abs/2601.22636",
      "category": "cs.AI"
    },
    {
      "title": "Game-Theoretic Co-Evolution for LLM-Based Heuristic Discovery",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.22896v2 Announce Type: replace \nAbstract: Large language models (LLMs) have enabled rapid progress in automatic heuristic discovery (AHD), yet most existing methods are predominantly limited by static evaluation against fixed instance distributions, leading to potential overfitting and poor generalization under distributional shifts. We propose Algorithm Space Response Oracles (ASRO), a game-theoretic framework that reframes heuristic discovery as a program level co-evolution between ",
      "url": "https://arxiv.org/abs/2601.22896",
      "category": "cs.AI"
    },
    {
      "title": "Optimizing Agentic Reasoning with Retrieval via Synthetic Semantic Information Gain Reward",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.00845v2 Announce Type: replace \nAbstract: Agentic reasoning enables large reasoning models (LRMs) to dynamically acquire external knowledge, but yet optimizing the retrieval process remains challenging due to the lack of dense, principled reward signals. In this paper, we introduce InfoReasoner, a unified framework that incentivizes effective information seeking via a synthetic semantic information gain reward. Theoretically, we redefine information gain as uncertainty reduction over ",
      "url": "https://arxiv.org/abs/2602.00845",
      "category": "cs.AI"
    },
    {
      "title": "Agyn: A Multi-Agent System for Team-Based Autonomous Software Engineering",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.01465v2 Announce Type: replace \nAbstract: Large language models have demonstrated strong capabilities in individual software engineering tasks, yet most autonomous systems still treat issue resolution as a monolithic or pipeline-based process. In contrast, real-world software development is organized as a collaborative activity carried out by teams following shared methodologies, with clear role separation, communication, and review. In this work, we present a fully automated multi-ag",
      "url": "https://arxiv.org/abs/2602.01465",
      "category": "cs.AI"
    },
    {
      "title": "ProjDevBench: Benchmarking AI Coding Agents on End-to-End Project Development",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.01655v2 Announce Type: replace \nAbstract: Recent coding agents can generate complete codebases from simple prompts, yet existing evaluations focus on issue-level bug fixing and lag behind end-to-end development. We introduce ProjDevBench, an end-to-end benchmark that provides project requirements to coding agents and evaluates the resulting repositories. Combining Online Judge (OJ) testing with LLM-assisted code review, the benchmark evaluates agents on (1) system architecture design,",
      "url": "https://arxiv.org/abs/2602.01655",
      "category": "cs.AI"
    },
    {
      "title": "FlowSteer: Interactive Agentic Workflow Orchestration via End-to-End Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.01664v2 Announce Type: replace \nAbstract: In recent years, a variety of powerful agentic workflows have been applied to solve a wide range of human problems. However, existing workflow orchestration still faces key challenges, including high manual cost, reliance on specific operators/large language models (LLMs), and sparse reward signals. To address these challenges, we propose FlowSteer, an end-to-end reinforcement learning framework that takes a lightweight policy model as the age",
      "url": "https://arxiv.org/abs/2602.01664",
      "category": "cs.AI"
    },
    {
      "title": "MACD: Model-Aware Contrastive Decoding via Counterfactual Data",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.01740v2 Announce Type: replace \nAbstract: Video language models (Video-LLMs) are prone to hallucinations, often generating plausible but ungrounded content when visual evidence is weak, ambiguous, or biased. Existing decoding methods, such as contrastive decoding (CD), rely on random perturbations to construct contrastive data for mitigating hallucination patterns. However, such a way is hard to control the visual cues that drive hallucination or well align with model weaknesses. We p",
      "url": "https://arxiv.org/abs/2602.01740",
      "category": "cs.AI"
    },
    {
      "title": "Beyond Quantity: Trajectory Diversity Scaling for Code Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.03219v2 Announce Type: replace \nAbstract: As code large language models (LLMs) evolve into tool-interactive agents via the Model Context Protocol (MCP), their generalization is increasingly limited by low-quality synthetic data and the diminishing returns of quantity scaling. Moreover, quantity-centric scaling exhibits an early bottleneck that underutilizes trajectory data. We propose TDScaling, a Trajectory Diversity Scaling-based data synthesis framework for code agents that scales ",
      "url": "https://arxiv.org/abs/2602.03219",
      "category": "cs.AI"
    },
    {
      "title": "AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.03786v2 Announce Type: replace \nAbstract: Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction that models any agent as a tuple Instruction, ",
      "url": "https://arxiv.org/abs/2602.03786",
      "category": "cs.AI"
    },
    {
      "title": "Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.03950v2 Announce Type: replace \nAbstract: Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although recent advances in multi-agent LLM-based systems have enhanced their mathematical reasoning capabilities, they still lack a reliably revisable representation of the reasoning process. Existing agen",
      "url": "https://arxiv.org/abs/2602.03950",
      "category": "cs.AI"
    },
    {
      "title": "Reactive Knowledge Representation and Asynchronous Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.05625v2 Announce Type: replace \nAbstract: Exact inference in complex probabilistic models often incurs prohibitive computational costs. This challenge is particularly acute for autonomous agents in dynamic environments that require frequent, real-time belief updates. Existing methods are often inefficient for ongoing reasoning, as they re-evaluate the entire model upon any change, failing to exploit that real-world information streams have heterogeneous update rates. To address this, ",
      "url": "https://arxiv.org/abs/2602.05625",
      "category": "cs.AI"
    },
    {
      "title": "Generative Ontology: When Structured Knowledge Learns to Create",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.05636v2 Announce Type: replace \nAbstract: Traditional ontologies describe domain structure but cannot generate novel artifacts. Large language models generate fluently but produce outputs lacking structural validity, hallucinating mechanisms without components, goals without end conditions. We introduce Generative Ontology, a framework synthesizing these complementary strengths: ontology provides the grammar; the LLM provides the creativity.\n  Generative Ontology encodes domain knowle",
      "url": "https://arxiv.org/abs/2602.05636",
      "category": "cs.AI"
    },
    {
      "title": "TKG-Thinker: Towards Dynamic Reasoning over Temporal Knowledge Graphs via Agentic Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.05818v2 Announce Type: replace \nAbstract: Temporal knowledge graph question answering (TKGQA) aims to answer time-sensitive questions by leveraging temporal knowledge bases. While Large Language Models (LLMs) demonstrate significant potential in TKGQA, current prompting strategies constrain their efficacy in two primary ways. First, they are prone to reasoning hallucinations under complex temporal constraints. Second, static prompting limits model autonomy and generalization, as it la",
      "url": "https://arxiv.org/abs/2602.05818",
      "category": "cs.AI"
    },
    {
      "title": "From Features to Actions: Explainability in Traditional and Agentic AI Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06841v2 Announce Type: replace \nAbstract: Over the last decade, explainable AI has primarily focused on interpreting individual model predictions, producing post-hoc explanations that relate inputs to outputs under a fixed decision structure. Recent advances in large language models (LLMs) have enabled agentic AI systems whose behaviour unfolds over multi-step trajectories. In these settings, success and failure are determined by sequences of decisions rather than a single output. Whi",
      "url": "https://arxiv.org/abs/2602.06841",
      "category": "cs.AI"
    },
    {
      "title": "AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06855v2 Announce Type: replace \nAbstract: LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks span diverse domains, including language modeling, mathematics, bioinformatics, and time series forecasting. AIRS-Bench tasks assess agentic capabilities over the full research lifecycle -- including",
      "url": "https://arxiv.org/abs/2602.06855",
      "category": "cs.AI"
    },
    {
      "title": "Playing 20 Question Game with Policy-Based Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:1808.07645v4 Announce Type: replace-cross \nAbstract: The 20 Questions (Q20) game is a well known game which encourages deductive reasoning and creativity. In the game, the answerer first thinks of an object such as a famous person or a kind of animal. Then the questioner tries to guess the object by asking 20 questions. In a Q20 game system, the user is considered as the answerer while the system itself acts as the questioner which requires a good strategy of question selection to figure o",
      "url": "https://arxiv.org/abs/1808.07645",
      "category": "cs.HC"
    },
    {
      "title": "YaRN: Efficient Context Window Extension of Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2309.00071v3 Announce Type: replace-cross \nAbstract: Rotary Position Embeddings (RoPE) have been shown to effectively encode positional information in transformer-based language models. However, these models fail to generalize past the sequence length they were trained on. We present YaRN (Yet another RoPE extensioN method), a compute-efficient method to extend the context window of such models, requiring 10x less tokens and 2.5x less training steps than previous methods. Using YaRN, we sh",
      "url": "https://arxiv.org/abs/2309.00071",
      "category": "cs.CL"
    },
    {
      "title": "DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided Image Editing",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2310.08785v3 Announce Type: replace-cross \nAbstract: Text-guided image editing faces significant challenges when considering training and inference flexibility. Much literature collects large amounts of annotated image-text pairs to train text-conditioned generative models from scratch, which is expensive and not efficient. After that, some approaches that leverage pre-trained vision-language models have been proposed to avoid data collection, but they are limited by either per text-prompt",
      "url": "https://arxiv.org/abs/2310.08785",
      "category": "cs.CV"
    },
    {
      "title": "Cognitive Edge Device (CED) for Real-Time Environmental Monitoring in Aquatic Ecosystems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2401.06157v3 Announce Type: replace-cross \nAbstract: Invasive signal crayfish have a detrimental impact on ecosystems. They spread the fungal-type crayfish plague disease (Aphanomyces astaci) that is lethal to the native white clawed crayfish, the only native crayfish species in Britain. Invasive signal crayfish extensively burrow, causing habitat destruction, erosion of river banks and adverse changes in water quality, while also competing with native species for resources leading to decl",
      "url": "https://arxiv.org/abs/2401.06157",
      "category": "cs.CV"
    },
    {
      "title": "Delay-Aware Reinforcement Learning for Highway On-Ramp Merging under Stochastic Communication Latency",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2403.11852v4 Announce Type: replace-cross \nAbstract: Delayed and partially observable state information poses significant challenges for reinforcement learning (RL)-based control in real-world autonomous driving. In highway on-ramp merging, a roadside unit (RSU) can sense nearby traffic, perform edge perception, and transmit state estimates to the ego vehicle over vehicle-to-infrastructure (V2I) links. With recent advancements in intelligent transportation infrastructure and edge computing",
      "url": "https://arxiv.org/abs/2403.11852",
      "category": "cs.RO"
    },
    {
      "title": "Towards Transparent and Efficient Anomaly Detection in Industrial Processes through ExIFFI",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2405.01158v3 Announce Type: replace-cross \nAbstract: Anomaly Detection (AD) is crucial in industrial settings to streamline operations by detecting underlying issues. Conventional methods merely label observations as normal or anomalous, lacking crucial insights. In Industry 5.0, interpretable outcomes become desirable to enable users to understand the rational under model decisions. This paper presents the first industrial application of ExIFFI, a recent approach for fast, efficient expla",
      "url": "https://arxiv.org/abs/2405.01158",
      "category": "cs.LG"
    },
    {
      "title": "Reproducible Benchmarking for Lung Nodule Detection and Malignancy Classification Across Multiple Low-Dose CT Datasets",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2405.04605v5 Announce Type: replace-cross \nAbstract: Evaluation of artificial intelligence (AI) models for low-dose CT lung cancer screening is limited by heterogeneous datasets, annotation standards, and evaluation protocols, making performance difficult to compare and translate across clinical settings. We establish a public, reproducible multi-dataset benchmark for lung nodule detection and nodule-level cancer classification and quantify cross-dataset generalizability.\n  Using the Duke ",
      "url": "https://arxiv.org/abs/2405.04605",
      "category": "cs.CV"
    },
    {
      "title": "Q-Learning under Finite Model Uncertainty",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2407.04259v3 Announce Type: replace-cross \nAbstract: We propose a robust Q-learning algorithm for Markov decision processes under model uncertainty when each state-action pair is associated with a finite ambiguity set of candidate transition kernels. This finite-measure framework enables highly flexible, user-designed uncertainty models and goes beyond the common KL and Wasserstein ball formulations. We establish almost sure convergence of the learned Q-function to the robust optimum, and ",
      "url": "https://arxiv.org/abs/2407.04259",
      "category": "math.OC"
    },
    {
      "title": "Why Rectified Power Unit Networks Fail and How to Improve It: An Effective Field Theory Perspective",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2408.02697v5 Announce Type: replace-cross \nAbstract: The Rectified Power Unit (RePU) activation function, a differentiable generalization of the Rectified Linear Unit (ReLU), has shown promise in constructing neural networks due to its smoothness properties. However, deep RePU networks often suffer from critical issues such as vanishing or exploding values during training, rendering them unstable regardless of hyperparameter initialization. Leveraging the perspective of effective field the",
      "url": "https://arxiv.org/abs/2408.02697",
      "category": "cs.LG"
    },
    {
      "title": "Optimizing Automated Picking Systems in Warehouse Robots Using Machine Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2408.16633v2 Announce Type: replace-cross \nAbstract: With the rapid growth of global e-commerce, the demand for automation in the logistics industry is increasing. This study focuses on automated picking systems in warehouses, utilizing deep learning and reinforcement learning technologies to enhance picking efficiency and accuracy while reducing system failure rates. Through empirical analysis, we demonstrate the effectiveness of these technologies in improving robot picking performance a",
      "url": "https://arxiv.org/abs/2408.16633",
      "category": "cs.RO"
    },
    {
      "title": "ComfyBench: Benchmarking LLM-based Agents in ComfyUI for Autonomously Designing Collaborative AI Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2409.01392v3 Announce Type: replace-cross \nAbstract: Much previous AI research has focused on developing monolithic models to maximize their intelligence, with the primary goal of enhancing performance on specific tasks. In contrast, this work attempts to study using LLM-based agents to design collaborative AI systems autonomously. To explore this problem, we first introduce ComfyBench to evaluate agents's ability to design collaborative AI systems in ComfyUI. ComfyBench is a comprehensive",
      "url": "https://arxiv.org/abs/2409.01392",
      "category": "cs.CL"
    },
    {
      "title": "RARe: Retrieval Augmented Retrieval with In-Context Examples",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2410.20088v2 Announce Type: replace-cross \nAbstract: While in-context learning is well-studied with decoder-only language models (LLMs), its utility for encoder-only models remains underexplored. We study in-context learning for encoder-only models for text retrieval tasks. Can incorporating in-context examples (query-document pairs) to the target query enhance retriever performance? Our approach, RARe, finetunes a pre-trained model with in-context examples whose query is semantically simi",
      "url": "https://arxiv.org/abs/2410.20088",
      "category": "cs.CL"
    },
    {
      "title": "Software Performance Engineering for Foundation Model-Powered Software",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2411.09580v2 Announce Type: replace-cross \nAbstract: The rise of Foundation Models (FMs) like Large Language Models (LLMs) is revolutionizing software development. Despite the impressive prototypes, transforming FMware into production-ready products demands complex engineering across various domains. A critical but overlooked aspect is performance engineering, which aims at ensuring FMware meets performance goals such as throughput and latency to avoid user dissatisfaction and financial lo",
      "url": "https://arxiv.org/abs/2411.09580",
      "category": "cs.SE"
    },
    {
      "title": "Disentangled Parameter-Efficient Linear Model for Long-Term Time Series Forecasting",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2411.17257v2 Announce Type: replace-cross \nAbstract: Long-term Time Series Forecasting (LTSF) is crucial across various domains, but complex deep models like Transformers are often prone to overfitting on extended sequences. Linear Fully Connected models have emerged as a powerful alternative, achieving competitive results with fewer parameters. However, their reliance on a single, monolithic weight matrix leads to quadratic parameter redundancy and an entanglement of temporal and frequent",
      "url": "https://arxiv.org/abs/2411.17257",
      "category": "cs.LG"
    },
    {
      "title": "SoK: Blockchain-Based Decentralized AI (DeAI)",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2411.17461v5 Announce Type: replace-cross \nAbstract: Centralization enhances the efficiency of Artificial Intelligence (AI) but also introduces critical challenges, including single points of failure, inherent biases, data privacy risks, and scalability limitations. To address these issues, blockchain-based Decentralized Artificial Intelligence (DeAI) has emerged as a promising paradigm that leverages decentralization and transparency to improve the trustworthiness of AI systems. Despite r",
      "url": "https://arxiv.org/abs/2411.17461",
      "category": "cs.LG"
    },
    {
      "title": "DeMo: Decoupled Momentum Optimization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2411.19870v2 Announce Type: replace-cross \nAbstract: Scaling neural network training increasingly depends on synchronous data-parallelism, yet full-precision gradient all-reduce imposes a severe communication bottleneck. We propose Decoupled Momentum Optimization (DeMo), a drop-in replacement for any momentum-based optimizers that significantly reduces the communication bandwidth while maintaining convergence. DeMo (i) decouples local momentum updates, (ii) applies a fast orthonormal trans",
      "url": "https://arxiv.org/abs/2411.19870",
      "category": "cs.LG"
    },
    {
      "title": "Automatic Item Generation for Personality Situational Judgment Tests with Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2412.12144v4 Announce Type: replace-cross \nAbstract: Personality assessment through situational judgment tests (SJTs) offers unique advantages over traditional Likert-type self-report scales, yet their development remains labor-intensive, time-consuming, and heavily dependent on subject matter experts. Recent advances in large language models (LLMs) have shown promise for automatic item generation (AIG). Building on these developments, the present study focuses on developing and evaluating",
      "url": "https://arxiv.org/abs/2412.12144",
      "category": "cs.CL"
    },
    {
      "title": "AI-Powered Intracranial Hemorrhage Detection: A Co-Scale Convolutional Attention Model with Uncertainty-Based Fuzzy Integral Operator and Feature Screening",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2412.14869v2 Announce Type: replace-cross \nAbstract: Intracranial hemorrhage (ICH) refers to the leakage or accumulation of blood within the skull, which occurs due to the rupture of blood vessels in or around the brain. If this condition is not diagnosed in a timely manner and appropriately treated, it can lead to serious complications such as decreased consciousness, permanent neurological disabilities, or even death.The primary aim of this study is to detect the occurrence or non-occurr",
      "url": "https://arxiv.org/abs/2412.14869",
      "category": "cs.CV"
    },
    {
      "title": "LEASE: Offline Preference-based Reinforcement Learning with High Sample Efficiency",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2412.21001v3 Announce Type: replace-cross \nAbstract: Offline preference-based reinforcement learning (PbRL) provides an effective way to overcome the challenges of designing reward and the high costs of online interaction. However, since labeling preference needs real-time human feedback, acquiring sufficient preference labels is challenging. To solve this, this paper proposes a offLine prEference-bAsed RL with high Sample Efficiency (LEASE) algorithm, where a learned transition model is l",
      "url": "https://arxiv.org/abs/2412.21001",
      "category": "cs.LG"
    },
    {
      "title": "Evaluating Sample Utility for Efficient Data Selection by Mimicking Model Weights",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2501.06708v4 Announce Type: replace-cross \nAbstract: Large-scale web-crawled datasets contain noise, bias, and irrelevant information, necessitating data selection techniques. Existing methods depend on hand-crafted heuristics, downstream datasets, or require expensive influence-based computations -- all of which limit scalability and introduce unwanted data dependencies. To address this, we introduce the Mimic Score, a simple and geometry-based data-quality metric that evaluates utility b",
      "url": "https://arxiv.org/abs/2501.06708",
      "category": "cs.LG"
    },
    {
      "title": "Rigor, Reliability, and Reproducibility Matter: A Decade-Scale Survey of 572 Code Benchmarks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2501.10711v4 Announce Type: replace-cross \nAbstract: Code-related benchmarks play a critical role in evaluating large language models (LLMs), yet their quality fundamentally shapes how the community interprets model capabilities. In the past few years, awareness of benchmark quality has grown. Yet, after a decade-scale (2014-2025) survey over 572 code benchmarks, we observed a lag between growing awareness and actual practice. For example, in 2025 alone, the number of benchmarks that ignor",
      "url": "https://arxiv.org/abs/2501.10711",
      "category": "cs.SE"
    },
    {
      "title": "Rethinking Functional Brain Connectome Analysis: Do Graph Deep Learning Models Help",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2501.17207v2 Announce Type: replace-cross \nAbstract: Graph deep learning models, a class of AI-driven approaches employing a message aggregation mechanism, have gained popularity for analyzing the functional brain connectome in neuroimaging. However, their actual effectiveness remains unclear. In this study, we re-examine graph deep learning versus classical machine learning models based on four large-scale neuroimaging studies. Surprisingly, we find that the message aggregation mechanism,",
      "url": "https://arxiv.org/abs/2501.17207",
      "category": "cs.NE"
    },
    {
      "title": "SafeDialBench: A Fine-Grained Safety Evaluation Benchmark for Large Language Models in Multi-Turn Dialogues with Diverse Jailbreak Attacks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2502.11090v4 Announce Type: replace-cross \nAbstract: With the rapid advancement of Large Language Models (LLMs), the safety of LLMs has been a critical concern requiring precise assessment. Current benchmarks primarily concentrate on single-turn dialogues or a single jailbreak attack method to assess the safety. Additionally, these benchmarks have not taken into account the LLM's capability of identifying and handling unsafe information in detail. To address these issues, we propose a fine",
      "url": "https://arxiv.org/abs/2502.11090",
      "category": "cs.CL"
    },
    {
      "title": "ExpliCa: Evaluating Explicit Causal Reasoning in Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2502.15487v4 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) are increasingly used in tasks requiring interpretive and inferential accuracy. In this paper, we introduce ExpliCa, a new dataset for evaluating LLMs in explicit causal reasoning. ExpliCa uniquely integrates both causal and temporal relations presented in different linguistic orders and explicitly expressed by linguistic connectives. The dataset is enriched with crowdsourced human acceptability ratings. We t",
      "url": "https://arxiv.org/abs/2502.15487",
      "category": "cs.CL"
    },
    {
      "title": "The Geometry of Refusal in Large Language Models: Concept Cones and Representational Independence",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2502.17420v2 Announce Type: replace-cross \nAbstract: The safety alignment of large language models (LLMs) can be circumvented through adversarially crafted inputs, yet the mechanisms by which these attacks bypass safety barriers remain poorly understood. Prior work suggests that a single refusal direction in the model's activation space determines whether an LLM refuses a request. In this study, we propose a novel gradient-based approach to representation engineering and use it to identify",
      "url": "https://arxiv.org/abs/2502.17420",
      "category": "cs.LG"
    },
    {
      "title": "MAFE: Enabling Equitable Algorithm Design in Multi-Agent Multi-Stage Decision-Making Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2502.18534v2 Announce Type: replace-cross \nAbstract: Algorithmic fairness is often studied in static or single-agent settings, yet many real-world decision-making systems involve multiple interacting entities whose multi-stage actions jointly influence long-term outcomes. Existing fairness methods applied at isolated decision points frequently fail to mitigate disparities that accumulate over time. Although recent work has modeled fairness as a sequential decision-making problem, it typica",
      "url": "https://arxiv.org/abs/2502.18534",
      "category": "cs.MA"
    },
    {
      "title": "Marking Code Without Breaking It: Code Watermarking for Detecting LLM-Generated Code",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2502.18851v4 Announce Type: replace-cross \nAbstract: Identifying LLM-generated code through watermarking poses a challenge in preserving functional correctness. Previous methods rely on the assumption that watermarking high-entropy tokens effectively maintains output quality. Our analysis reveals a fundamental limitation of this assumption: syntax-critical tokens such as keywords often exhibit the highest entropy, making existing approaches vulnerable to logic corruption. We present STONE,",
      "url": "https://arxiv.org/abs/2502.18851",
      "category": "cs.CR"
    },
    {
      "title": "Taxation Perspectives from Large Language Models: A Case Study on Additional Tax Penalties",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2503.03444v2 Announce Type: replace-cross \nAbstract: How capable are large language models (LLMs) in the domain of taxation? Although numerous studies have explored the legal domain, research dedicated to taxation remains scarce. Moreover, the datasets used in these studies are either simplified, failing to reflect the real-world complexities, or not released as open-source. To address this gap, we introduce PLAT, a new benchmark designed to assess the ability of LLMs to predict the legiti",
      "url": "https://arxiv.org/abs/2503.03444",
      "category": "cs.CL"
    },
    {
      "title": "RiskAgent: Synergizing Language Models with Validated Tools for Evidence-Based Risk Prediction",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2503.03802v2 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) achieve competitive results compared to human experts in medical examinations. However, it remains a challenge to apply LLMs to complex clinical decision-making, which requires a deep understanding of medical knowledge and differs from the standardized, exam-style scenarios commonly used in current efforts. A common approach is to fine-tune LLMs for target tasks, which, however, not only requires substantial ",
      "url": "https://arxiv.org/abs/2503.03802",
      "category": "cs.LG"
    },
    {
      "title": "Capacity-Aware Inference: Mitigating the Straggler Effect in Mixture of Experts",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2503.05066v4 Announce Type: replace-cross \nAbstract: The Mixture of Experts (MoE) is an effective architecture for scaling large language models by leveraging sparse expert activation to balance performance and efficiency. However, under expert parallelism, MoE suffers from inference inefficiencies due to imbalanced token-to-expert assignment, where underloaded experts complete computations early but must wait for overloaded experts, leading to global delays. We define this phenomenon as t",
      "url": "https://arxiv.org/abs/2503.05066",
      "category": "cs.LG"
    },
    {
      "title": "Right Reward Right Time for Federated Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2503.07869v2 Announce Type: replace-cross \nAbstract: Critical learning periods (CLPs) in federated learning (FL) refer to early stages during which low-quality contributions (e.g., sparse training data availability) can permanently impair the performance of the global model owned by the model owner (i.e., a cloud server). However, existing incentive mechanisms exhibit temporal homogeneity, treating all training rounds as equally important, thereby failing to prioritize and attract high-qua",
      "url": "https://arxiv.org/abs/2503.07869",
      "category": "cs.LG"
    },
    {
      "title": "Vision Transformer for Intracranial Hemorrhage Classification in CT Scans Using an Entropy-Aware Fuzzy Integral Strategy for Adaptive Scan-Level Decision Fusion",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2503.08609v2 Announce Type: replace-cross \nAbstract: Intracranial hemorrhage (ICH) is a critical medical emergency caused by the rupture of cerebral blood vessels, leading to internal bleeding within the skull. Accurate and timely classification of hemorrhage subtypes is essential for effective clinical decision-making. To address this challenge, we propose an advanced pyramid vision transformer (PVT)-based model, leveraging its hierarchical attention mechanisms to capture both local and g",
      "url": "https://arxiv.org/abs/2503.08609",
      "category": "eess.IV"
    },
    {
      "title": "TruthPrInt: Mitigating Large Vision-Language Models Object Hallucination Via Latent Truthful-Guided Pre-Intervention",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2503.10602v3 Announce Type: replace-cross \nAbstract: Object Hallucination (OH) has been acknowledged as one of the major trustworthy challenges in Large Vision-Language Models (LVLMs). Recent advancements in Large Language Models (LLMs) indicate that internal states, such as hidden states, encode the \"overall truthfulness\" of generated responses. However, it remains under-explored how internal states in LVLMs function and whether they could serve as \"per-token\" hallucination indicators, wh",
      "url": "https://arxiv.org/abs/2503.10602",
      "category": "cs.CV"
    },
    {
      "title": "Adversarial Wear and Tear: Exploiting Natural Damage for Generating Physical-World Adversarial Examples",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2503.21164v2 Announce Type: replace-cross \nAbstract: The presence of adversarial examples in the physical world poses significant challenges to the deployment of Deep Neural Networks in safety-critical applications such as autonomous driving. Most existing methods for crafting physical-world adversarial examples are ad-hoc, relying on temporary modifications like shadows, laser beams, or stickers that are tailored to specific scenarios. In this paper, we introduce a new class of physical-w",
      "url": "https://arxiv.org/abs/2503.21164",
      "category": "cs.CV"
    },
    {
      "title": "Achieving Unanimous Consensus Through Multi-Agent Deliberation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2504.02128v2 Announce Type: replace-cross \nAbstract: Blockchain consensus mechanisms have relied on algorithms such as Proof-of-Work (PoW) and Proof-of-Stake (PoS) to ensure network functionality and integrity. However, these approaches struggle with adaptability for decision-making where the opinions of each matter rather than reaching an agreement based on honest majority or weighted consensus. This paper introduces a novel deliberation-based consensus mechanism where Large Language Mode",
      "url": "https://arxiv.org/abs/2504.02128",
      "category": "cs.MA"
    },
    {
      "title": "Towards an Understanding of Context Utilization in Code Intelligence",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2504.08734v2 Announce Type: replace-cross \nAbstract: Code intelligence is an emerging domain in software engineering, aiming to improve the effectiveness and efficiency of various code-related tasks. Recent research suggests that incorporating contextual information beyond the basic original task inputs (i.e., source code) can substantially enhance model performance. Such contextual signals may be obtained directly or indirectly from sources such as API documentation or intermediate repres",
      "url": "https://arxiv.org/abs/2504.08734",
      "category": "cs.SE"
    },
    {
      "title": "Integrating Structural and Semantic Signals in Text-Attributed Graphs with BiGTex",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2504.12474v4 Announce Type: replace-cross \nAbstract: Text-attributed graphs (TAGs) present unique challenges in representation learning by requiring models to capture both the semantic richness of node-associated texts and the structural dependencies of the graph. While graph neural networks (GNNs) excel at modeling topological information, they lack the capacity to process unstructured text. Conversely, large language models (LLMs) are proficient in text understanding but are typically un",
      "url": "https://arxiv.org/abs/2504.12474",
      "category": "cs.CL"
    },
    {
      "title": "Toward Efficient Exploration by Large Language Model Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2504.20997v2 Announce Type: replace-cross \nAbstract: A burgeoning area within reinforcement learning (RL) is the design of sequential decision-making agents centered around large language models (LLMs). While autonomous decision-making agents powered by modern LLMs could facilitate numerous real-world applications, such successes demand agents that are capable of data-efficient RL. One key obstacle to achieving data efficiency in RL is exploration, a challenge that we demonstrate many rece",
      "url": "https://arxiv.org/abs/2504.20997",
      "category": "cs.LG"
    },
    {
      "title": "Dynamic and Distributed Routing in IoT Networks based on Multi-Objective Q-Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2505.00918v5 Announce Type: replace-cross \nAbstract: IoT networks often face conflicting routing goals such as maximizing packet delivery, minimizing delay, and conserving limited battery energy. These priorities can also change dynamically: for example, an emergency alert requires high reliability, while routine monitoring prioritizes energy efficiency to prolong network lifetime. Existing works, including many deep reinforcement learning approaches, are typically centralized and assume s",
      "url": "https://arxiv.org/abs/2505.00918",
      "category": "cs.DC"
    },
    {
      "title": "Systematic Failures in Collective Reasoning under Distributed Information in Multi-Agent LLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2505.11556v3 Announce Type: replace-cross \nAbstract: Multi-agent systems built on large language models (LLMs) are expected to enhance decision-making by pooling distributed information, yet systematically evaluating this capability has remained challenging. We introduce HiddenBench, a 65-task benchmark grounded in the Hidden Profile paradigm, which isolates collective reasoning under distributed information from individual reasoning ability. Evaluating 15 frontier LLMs, we find that multi",
      "url": "https://arxiv.org/abs/2505.11556",
      "category": "cs.CL"
    },
    {
      "title": "Dist2ill: Distributional Distillation for One-Pass Uncertainty Estimation in Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2505.11731v3 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) often exhibit misalignment between the quality of their generated responses and the confidence estimates they assign to them. Bayesian treatments, such as marginalizing over a reliable weight posterior or over the space of reasoning traces, provide an effective remedy, but incur substantial computational overhead due to repeated sampling at test time. To enable accurate uncertainty estimation in a single forw",
      "url": "https://arxiv.org/abs/2505.11731",
      "category": "cs.LG"
    },
    {
      "title": "Safety Subspaces are Not Linearly Distinct: A Fine-Tuning Case Study",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2505.14185v3 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) rely on safety alignment to produce socially acceptable responses. However, this behavior is known to be brittle: further fine-tuning, even on benign or lightly contaminated data, can degrade safety and reintroduce harmful behaviors. A growing body of work suggests that alignment may correspond to identifiable directions in weight space, forming subspaces that could, in principle, be isolated or preserved to ",
      "url": "https://arxiv.org/abs/2505.14185",
      "category": "cs.LG"
    },
    {
      "title": "ABBA-Adapters: Efficient and Expressive Fine-Tuning of Foundation Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2505.14238v4 Announce Type: replace-cross \nAbstract: Large Language Models have demonstrated strong performance across a wide range of tasks, but adapting them efficiently to new domains remains a key challenge. Parameter-Efficient Fine-Tuning (PEFT) methods address this by introducing lightweight, trainable modules while keeping most pre-trained weights fixed. The prevailing approach, LoRA, models updates using a low-rank decomposition, but its expressivity is inherently constrained by th",
      "url": "https://arxiv.org/abs/2505.14238",
      "category": "cs.CL"
    },
    {
      "title": "PiFlow: Principle-Aware Scientific Discovery with Multi-Agent Collaboration",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2505.15047v4 Announce Type: replace-cross \nAbstract: Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate remarkable potential for scientific discovery. Existing approaches, however, often automate scientific discovery using predefined workflows that lack rationality constraints. This often leads to aimless hypothesizing and a failure to consistently link hypotheses with evidence, thereby hindering the systematic reduction of uncertainty. Overcoming these limitations fund",
      "url": "https://arxiv.org/abs/2505.15047",
      "category": "cs.LG"
    },
    {
      "title": "Efficient Policy Optimization in Robust Constrained MDPs with Iteration Complexity Guarantees",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2505.19238v3 Announce Type: replace-cross \nAbstract: Constrained decision-making is essential for designing safe policies in real-world control systems, yet simulated environments often fail to capture real-world adversities. We consider the problem of learning a policy that will maximize the cumulative reward while satisfying a constraint, even when there is a mismatch between the real model and an accessible simulator/nominal model. In particular, we consider the robust constrained Marko",
      "url": "https://arxiv.org/abs/2505.19238",
      "category": "cs.LG"
    },
    {
      "title": "Can NeRFs See without Cameras?",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2505.22441v3 Announce Type: replace-cross \nAbstract: Neural Radiance Fields (NeRFs) have been remarkably successful at synthesizing novel views of 3D scenes by optimizing a volumetric scene function. This scene function models how optical rays bring color information from a 3D object to the camera pixels. Radio frequency (RF) or audio signals can also be viewed as a vehicle for delivering information about the environment to a sensor. However, unlike camera pixels, an RF/audio sensor recei",
      "url": "https://arxiv.org/abs/2505.22441",
      "category": "cs.CV"
    },
    {
      "title": "Who Gets Credit or Blame? Attributing Accountability in Modern AI Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2506.00175v4 Announce Type: replace-cross \nAbstract: Modern AI systems are typically developed through multiple stages-pretraining, fine-tuning rounds, and subsequent adaptation or alignment, where each stage builds on the previous ones and updates the model in distinct ways. This raises a critical question of accountability: when a deployed model succeeds or fails, which stage is responsible, and to what extent? We pose the accountability attribution problem for tracing model behavior bac",
      "url": "https://arxiv.org/abs/2506.00175",
      "category": "cs.LG"
    },
    {
      "title": "AlphaSteer: Learning Refusal Steering with Principled Null-Space Constraint",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2506.07022v2 Announce Type: replace-cross \nAbstract: As LLMs are increasingly deployed in real-world applications, ensuring their ability to refuse malicious prompts, especially jailbreak attacks, is essential for safe and reliable use. Recently, activation steering has emerged as an effective approach for enhancing LLM safety by adding a refusal direction vector to internal activations of LLMs during inference, which will further induce the refusal behaviors of LLMs. However, indiscrimina",
      "url": "https://arxiv.org/abs/2506.07022",
      "category": "cs.LG"
    },
    {
      "title": "Task-Conditioned Probing Reveals Brain-Alignment Patterns in Instruction-Tuned Multimodal LLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2506.08277v2 Announce Type: replace-cross \nAbstract: Recent voxel-wise multimodal brain encoding studies have shown that multimodal large language models (MLLMs) exhibit a higher degree of brain alignment compared to unimodal models. More recently, instruction-tuned multimodal (IT) models have been shown to generate task-specific representations that align strongly with brain activity, yet most prior evaluations focus on unimodal stimuli or non-instruction-tuned models under multimodal sti",
      "url": "https://arxiv.org/abs/2506.08277",
      "category": "q-bio.NC"
    },
    {
      "title": "Beyond Bias Scores: Unmasking Vacuous Neutrality in Small Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2506.08487v3 Announce Type: replace-cross \nAbstract: The rapid adoption of Small Language Models (SLMs) for resource constrained applications has outpaced our understanding of their ethical and fairness implications. To address this gap, we introduce the Vacuous Neutrality Framework (VaNeu), a multi-dimensional evaluation paradigm designed to assess SLM fairness prior to deployment. The framework examines model robustness across four stages - biases, utility, ambiguity handling, and positi",
      "url": "https://arxiv.org/abs/2506.08487",
      "category": "cs.CL"
    },
    {
      "title": "Language Bottleneck Models for Qualitative Knowledge State Modeling",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2506.16982v2 Announce Type: replace-cross \nAbstract: Accurately assessing student knowledge is central to education. Cognitive Diagnosis (CD) models estimate student proficiency at a fixed point in time, while Knowledge Tracing (KT) methods model evolving knowledge states to predict future performance. However, existing approaches either provide quantitative concept mastery estimates with limited expressivity (CD, probabilistic KT) or prioritize predictive accuracy at the cost of interpret",
      "url": "https://arxiv.org/abs/2506.16982",
      "category": "cs.CL"
    },
    {
      "title": "These Are Not All the Features You Are Looking For: A Fundamental Bottleneck in Supervised Pretraining",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2506.18221v3 Announce Type: replace-cross \nAbstract: Transfer learning is widely used to adapt large pretrained models to new tasks with only a small amount of new data. However, a challenge persists -- the features from the original task often do not fully cover what is needed for unseen data, especially when the relatedness of tasks is not clear. Since deep learning models tend to learn very sparse representations, they retain only the minimal features required for the initial training w",
      "url": "https://arxiv.org/abs/2506.18221",
      "category": "cs.LG"
    },
    {
      "title": "mTSBench: Benchmarking Multivariate Time Series Anomaly Detection and Model Selection at Scale",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2506.21550v2 Announce Type: replace-cross \nAbstract: Anomaly detection in multivariate time series is essential across domains such as healthcare, cybersecurity, and industrial monitoring, yet remains fundamentally challenging due to high-dimensional dependencies, the presence of cross-correlations between time-dependent variables, and the scarcity of labeled anomalies. We introduce mTSBench, the largest benchmark to date for multivariate time series anomaly detection and model selection, ",
      "url": "https://arxiv.org/abs/2506.21550",
      "category": "cs.LG"
    },
    {
      "title": "Theoretical Modeling of Large Language Model Self-Improvement Training Dynamics Through Solver-Verifier Gap",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2507.00075v4 Announce Type: replace-cross \nAbstract: Self-improvement is a significant techniques within the realm of large language model (LLM), aiming to enhance the LLM performance without relying on external data. Despite its significance, generally how LLM performances evolve during the self-improvement process remains underexplored. In this paper, we theoretically model the training dynamics of self-improvement via the concept of solver-verifier gap. This is inspired by the conjectur",
      "url": "https://arxiv.org/abs/2507.00075",
      "category": "cs.LG"
    },
    {
      "title": "Optimas: Optimizing Compound AI Systems with Globally Aligned Local Rewards",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2507.03041v4 Announce Type: replace-cross \nAbstract: Compound AI systems integrating multiple components, such as Large Language Models, specialized tools, and traditional machine learning models, are increasingly deployed to solve complex real-world tasks. However, optimizing compound systems remains challenging due to their non-differentiable structures and diverse configuration types across components, including prompts, hyperparameters, and model parameters. To address this challenge, ",
      "url": "https://arxiv.org/abs/2507.03041",
      "category": "cs.LG"
    },
    {
      "title": "MedVAL: Toward Expert-Level Medical Text Validation with Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2507.03152v5 Announce Type: replace-cross \nAbstract: With the growing use of language models (LMs) in clinical environments, there is an immediate need to evaluate the accuracy and safety of LM-generated medical text. Currently, such evaluation relies solely on manual physician review. However, detecting errors in LM-generated text is challenging because 1) manual review is costly and 2) expert-composed reference outputs are often unavailable in real-world settings. While the \"LLM-as-a-jud",
      "url": "https://arxiv.org/abs/2507.03152",
      "category": "cs.CL"
    },
    {
      "title": "Sequential Attention-based Sampling for Histopathological Analysis",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2507.05077v4 Announce Type: replace-cross \nAbstract: Deep neural networks are increasingly applied in automated histopathology. Yet, whole-slide images (WSIs) are often acquired at gigapixel sizes, rendering them computationally infeasible to analyze entirely at high resolution. Diagnostic labels are largely available only at the slide-level, because expert annotation of images at a finer (patch) level is both laborious and expensive. Moreover, regions with diagnostic information typically",
      "url": "https://arxiv.org/abs/2507.05077",
      "category": "eess.IV"
    },
    {
      "title": "DRAGOn: Designing RAG On Periodically Updated Corpus",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2507.05713v3 Announce Type: replace-cross \nAbstract: This paper introduces DRAGOn, method to design a RAG benchmark on a regularly updated corpus. It features recent reference datasets, a question generation framework, an automatic evaluation pipeline, and a public leaderboard. Specified reference datasets allow for uniform comparison of RAG systems, while newly generated dataset versions mitigate data leakage and ensure that all models are evaluated on unseen, comparable data. The pipelin",
      "url": "https://arxiv.org/abs/2507.05713",
      "category": "cs.CL"
    },
    {
      "title": "XiChen: A global weather observation-to-forecast machine learning system via four-dimensional variational gradient-guided flexible assimilation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2507.09202v3 Announce Type: replace-cross \nAbstract: Machine Learning (ML) has shown great promise in revolutionizing weather forecasting, yet most ML systems still rely on initial conditions generated by Numerical Weather Prediction (NWP) systems. End-to-end ML models aim to eliminate this dependency, but they often rely on observation-specific encoders and require redesign or retraining when observation sources change, thereby limiting their operational robustness. Here, we introduce XiC",
      "url": "https://arxiv.org/abs/2507.09202",
      "category": "cs.LG"
    },
    {
      "title": "Evolution of Fear and Social Rewards in Prey-Predator Relationship",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2507.09992v2 Announce Type: replace-cross \nAbstract: Fear is a critical brain function that enables us to learn to avoid danger via reinforcement learning (RL). While many researchers have argued that fear has evolved to escape predators, how varying predatory pressures have shaped fear and other rewards, including positive social rewards for collective grouping, remains an open question. In this study, we investigate the relationship between predatory pressure and fear using an evolutiona",
      "url": "https://arxiv.org/abs/2507.09992",
      "category": "q-bio.PE"
    },
    {
      "title": "NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2507.12412v2 Announce Type: replace-cross \nAbstract: In many critical domains, features are not freely available at inference time: each measurement may come with a cost of time, money, and risk. Longitudinal prediction further complicates this setting because both features and labels evolve over time, and missing measurements at earlier timepoints may become permanently unavailable. We propose NOCTA, a Non-Greedy Objective Cost-Tradeoff Acquisition framework that sequentially acquires the",
      "url": "https://arxiv.org/abs/2507.12412",
      "category": "cs.LG"
    },
    {
      "title": "\"PhyWorldBench\": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2507.13428v2 Announce Type: replace-cross \nAbstract: Video generation models have achieved remarkable progress in creating high-quality, photorealistic content. However, their ability to accurately simulate physical phenomena remains a critical and unresolved challenge. This paper presents PhyWorldBench, a comprehensive benchmark designed to evaluate video generation models based on their adherence to the laws of physics. The benchmark covers multiple levels of physical phenomena, ranging ",
      "url": "https://arxiv.org/abs/2507.13428",
      "category": "cs.CV"
    },
    {
      "title": "SegQuant: A Semantics-Aware and Generalizable Quantization Framework for Diffusion Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2507.14811v5 Announce Type: replace-cross \nAbstract: Diffusion models have demonstrated exceptional generative capabilities but are computationally intensive, posing significant challenges for deployment in resource-constrained or latency-sensitive environments. Quantization offers an effective means to reduce model size and computational cost, with post-training quantization (PTQ) being particularly appealing due to its compatibility with pre-trained models without requiring retraining or",
      "url": "https://arxiv.org/abs/2507.14811",
      "category": "cs.CV"
    },
    {
      "title": "Efficient Attention Mechanisms for Large Language Models: A Survey",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2507.19595v3 Announce Type: replace-cross \nAbstract: Transformer-based architectures have become the prevailing backbone of large language models. However, the quadratic time and memory complexity of self-attention remains a fundamental obstacle to efficient long-context modeling. To address this limitation, recent research has introduced two principal categories of efficient attention mechanisms. Linear attention methods achieve linear complexity through kernel approximations, recurrent f",
      "url": "https://arxiv.org/abs/2507.19595",
      "category": "cs.CL"
    },
    {
      "title": "A Parallel Alternative for Energy-Efficient Neural Network Training and Inferencing",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2508.00960v2 Announce Type: replace-cross \nAbstract: Energy efficiency of training and inferencing with large neural network models is a critical challenge facing the future of sustainable large-scale machine learning workloads. This paper introduces an alternative strategy, called phantom parallelism, to minimize the net energy consumption of traditional tensor (model) parallelism, the most energy-inefficient component of large neural network training. The approach is presented in the con",
      "url": "https://arxiv.org/abs/2508.00960",
      "category": "cs.LG"
    },
    {
      "title": "TensorHyper-VQC: A Tensor-Train-Guided Hypernetwork for Robust and Scalable Variational Quantum Computing",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2508.01116v4 Announce Type: replace-cross \nAbstract: Variational Quantum Computing (VQC) faces fundamental scalability barriers, primarily due to barren plateaus and sensitivity to quantum noise. To address these challenges, we introduce TensorHyper-VQC, a novel tensor-train (TT)-guided hypernetwork framework that significantly improves the robustness and scalability of VQC. Our framework fully delegates the generation of quantum-circuit parameters to a classical TT network, thereby decoup",
      "url": "https://arxiv.org/abs/2508.01116",
      "category": "quant-ph"
    },
    {
      "title": "Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2508.05342v2 Announce Type: replace-cross \nAbstract: Teaching robots dexterous skills from human videos remains challenging due to the reliance on low-level trajectory imitation, which fails to generalize across object types, spatial layouts, and manipulator configurations. We propose Graph-Fused Vision-Language-Action (GF-VLA), a framework that enables dual-arm robotic systems to perform task-level reasoning and execution directly from RGB and Depth human demonstrations. GF-VLA first extr",
      "url": "https://arxiv.org/abs/2508.05342",
      "category": "cs.RO"
    },
    {
      "title": "Hyperspectral Imaging",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2508.08107v2 Announce Type: replace-cross \nAbstract: Hyperspectral imaging (HSI) is an advanced sensing modality that simultaneously captures spatial and spectral information, enabling non-invasive, label-free analysis of material, chemical, and biological properties. This Primer presents a comprehensive overview of HSI, from the underlying physical principles and sensor architectures to key steps in data acquisition, calibration, and correction. We summarize common data structures and hig",
      "url": "https://arxiv.org/abs/2508.08107",
      "category": "cs.CV"
    },
    {
      "title": "Benchmarking Large Language Models for Geolocating Colonial Virginia Land Grants",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2508.08266v2 Announce Type: replace-cross \nAbstract: Virginia's seventeenth- and eighteenth-century land patents survive primarily as narrative metes-and-bounds descriptions, limiting spatial analysis. This study systematically evaluates current-generation large language models (LLMs) in converting these prose abstracts into geographically accurate latitude/longitude coordinates within a focused evaluation context. A digitized corpus of 5,471 Virginia patent abstracts (1695-1732) is releas",
      "url": "https://arxiv.org/abs/2508.08266",
      "category": "cs.LG"
    },
    {
      "title": "DegDiT: Controllable Audio Generation with Dynamic Event Graph Guided Diffusion Transformer",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2508.13786v2 Announce Type: replace-cross \nAbstract: Controllable text-to-audio generation aims to synthesize audio from textual descriptions while satisfying user-specified constraints, including event types, temporal sequences, and onset and offset timestamps. This enables precise control over both the content and temporal structure of the generated audio. Despite recent progress, existing methods still face inherent trade-offs among accurate temporal localization, open-vocabulary scalab",
      "url": "https://arxiv.org/abs/2508.13786",
      "category": "cs.SD"
    },
    {
      "title": "Beyond the Mean: Fisher-Orthogonal Projection for Natural Gradient Descent in Large Batch Training",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2508.13898v3 Announce Type: replace-cross \nAbstract: Modern GPUs are equipped with large amounts of high-bandwidth memory, enabling them to support mini-batch sizes of up to tens of thousands of training samples. However, most existing optimizers struggle to perform effectively at such a large batch size. As batch size increases, gradient noise decreases due to averaging over many samples, limiting the ability of first-order methods to escape sharp or suboptimal minima and reach the global",
      "url": "https://arxiv.org/abs/2508.13898",
      "category": "cs.LG"
    },
    {
      "title": "Your Reward Function for RL is Your Best PRM for Search: Unifying RL and Search-Based TTS",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2508.14313v3 Announce Type: replace-cross \nAbstract: Test-time scaling (TTS) for large language models (LLMs) has thus far fallen into two largely separate paradigms: (1) reinforcement learning (RL) methods that optimize sparse outcome-based rewards, yet suffer from instability and low sample efficiency; and (2) search-based techniques guided by independently trained, static process reward models (PRMs), which require expensive human- or LLM-generated labels and often degrade under distrib",
      "url": "https://arxiv.org/abs/2508.14313",
      "category": "cs.LG"
    },
    {
      "title": "Practical Feasibility of Gradient Inversion Attacks in Federated Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2508.19819v2 Announce Type: replace-cross \nAbstract: Gradient inversion attacks are often presented as a serious privacy threat in federated learning, with recent work reporting increasingly strong reconstructions under favorable experimental settings. However, it remains unclear whether such attacks are feasible in modern, performance-optimized systems deployed in practice. In this work, we evaluate the practical feasibility of gradient inversion for image-based federated learning. We con",
      "url": "https://arxiv.org/abs/2508.19819",
      "category": "cs.CR"
    },
    {
      "title": "DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2508.20033v2 Announce Type: replace-cross \nAbstract: The ability to research and synthesize knowledge is central to human expertise and progress. A new class of AI systems--designed for generative research synthesis--aims to automate this process by retrieving information from the live web and producing long-form, cited reports. Yet, evaluating such systems remains an open challenge: existing question-answering benchmarks focus on short, factual answers, while expert-curated datasets risk ",
      "url": "https://arxiv.org/abs/2508.20033",
      "category": "cs.CL"
    },
    {
      "title": "SpecPrune-VLA: Accelerating Vision-Language-Action Models via Action-Aware Self-Speculative Pruning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.05614v2 Announce Type: replace-cross \nAbstract: Pruning is a typical acceleration technique for compute-bound models by removing computation on unimportant values. Recently, it has been applied to accelerate Vision-Language-Action (VLA) model inference. However, existing acceleration methods focus on local information from the current action step and ignore the global context, leading to >20% success rate drop and limited speedup in some scenarios. In this paper, we point out spatial-",
      "url": "https://arxiv.org/abs/2509.05614",
      "category": "cs.CV"
    },
    {
      "title": "No Answer Needed: Predicting LLM Answer Accuracy from Question-Only Linear Probes",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.10625v2 Announce Type: replace-cross \nAbstract: Do large language models (LLMs) anticipate when they will answer correctly? To study this, we extract activations after a question is read but before any tokens are generated, and train linear probes to predict whether the model's forthcoming answer will be correct. Across three open-source model families ranging from 7 to 70 billion parameters, projections on this \"in-advance correctness direction\" trained on generic trivia questions pr",
      "url": "https://arxiv.org/abs/2509.10625",
      "category": "cs.CL"
    },
    {
      "title": "Vibe Coding for Product Design: Understanding Product Team Members' Perceptions of AI-Assisted Design and Development",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.10652v2 Announce Type: replace-cross \nAbstract: Generative AI is reshaping product design practices through \"vibe coding\", where product team members express intent in natural language and AI translates it into functional prototypes and code. Despite rapid adoption, little research has examined how vibe coding reconfigures product development workflows and collaboration. Drawing on interviews with 22 product team members across enterprises, startups, and academia, we show how vibe cod",
      "url": "https://arxiv.org/abs/2509.10652",
      "category": "cs.HC"
    },
    {
      "title": "Fed-PISA: Federated Voice Cloning via Personalized Identity-Style Adaptation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.16010v2 Announce Type: replace-cross \nAbstract: Voice cloning for Text-to-Speech (TTS) aims to generate expressive and personalized speech from text using limited data from a target speaker. Federated Learning (FL) offers a collaborative and privacy-preserving framework for this task, but existing approaches suffer from high communication costs and tend to suppress stylistic heterogeneity, resulting in insufficient personalization. To address these issues, we propose Fed-PISA, which s",
      "url": "https://arxiv.org/abs/2509.16010",
      "category": "cs.SD"
    },
    {
      "title": "MedVSR: Medical Video Super-Resolution with Cross State-Space Propagation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.21265v2 Announce Type: replace-cross \nAbstract: High-resolution (HR) medical videos are vital for accurate diagnosis, yet are hard to acquire due to hardware limitations and physiological constraints. Clinically, the collected low-resolution (LR) medical videos present unique challenges for video super-resolution (VSR) models, including camera shake, noise, and abrupt frame transitions, which result in significant optical flow errors and alignment difficulties. Additionally, tissues a",
      "url": "https://arxiv.org/abs/2509.21265",
      "category": "cs.CV"
    },
    {
      "title": "MIXRAG : Mixture-of-Experts Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.21391v2 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) have achieved impressive performance across a wide range of applications. However, they often suffer from hallucinations in knowledge-intensive domains due to their reliance on static pretraining corpora. To address this limitation, Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating external knowledge sources during inference. Among these sources, textual graphs provide structured and semanti",
      "url": "https://arxiv.org/abs/2509.21391",
      "category": "cs.IR"
    },
    {
      "title": "No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.21880v3 Announce Type: replace-cross \nAbstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful framework for improving the reasoning abilities of Large Language Models (LLMs). However, current methods such as GRPO rely only on problems where the model responses to the same input differ in correctness, while ignoring those where all responses receive the same reward -- so-called zero-variance prompts. In this work, we argue that such prompts are not useless but can",
      "url": "https://arxiv.org/abs/2509.21880",
      "category": "cs.CL"
    },
    {
      "title": "Interpretable Discovery of One-parameter Subgroups: A Modular Framework for Elliptical, Hyperbolic, and Parabolic Symmetries",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.22219v4 Announce Type: replace-cross \nAbstract: We propose a modular, data-driven framework for jointly learning unknown functional mappings and discovering the underlying one-parameter symmetry subgroup governing the data. Unlike conventional geometric deep learning methods that assume known symmetries, our approach identifies the relevant continuous subgroup directly from data. We consider the broad class of one-parameter subgroups, which admit a canonical geometric classification i",
      "url": "https://arxiv.org/abs/2509.22219",
      "category": "cs.LG"
    },
    {
      "title": "ASSESS: A Semantic and Structural Evaluation Framework for Statement Similarity",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.22246v2 Announce Type: replace-cross \nAbstract: Despite significant strides in statement autoformalization, a critical gap remains in the development of automated evaluation metrics capable of assessing formal translation quality. Existing metrics often fail to balance semantic and structural information: string-based methods neglect semantics, whereas proof-based approaches offer no graded similarity when proofs fail. To address these issues, we introduce ASSESS (A Semantic and Struc",
      "url": "https://arxiv.org/abs/2509.22246",
      "category": "cs.LG"
    },
    {
      "title": "Functional Critics Are Essential for Actor-Critic: From Off-Policy Stability to Efficient Exploration",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.22964v4 Announce Type: replace-cross \nAbstract: The actor-critic (AC) framework has achieved strong empirical success in off-policy reinforcement learning but suffers from the \"moving target\" problem, where the evaluated policy changes continually. Functional critics, or policy-conditioned value functions, address this by explicitly including a representation of the policy as input. While conceptually appealing, previous efforts have struggled to remain competitive against standard AC",
      "url": "https://arxiv.org/abs/2509.22964",
      "category": "cs.LG"
    },
    {
      "title": "Uncovering Vulnerabilities of LLM-Assisted Cyber Threat Intelligence",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.23573v3 Announce Type: replace-cross \nAbstract: Large language models (LLMs) are increasingly used to help security analysts manage the surge of cyber threats, automating tasks from vulnerability assessment to incident response. Yet in operational CTI workflows, reliability gaps remain substantial. Existing explanations often point to generic model issues (e.g., hallucination), but we argue the dominant bottleneck is the threat landscape itself: CTI is heterogeneous, volatile, and fra",
      "url": "https://arxiv.org/abs/2509.23573",
      "category": "cs.CR"
    },
    {
      "title": "Evolution Strategies at Scale: LLM Fine-Tuning Beyond Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.24372v2 Announce Type: replace-cross \nAbstract: Fine-tuning large language models (LLMs) for downstream tasks is an essential stage of modern AI deployment. Reinforcement learning (RL) has emerged as the dominant fine-tuning paradigm, underpinning many state-of-the-art LLMs. In contrast, evolution strategies (ES) has largely been overlooked due to the widespread belief that it does not scale to modern model sizes. This paper overturns this assumption by demonstrating the first success",
      "url": "https://arxiv.org/abs/2509.24372",
      "category": "cs.LG"
    },
    {
      "title": "Vid-LLM: A Compact Video-based 3D Multimodal LLM with Reconstruction-Reasoning Synergy",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.24385v3 Announce Type: replace-cross \nAbstract: Recent developments in Multimodal Large Language Models (MLLMs) have significantly improved Vision-Language (VL) reasoning in 2D domains. However, extending these capabilities to 3D scene understanding remains a major challenge. Existing 3D Multimodal Large Language Models (3D-MLLMs) often depend on 3D data inputs, which limits scalability and generalization. To address this limitation, we propose Vid-LLM, a video-based 3D-MLLM that dire",
      "url": "https://arxiv.org/abs/2509.24385",
      "category": "cs.CV"
    },
    {
      "title": "Specialization after Generalization: Towards Understanding Test-Time Training in Foundation Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.24510v4 Announce Type: replace-cross \nAbstract: Recent empirical studies have explored the idea of continuing to train a model at test-time for a given task, known as test-time training (TTT), and have found it to yield significant performance improvements. However, there is limited understanding of why and when TTT is effective. Earlier explanations mostly focused on the observation that TTT may help when applied to out-of-distribution adaptation or used with privileged data. However",
      "url": "https://arxiv.org/abs/2509.24510",
      "category": "cs.LG"
    },
    {
      "title": "Emotion-Aligned Generation in Diffusion Text to Speech Models via Preference-Guided Optimization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2509.25416v2 Announce Type: replace-cross \nAbstract: Emotional text-to-speech seeks to convey affect while preserving intelligibility and prosody, yet existing methods rely on coarse labels or proxy classifiers and receive only utterance-level feedback. We introduce Emotion-Aware Stepwise Preference Optimization (EASPO), a post-training framework that aligns diffusion TTS with fine-grained emotional preferences at intermediate denoising steps. Central to our approach is EASPM, a time-condi",
      "url": "https://arxiv.org/abs/2509.25416",
      "category": "cs.CL"
    },
    {
      "title": "CHAI: Command Hijacking against embodied AI",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.00181v2 Announce Type: replace-cross \nAbstract: Embodied Artificial Intelligence (AI) promises to handle edge cases in robotic vehicle systems where data is scarce by using common-sense reasoning grounded in perception and action to generalize beyond training distributions and adapt to novel real-world situations. These capabilities, however, also create new security risks. In this paper, we introduce CHAI (Command Hijacking against embodied AI), a physical environment indirect prompt",
      "url": "https://arxiv.org/abs/2510.00181",
      "category": "cs.CR"
    },
    {
      "title": "Copy-Paste to Mitigate Large Language Model Hallucinations",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.00508v2 Announce Type: replace-cross \nAbstract: While Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to generate contextually grounded responses, contextual faithfulness remains challenging as LLMs may not consistently trust provided context, leading to hallucinations that undermine reliability. We observe an inverse correlation between response copying degree and context-unfaithful hallucinations on RAGTruth, suggesting that higher copying degrees reduce ha",
      "url": "https://arxiv.org/abs/2510.00508",
      "category": "cs.CL"
    },
    {
      "title": "Towards Open-Ended Discovery for Low-Resource NLP",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.01220v2 Announce Type: replace-cross \nAbstract: Natural Language Processing (NLP) for low-resource languages remains fundamentally constrained by the lack of textual corpora, standardized orthographies, and scalable annotation pipelines. While recent advances in large language models have improved cross-lingual transfer, they remain inaccessible to underrepresented communities due to their reliance on massive, pre-collected data and centralized infrastructure. In this position paper, ",
      "url": "https://arxiv.org/abs/2510.01220",
      "category": "cs.CL"
    },
    {
      "title": "Trade in Minutes! Rationality-Driven Agentic System for Quantitative Financial Trading",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.04787v2 Announce Type: replace-cross \nAbstract: Recent advancements in large language models (LLMs) and agentic systems have shown exceptional decision-making capabilities, revealing significant potential for autonomic finance. Current financial trading agents predominantly simulate anthropomorphic roles that inadvertently introduce emotional biases and rely on peripheral information, while being constrained by the necessity for continuous inference during deployment. In this paper, w",
      "url": "https://arxiv.org/abs/2510.04787",
      "category": "cs.MA"
    },
    {
      "title": "Deep Generative Model for Human Mobility Behavior",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.06473v2 Announce Type: replace-cross \nAbstract: Understanding and modeling human mobility is central to challenges in transport planning, sustainable urban design, and public health. Despite decades of effort, simulating individual mobility remains challenging because of its complex, context-dependent, and exploratory nature. Here, we advance a unified event-level formulation of daily mobility and propose MobilityGen to generate multi-attribute event sequences over days to weeks at la",
      "url": "https://arxiv.org/abs/2510.06473",
      "category": "physics.soc-ph"
    },
    {
      "title": "VAO: Validation-Aligned Optimization for Cross-Task Generative Auto-Bidding",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.07760v3 Announce Type: replace-cross \nAbstract: Generative auto-bidding has demonstrated strong performance in online advertising, yet it often suffers from data scarcity in small-scale settings with limited advertiser participation. While cross-task data sharing is a natural remedy to mitigate this issue, naive approaches often introduce gradient bias due to distribution shifts across different tasks, and existing methods are not readily applicable to generative auto-bidding. In this",
      "url": "https://arxiv.org/abs/2510.07760",
      "category": "cs.LG"
    },
    {
      "title": "CoMAS: Co-Evolving Multi-Agent Systems via Interaction Rewards",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.08529v2 Announce Type: replace-cross \nAbstract: Self-evolution is a central research topic in enabling large language model (LLM)-based agents to continually improve their capabilities after pretraining. Recent research has witnessed a transition from reinforcement learning (RL)-free to RL-based methods. Current RL-based methods either rely on dense external reward signals or extract intrinsic reward signals from LLMs themselves. However, these approaches diverge from the self-evoluti",
      "url": "https://arxiv.org/abs/2510.08529",
      "category": "cs.CL"
    },
    {
      "title": "SHERLOCK:Towards Dynamic Knowledge Adaptation in LLM-enhanced E-commerce Risk Management",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.08948v3 Announce Type: replace-cross \nAbstract: Effective e-commerce risk management requires in-depth case investigations to identify emerging fraud patterns in highly adversarial environments. However, manual investigation typically requires analyzing the associations and couplings among multi-source heterogeneous data, a labor-intensive process that limits efficiency. While Large Language Models (LLMs) show promise in automating these analyses, their deployment is hindered by the c",
      "url": "https://arxiv.org/abs/2510.08948",
      "category": "cs.IR"
    },
    {
      "title": "Diffusion-Inspired Masked Fine-Tuning for Knowledge Injection in Autoregressive LLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.09885v4 Announce Type: replace-cross \nAbstract: Large language models (LLMs) are often used in environments where facts evolve, yet factual knowledge updates via fine-tuning on unstructured text often suffers from 1) reliance on compute-heavy paraphrase augmentation and 2) the reversal curse. Recent studies show diffusion large language models (dLLMs) require fewer training samples to achieve lower loss in pre-training and are more resistant to the reversal curse, suggesting dLLMs may",
      "url": "https://arxiv.org/abs/2510.09885",
      "category": "cs.CL"
    },
    {
      "title": "Probabilistic bias adjustment of seasonal predictions of Arctic Sea Ice Concentration",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.09891v2 Announce Type: replace-cross \nAbstract: Seasonal forecast of Arctic sea ice concentration is key to mitigate the negative impact and assess potential opportunities posed by the rapid decline of sea ice coverage. Seasonal prediction systems based on climate models often show systematic biases and complex spatio-temporal errors that grow with the forecasts. Consequently, operational predictions are routinely bias corrected and calibrated using retrospective forecasts. For predic",
      "url": "https://arxiv.org/abs/2510.09891",
      "category": "cs.LG"
    },
    {
      "title": "PAC-Bayesian Reinforcement Learning Trains Generalizable Policies",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.10544v2 Announce Type: replace-cross \nAbstract: We derive a novel PAC-Bayesian generalization bound for reinforcement learning that explicitly accounts for Markov dependencies in the data, through the chain's mixing time. This contributes to overcoming challenges in obtaining generalization guarantees for reinforcement learning, where the sequential nature of data breaks the independence assumptions underlying classical bounds. The new bound provides non-vacuous certificates for moder",
      "url": "https://arxiv.org/abs/2510.10544",
      "category": "cs.LG"
    },
    {
      "title": "Transformer-based Learning-to-Optimize Approach for Scalable and Generalizable Beamforming",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.13077v2 Announce Type: replace-cross \nAbstract: We develop an unsupervised deep learning framework for downlink beamforming in large-scale MU-MISO channels. The model is trained offline, allowing real-time inference through lightweight feedforward computations in dynamic communication environments. Following the learning-to-optimize (L2O) paradigm, a multi-layer Transformer iteratively refines both channel and beamformer features via residual connections. To enhance training, three st",
      "url": "https://arxiv.org/abs/2510.13077",
      "category": "cs.LG"
    },
    {
      "title": "Paper Copilot: Tracking the Evolution of Peer Review in AI Conferences",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.13201v2 Announce Type: replace-cross \nAbstract: The rapid growth of AI conferences is straining an already fragile peer-review system, leading to heavy reviewer workloads, expertise mismatches, inconsistent evaluation standards, superficial or templated reviews, and limited accountability under compressed timelines. In response, conference organizers have introduced new policies and interventions to preserve review standards. Yet these ad-hoc changes often create further concerns and ",
      "url": "https://arxiv.org/abs/2510.13201",
      "category": "cs.CV"
    },
    {
      "title": "What Layers When: Learning to Skip Compute in LLMs with Residual Gates",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.13876v3 Announce Type: replace-cross \nAbstract: We introduce GateSkip, a simple residual-stream gating mechanism that enables token-wise layer skipping in decoder-only LMs. Each Attention/MLP branch is equipped with a sigmoid-linear gate that condenses the branch's output before it re-enters the residual stream. During inference we rank tokens by the gate values and skip low-importance ones using a per-layer budget. While early-exit or router-based Mixture-of-Depths models are known t",
      "url": "https://arxiv.org/abs/2510.13876",
      "category": "cs.CL"
    },
    {
      "title": "ActivationReasoning: Logical Reasoning in Latent Activation Spaces",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.18184v2 Announce Type: replace-cross \nAbstract: Large language models (LLMs) excel at generating fluent text, but their internal reasoning remains opaque and difficult to control. Sparse autoencoders (SAEs) make hidden activations more interpretable by exposing latent features that often align with human concepts. Yet, these features are fragile and passive, offering no mechanism for systematic reasoning or model control. To address this, we introduce ActivationReasoning (AR), a frame",
      "url": "https://arxiv.org/abs/2510.18184",
      "category": "cs.LG"
    },
    {
      "title": "The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.20647v3 Announce Type: replace-cross \nAbstract: Large Reasoning Models (LRMs) achieve strong performance on mathematical, scientific, and other question-answering tasks, but their multilingual reasoning abilities remain underexplored. When presented with non-English questions, LRMs often default to reasoning in English, raising concerns about interpretability and the handling of linguistic and cultural nuances. We systematically compare an LRM's reasoning in English versus the languag",
      "url": "https://arxiv.org/abs/2510.20647",
      "category": "cs.CL"
    },
    {
      "title": "Deep Ensembles for Epistemic Uncertainty: A Frequentist Perspective",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.22063v3 Announce Type: replace-cross \nAbstract: Decomposing prediction uncertainty into aleatoric (irreducible) and epistemic (reducible) components is critical for the reliable deployment of machine learning systems. While the mutual information between the response variable and model parameters is a principled measure for epistemic uncertainty, it requires access to the parameter posterior, which is computationally challenging to approximate. Consequently, practitioners often rely o",
      "url": "https://arxiv.org/abs/2510.22063",
      "category": "stat.ML"
    },
    {
      "title": "GPTOpt: Teaching LLMs to do Interpretable Black-Box Optimization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2510.25404v2 Announce Type: replace-cross \nAbstract: Global optimization of expensive, derivative-free black-box functions demands extreme sample efficiency and decision interpretability. While Large Language Models (LLMs) have shown broad capabilities, even state-of-the-art models remain limited in solving continuous black-box optimization tasks and struggle to maintain exploration-exploitation balance. We introduce GPTOpt, an optimization method that equips LLMs with continuous black-box",
      "url": "https://arxiv.org/abs/2510.25404",
      "category": "cs.LG"
    },
    {
      "title": "BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.04919v2 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) face significant computational and memory constraints when processing long contexts, despite growing demand for applications requiring reasoning over extensive documents, multi-session dialogues, and book length texts. While recent advances have extended context windows to 100K-1M tokens, such approaches incur prohibitive costs for resource constrained deployments. We propose BudgetMem, a novel memory augment",
      "url": "https://arxiv.org/abs/2511.04919",
      "category": "cs.CL"
    },
    {
      "title": "Constructing the Umwelt: Cognitive Planning through Belief-Intent Co-Evolution",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.05540v3 Announce Type: replace-cross \nAbstract: This paper challenges a prevailing epistemological assumption in End-to-End Autonomous Driving: that high-performance planning necessitates high-fidelity world reconstruction. Inspired by cognitive science, we propose the Mental Bayesian Causal World Model (MBCWM) and instantiate it as the Tokenized Intent World Model (TIWM), a novel cognitive computing architecture. Its core philosophy posits that intelligence emerges not from pixel-lev",
      "url": "https://arxiv.org/abs/2511.05540",
      "category": "cs.CV"
    },
    {
      "title": "IDALC: A Semi-Supervised Framework for Intent Detection and Active Learning based Correction",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.05921v2 Announce Type: replace-cross \nAbstract: Voice-controlled dialog systems have become immensely popular due to their ability to perform a wide range of actions in response to diverse user queries. These agents possess a predefined set of skills or intents to fulfill specific user tasks. But every system has its own limitations. There are instances where, even for known intents, if any model exhibits low confidence, it results in rejection of utterances that necessitate manual an",
      "url": "https://arxiv.org/abs/2511.05921",
      "category": "cs.CL"
    },
    {
      "title": "Explainable Cross-Disease Reasoning for Cardiovascular Risk Assessment from Low-Dose Computed Tomography",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.06625v4 Announce Type: replace-cross \nAbstract: Low-dose chest computed tomography (LDCT) inherently captures both pulmonary and cardiac structures, offering a unique opportunity for joint assessment of lung and cardiovascular health. However, most existing approaches treat these domains as independent tasks, overlooking their physiological interplay and shared imaging biomarkers. We propose an Explainable Cross-Disease Reasoning Framework that enables interpretable cardiopulmonary ri",
      "url": "https://arxiv.org/abs/2511.06625",
      "category": "cs.CV"
    },
    {
      "title": "Training Language Models to Explain Their Own Computations",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.08579v3 Announce Type: replace-cross \nAbstract: Can language models (LMs) learn to faithfully describe their internal computations? Are they better able to describe themselves than other models? We study the extent to which LMs' privileged access to their own internals can be leveraged to produce new techniques for explaining their behavior. Using existing interpretability techniques as a source of ground truth, we fine-tune LMs to generate natural language descriptions of (1) the inf",
      "url": "https://arxiv.org/abs/2511.08579",
      "category": "cs.CL"
    },
    {
      "title": "MTR-DuplexBench: Towards a Comprehensive Evaluation of Multi-Round Conversations for Full-Duplex Speech Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.10262v2 Announce Type: replace-cross \nAbstract: Full-Duplex Speech Language Models (FD-SLMs) enable real-time, overlapping conversational interactions, offering a more dynamic user experience compared to traditional half-duplex models. However, existing benchmarks primarily focus on evaluating single-round interactions, neglecting the complexities of multi-round communication. Evaluating FD-SLMs in multi-round settings poses significant challenges, including blurred turn boundaries in",
      "url": "https://arxiv.org/abs/2511.10262",
      "category": "cs.CL"
    },
    {
      "title": "Twice Sequential Monte Carlo for Tree Search",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2511.14220v2 Announce Type: replace-cross \nAbstract: Model-based reinforcement learning (RL) methods that leverage search are responsible for many milestone breakthroughs in RL. Sequential Monte Carlo (SMC) recently emerged as an alternative to the Monte Carlo Tree Search (MCTS) algorithm which drove these breakthroughs. SMC is easier to parallelize and more suitable to GPU acceleration. However, it also suffers from large variance and path degeneracy which prevent it from scaling well wit",
      "url": "https://arxiv.org/abs/2511.14220",
      "category": "cs.LG"
    },
    {
      "title": "MOTION: ML-Assisted On-Device Low-Latency Motion Recognition",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.00008v3 Announce Type: replace-cross \nAbstract: The use of tiny devices capable of low-latency gesture recognition is gaining momentum in everyday human-computer interaction and especially in medical monitoring fields. Embedded solutions such as fall detection, rehabilitation tracking, and patient supervision require fast and efficient tracking of movements while avoiding unwanted false alarms. This study presents an efficient solution on how to build very efficient motion-based model",
      "url": "https://arxiv.org/abs/2512.00008",
      "category": "cs.CV"
    },
    {
      "title": "Open-Set Domain Adaptation Under Background Distribution Shift: Challenges and A Provably Efficient Solution",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.01152v3 Announce Type: replace-cross \nAbstract: As we deploy machine learning systems in the real world, a core challenge is to maintain a model that is performant even as the data shifts. Such shifts can take many forms: new classes may emerge that were absent during training, a problem known as open-set recognition, and the distribution of known categories may change. Guarantees on open-set recognition are mostly derived under the assumption that the distribution of known classes, w",
      "url": "https://arxiv.org/abs/2512.01152",
      "category": "cs.LG"
    },
    {
      "title": "GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.01952v2 Announce Type: replace-cross \nAbstract: Recent advances in video world modeling have enabled large-scale generative models to simulate embodied environments with high visual fidelity, providing strong priors for prediction, planning, and control. Yet, despite their realism, these models often lack geometric grounding, limiting their use in navigation tasks that require spatial coherence and stability. We introduce Reinforcement Learning with World Grounding (RLWG), a self-supe",
      "url": "https://arxiv.org/abs/2512.01952",
      "category": "cs.CV"
    },
    {
      "title": "Breaking Scale Anchoring: Frequency Representation Learning for Accurate High-Resolution Inference from Low-Resolution Training",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.05132v2 Announce Type: replace-cross \nAbstract: Zero-Shot Super-Resolution Spatiotemporal Forecasting requires a deep learning model to be trained on low-resolution data and deployed for inference on high-resolution. Existing studies consider maintaining similar error across different resolutions as indicative of successful multi-resolution generalization. However, deep learning models serving as alternatives to numerical solvers should reduce error as resolution increases. The fundam",
      "url": "https://arxiv.org/abs/2512.05132",
      "category": "cs.CV"
    },
    {
      "title": "Fine-tuning an ECG Foundation Model to Predict Coronary CT Angiography Outcomes",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.05136v2 Announce Type: replace-cross \nAbstract: Coronary artery disease (CAD) remains a major global public health burden, yet scalable tools for risk screening are limited. Although coronary computed tomography angiography (CCTA) is a first-line non-invasive diagnostic modality, its widespread use is constrained by resource requirements and radiation exposure. Artificial intelligence--enabled electrocardiography (AI-ECG) may provide a complementary approach for CAD risk stratificatio",
      "url": "https://arxiv.org/abs/2512.05136",
      "category": "cs.CV"
    },
    {
      "title": "China Regional 3km Downscaling Based on Residual Corrective Diffusion Model",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.05377v4 Announce Type: replace-cross \nAbstract: A fundamental challenge in numerical weather prediction is to efficiently produce high-resolution forecasts. A common solution is applying downscaling methods, which include dynamical downscaling and statistical downscaling, to the outputs of global models. This work focuses on statistical downscaling, which establishes statistical relationships between low-resolution and high-resolution historical data using statistical models. Deep lea",
      "url": "https://arxiv.org/abs/2512.05377",
      "category": "cs.LG"
    },
    {
      "title": "SoK: Trust-Authorization Mismatch in LLM Agent Interactions",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.06914v2 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) are evolving into autonomous agents capable of executing complex workflows via standardized protocols (e.g., MCP). However, this paradigm shifts control from deterministic code to probabilistic inference, creating a fundamental Trust-Authorization Mismatch: static permissions are structurally decoupled from the agent's fluctuating runtime trustworthiness. In this Systematization of Knowledge (SoK), we survey ",
      "url": "https://arxiv.org/abs/2512.06914",
      "category": "cs.CR"
    },
    {
      "title": "Investigating Data Pruning for Pretraining Biological Foundation Models at Scale",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.12932v2 Announce Type: replace-cross \nAbstract: Biological foundation models (BioFMs), pretrained on large-scale biological sequences, have recently shown strong potential in providing meaningful representations for diverse downstream bioinformatics tasks. However, such models often rely on millions to billions of training sequences and billions of parameters, resulting in prohibitive computational costs and significant barriers to reproducibility and accessibility, particularly for a",
      "url": "https://arxiv.org/abs/2512.12932",
      "category": "cs.LG"
    },
    {
      "title": "Data-Chain Backdoor: Do You Trust Diffusion Models as Generative Data Supplier?",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.15769v2 Announce Type: replace-cross \nAbstract: The increasing use of generative models such as diffusion models for synthetic data augmentation has greatly reduced the cost of data collection and labeling in downstream perception tasks. However, this new data source paradigm may introduce important security concerns. Publicly available generative models are often reused without verification, raising a fundamental question of their safety and trustworthiness. This work investigates ba",
      "url": "https://arxiv.org/abs/2512.15769",
      "category": "cs.CR"
    },
    {
      "title": "Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.19707v2 Announce Type: replace-cross \nAbstract: The benefits of artificial intelligence (AI) human partnerships-evaluating how AI agents enhance expert human performance-are increasingly studied. Though rarely evaluated in healthcare, an inverse approach is possible: AI benefiting from the support of an expert human agent. Here, we investigate both human-AI clinical partnership paradigms in the magnetic resonance imaging-guided characterisation of patients with brain tumours. We revea",
      "url": "https://arxiv.org/abs/2512.19707",
      "category": "cs.HC"
    },
    {
      "title": "Block-Recurrent Dynamics in Vision Transformers",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.19941v3 Announce Type: replace-cross \nAbstract: As Vision Transformers (ViTs) become standard vision backbones, a mechanistic account of their computational phenomenology is essential. Despite architectural cues that hint at dynamical structure, there is no settled framework that interprets Transformer depth as a well-characterized flow. In this work, we introduce the Block-Recurrent Hypothesis (BRH), arguing that trained ViTs admit a block-recurrent depth structure such that the comp",
      "url": "https://arxiv.org/abs/2512.19941",
      "category": "cs.CV"
    },
    {
      "title": "TS-Arena -- A Live Forecast Pre-Registration Platform",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.20761v2 Announce Type: replace-cross \nAbstract: Time Series Foundation Models (TSFMs) are transforming the field of forecasting. However, evaluating them on historical data is increasingly difficult due to the risks of train-test sample overlaps and temporal overlaps between correlated train and test time series. To address this, we introduce TS-Arena, a live forecasting platform that shifts evaluation from the known past to the unknown future. Building on the concept of continuous be",
      "url": "https://arxiv.org/abs/2512.20761",
      "category": "cs.LG"
    },
    {
      "title": "SuperiorGAT: Graph Attention Networks for Sparse LiDAR Point Cloud Reconstruction in Autonomous Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.22439v3 Announce Type: replace-cross \nAbstract: LiDAR-based perception in autonomous systems is constrained by fixed vertical beam resolution and further compromised by beam dropout resulting from environmental occlusions. This paper introduces SuperiorGAT, a graph attention-based framework designed to reconstruct missing elevation information in sparse LiDAR point clouds. By modeling LiDAR scans as beam-aware graphs and incorporating gated residual fusion with feed-forward refinement",
      "url": "https://arxiv.org/abs/2512.22439",
      "category": "cs.CV"
    },
    {
      "title": "Towards Reliable Evaluation of Adversarial Robustness for Spiking Neural Networks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.22522v3 Announce Type: replace-cross \nAbstract: Spiking Neural Networks (SNNs) utilize spike-based activations to mimic the brain's energy-efficient information processing. However, the binary and discontinuous nature of spike activations causes vanishing gradients, making adversarial robustness evaluation via gradient descent unreliable. While improved surrogate gradient methods have been proposed, their effectiveness under strong adversarial attacks remains unclear. We propose a mor",
      "url": "https://arxiv.org/abs/2512.22522",
      "category": "cs.LG"
    },
    {
      "title": "Trust Region Masking for Long-Horizon LLM Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2512.23075v3 Announce Type: replace-cross \nAbstract: Policy gradient methods for Large Language Models optimize a policy $\\pi_\\theta$ via a surrogate objective computed from samples of a rollout policy $\\pi_{\\text{roll}}$. However, modern LLM-RL pipelines suffer from unavoidable implementation divergences -- backend discrepancies, Mixture-of-Experts routing discontinuities, and distributed training staleness -- causing off-policy mismatch ($\\pi_{\\text{roll}} \\neq \\pi_\\theta$) and approxima",
      "url": "https://arxiv.org/abs/2512.23075",
      "category": "cs.LG"
    },
    {
      "title": "Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.00181v2 Announce Type: replace-cross \nAbstract: Despite strong recent progress in Emotion Recognition in Conversation (ERC), two gaps remain: we lack clear understanding of which modeling choices materially affect performance, and we have limited linguistic analysis linking recognition findings to actionable generation cues. We address both via a systematic study on IEMOCAP.\n  For recognition, we conduct controlled ablations with 10 random seeds and paired tests (with correction for m",
      "url": "https://arxiv.org/abs/2601.00181",
      "category": "cs.CL"
    },
    {
      "title": "The Refutability Gap: Challenges in Validating Reasoning by Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.02380v3 Announce Type: replace-cross \nAbstract: Recent reports claim that Large Language Models (LLMs) have achieved the ability to derive new science and exhibit human-level general intelligence. We argue that such claims are not rigorous scientific claims, as they do not satisfy Popper's refutability principle (often termed falsifiability), which requires that scientific statements be capable of being disproven. We identify several methodological pitfalls in current AI research on r",
      "url": "https://arxiv.org/abs/2601.02380",
      "category": "cs.CY"
    },
    {
      "title": "HEEGNet: Hyperbolic Embeddings for EEG",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.03322v2 Announce Type: replace-cross \nAbstract: Electroencephalography (EEG)-based brain-computer interfaces facilitate direct communication with a computer, enabling promising applications in human-computer interactions. However, their utility is currently limited because EEG decoding often suffers from poor generalization due to distribution shifts across domains (e.g., subjects). Learning robust representations that capture underlying task-relevant information would mitigate these ",
      "url": "https://arxiv.org/abs/2601.03322",
      "category": "cs.LG"
    },
    {
      "title": "Towards Spatio-Temporal Extrapolation of Phase-Field Simulations with Convolution-Only Neural Networks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.04510v2 Announce Type: replace-cross \nAbstract: Phase-field simulations of liquid metal dealloying (LMD) can capture complex microstructural evolutions but can be prohibitively expensive for large domains and long time horizons. In this paper, we introduce a fully convolutional, conditionally parameterized U-Net surrogate designed to extrapolate far beyond its training data in both space and time. The architecture integrates convolutional self-attention, physically informed padding, a",
      "url": "https://arxiv.org/abs/2601.04510",
      "category": "cs.CE"
    },
    {
      "title": "Challenges and Research Directions for Large Language Model Inference Hardware",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.05047v3 Announce Type: replace-cross \nAbstract: Large Language Model (LLM) inference is hard. The autoregressive Decode phase of the underlying Transformer model makes LLM inference fundamentally different from training. Exacerbated by recent AI trends, the primary challenges are memory and interconnect rather than compute. To address these challenges, we highlight four architecture research opportunities: High Bandwidth Flash for 10X memory capacity with HBM-like bandwidth; Processin",
      "url": "https://arxiv.org/abs/2601.05047",
      "category": "cs.AR"
    },
    {
      "title": "A Review of Online Diffusion Policy RL Algorithms for Scalable Robotic Control",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.06133v2 Announce Type: replace-cross \nAbstract: Diffusion policies have emerged as a powerful approach for robotic control, demonstrating superior expressiveness in modeling multimodal action distributions compared to conventional policy networks. However, their integration with online reinforcement learning remains challenging due to fundamental incompatibilities between diffusion model training objectives and standard RL policy improvement mechanisms. This paper presents the first c",
      "url": "https://arxiv.org/abs/2601.06133",
      "category": "cs.LG"
    },
    {
      "title": "3D Wavelet-Based Structural Priors for Controlled Diffusion in Whole-Body Low-Dose PET Denoising",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.07093v3 Announce Type: replace-cross \nAbstract: Low-dose Positron Emission Tomography (PET) imaging reduces patient radiation exposure but suffers from increased noise that degrades image quality and diagnostic reliability. Although diffusion models have demonstrated strong denoising capability, their stochastic nature makes it challenging to enforce anatomically consistent structures, particularly in low signal-to-noise regimes and volumetric whole-body imaging. We propose Wavelet-Co",
      "url": "https://arxiv.org/abs/2601.07093",
      "category": "cs.CV"
    },
    {
      "title": "Moonworks Lunara Aesthetic Dataset",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.07941v4 Announce Type: replace-cross \nAbstract: The dataset spans diverse artistic styles, including regionally grounded aesthetics from the Middle East, Northern Europe, East Asia, and South Asia, alongside general categories such as sketch and oil painting. All images are generated using the Moonworks Lunara model and intentionally crafted to embody distinct, high-quality aesthetic styles, yielding a first-of-its-kind dataset with substantially higher aesthetic scores, exceeding eve",
      "url": "https://arxiv.org/abs/2601.07941",
      "category": "cs.CV"
    },
    {
      "title": "On Evaluation of Unsupervised Feature Selection for Pattern Classification",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.08257v3 Announce Type: replace-cross \nAbstract: Unsupervised feature selection aims to identify a compact subset of features that captures the intrinsic structure of data without supervised label. Most existing studies evaluate the performance of methods using the single-label dataset that can be instantiated by selecting a label from multi-label data while maintaining the original features. Because the chosen label can vary arbitrarily depending on the experimental setting, the super",
      "url": "https://arxiv.org/abs/2601.08257",
      "category": "cs.LG"
    },
    {
      "title": "Generating metamers of human scene understanding",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.11675v2 Announce Type: replace-cross \nAbstract: Human vision combines low-resolution \"gist\" information from the visual periphery with sparse but high-resolution information from fixated locations to construct a coherent understanding of a visual scene. In this paper, we introduce MetamerGen, a tool for generating scenes that are aligned with latent human scene representations. MetamerGen is a latent diffusion model that combines peripherally obtained scene gist information with infor",
      "url": "https://arxiv.org/abs/2601.11675",
      "category": "cs.CV"
    },
    {
      "title": "Report for NSF Workshop on AI for Electronic Design Automation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.14541v3 Announce Type: replace-cross \nAbstract: This report distills the discussions and recommendations from the NSF Workshop on AI for Electronic Design Automation (EDA), held on December 10, 2024 in Vancouver alongside NeurIPS 2024. Bringing together experts across machine learning and EDA, the workshop examined how AI-spanning large language models (LLMs), graph neural networks (GNNs), reinforcement learning (RL), neurosymbolic methods, etc.-can facilitate EDA and shorten design t",
      "url": "https://arxiv.org/abs/2601.14541",
      "category": "cs.LG"
    },
    {
      "title": "Evaluating Semantic and Syntactic Understanding in Large Language Models for Payroll Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.18012v2 Announce Type: replace-cross \nAbstract: Large language models are now used daily for writing, search, and analysis, and their natural language understanding continues to improve. However, they remain unreliable on exact numerical calculation and on producing outputs that are straightforward to audit. We study synthetic payroll system as a focused, high-stakes example and evaluate whether models can understand a payroll schema, apply rules in the right order, and deliver cent-a",
      "url": "https://arxiv.org/abs/2601.18012",
      "category": "cs.CL"
    },
    {
      "title": "Rethinking Cross-Modal Fine-Tuning: Optimizing the Interaction between Feature Alignment and Target Fitting",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.18231v2 Announce Type: replace-cross \nAbstract: Adapting pre-trained models to unseen feature modalities has become increasingly important due to the growing need for cross-disciplinary knowledge integration. A key challenge here is how to align the representation of new modalities with the most relevant parts of the pre-trained model's representation space to enable accurate knowledge transfer. This requires combining feature alignment with target fine-tuning, but uncalibrated combin",
      "url": "https://arxiv.org/abs/2601.18231",
      "category": "cs.LG"
    },
    {
      "title": "Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.18626v2 Announce Type: replace-cross \nAbstract: Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full ",
      "url": "https://arxiv.org/abs/2601.18626",
      "category": "cs.LG"
    },
    {
      "title": "From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.18702v3 Announce Type: replace-cross \nAbstract: The pursuit of scale in deep learning has entrenched a trade-off: computational throughput is prioritized at the expense of numerical precision. We argue this compromise is fundamentally at odds with the requirements of general intelligence. We propose the \\textit{Exactness Hypothesis}: high-order causal reasoning -- a cornerstone of AGI -- demands a substrate supporting arbitrary-precision, logically consistent arithmetic. We trace prev",
      "url": "https://arxiv.org/abs/2601.18702",
      "category": "cs.LG"
    },
    {
      "title": "Bridging Gulfs in UI Generation through Semantic Guidance",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.19171v2 Announce Type: replace-cross \nAbstract: While generative AI enables high-fidelity UI generation from text prompts, users struggle to articulate design intent and evaluate or refine results-creating gulfs of execution and evaluation. To understand the information needed for UI generation, we conducted a thematic analysis of UI prompting guidelines, identifying key design semantics and discovering that they are hierarchical and interdependent. Leveraging these findings, we devel",
      "url": "https://arxiv.org/abs/2601.19171",
      "category": "cs.HC"
    },
    {
      "title": "Decoupled Split Learning via Auxiliary Loss",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.19261v2 Announce Type: replace-cross \nAbstract: Split learning is a distributed training paradigm where a neural network is partitioned between clients and a server, which allows data to remain at the client while only intermediate activations are shared. Traditional split learning relies on end-to-end backpropagation across the client-server split point. This incurs a large communication overhead (i.e., forward activations and backward gradients need to be exchanged every iteration) ",
      "url": "https://arxiv.org/abs/2601.19261",
      "category": "cs.LG"
    },
    {
      "title": "Safe Exploration via Policy Priors",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.19612v2 Announce Type: replace-cross \nAbstract: Safe exploration is a key requirement for reinforcement learning (RL) agents to learn and adapt online, beyond controlled (e.g. simulated) environments. In this work, we tackle this challenge by utilizing suboptimal yet conservative policies (e.g., obtained from offline data or simulators) as priors. Our approach, SOOPER, uses probabilistic dynamics models to optimistically explore, yet pessimistically fall back to the conservative polic",
      "url": "https://arxiv.org/abs/2601.19612",
      "category": "cs.LG"
    },
    {
      "title": "NRR-Phi: Text-to-State Mapping for Ambiguity Preservation in LLM Inference",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.19933v3 Announce Type: replace-cross \nAbstract: Large language models exhibit a systematic tendency toward early semantic commitment: given ambiguous input, they collapse multiple valid interpretations into a single response before sufficient context is available. We present a formal framework for text-to-state mapping ($\\phi: \\mathcal{T} \\to \\mathcal{S}$) that transforms natural language into a non-collapsing state space where multiple interpretations coexist. The mapping decomposes ",
      "url": "https://arxiv.org/abs/2601.19933",
      "category": "cs.CL"
    },
    {
      "title": "Membership Inference Attacks Against Fine-tuned Diffusion Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.20125v3 Announce Type: replace-cross \nAbstract: Diffusion Language Models (DLMs) represent a promising alternative to autoregressive language models, using bidirectional masked token prediction. Yet their susceptibility to privacy leakage via Membership Inference Attacks (MIA) remains critically underexplored. This paper presents the first systematic investigation of MIA vulnerabilities in DLMs. Unlike the autoregressive models' single fixed prediction pattern, DLMs' multiple maskable",
      "url": "https://arxiv.org/abs/2601.20125",
      "category": "cs.LG"
    },
    {
      "title": "Conditional PED-ANOVA: Hyperparameter Importance in Hierarchical & Dynamic Search Spaces",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.20800v2 Announce Type: replace-cross \nAbstract: We propose conditional PED-ANOVA (condPED-ANOVA), a principled framework for estimating hyperparameter importance (HPI) in conditional search spaces, where the presence or domain of a hyperparameter can depend on other hyperparameters. Although the original PED-ANOVA provides a fast and efficient way to estimate HPI within the top-performing regions of the search space, it assumes a fixed, unconditional search space and therefore cannot ",
      "url": "https://arxiv.org/abs/2601.20800",
      "category": "cs.LG"
    },
    {
      "title": "Solver-in-the-Loop: MDP-Based Benchmarks for Self-Correction and Behavioral Rationality in Operations Research",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.21008v2 Announce Type: replace-cross \nAbstract: Operations Research practitioners routinely debug infeasible models through an iterative process: analyzing Irreducible Infeasible Subsystems (\\IIS{}), identifying constraint conflicts, and systematically repairing formulations until feasibility is achieved. Yet existing LLM benchmarks evaluate OR as one-shot translation -- given a problem description, generate solver code -- ignoring this diagnostic loop entirely. We introduce two bench",
      "url": "https://arxiv.org/abs/2601.21008",
      "category": "cs.LG"
    },
    {
      "title": "SAGE: Sequence-level Adaptive Gradient Evolution for Generative Recommendation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.21452v2 Announce Type: replace-cross \nAbstract: While works such as OneRec have validated the scaling laws of Large Language Models (LLMs) in recommender systems, they rely on a cumbersome separate vocabulary. This dependency prevents the model architecture from reusing native LLM vocabularies, resulting in high maintenance costs and poor scalability. In response, we aim to efficiently reuse open-source LLM architectures without constructing a separate tokenization vocabulary. Further",
      "url": "https://arxiv.org/abs/2601.21452",
      "category": "cs.LG"
    },
    {
      "title": "HER: Human-like Reasoning and Reinforcement Learning for LLM Role-playing",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.21459v3 Announce Type: replace-cross \nAbstract: LLM role-playing, i.e., using LLMs to simulate specific personas, has emerged as a key capability in various applications, such as companionship, content creation, and digital games. While current models effectively capture character tones and knowledge, simulating the inner thoughts behind their behaviors remains a challenge. Towards cognitive simulation in LLM role-play, previous efforts mainly suffer from two deficiencies: data with h",
      "url": "https://arxiv.org/abs/2601.21459",
      "category": "cs.LG"
    },
    {
      "title": "Task-free Adaptive Meta Black-box Optimization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.21475v2 Announce Type: replace-cross \nAbstract: Handcrafted optimizers become prohibitively inefficient for complex black-box optimization (BBO) tasks. MetaBBO addresses this challenge by meta-learning to automatically configure optimizers for low-level BBO tasks, thereby eliminating heuristic dependencies. However, existing methods typically require extensive handcrafted training tasks to learn meta-strategies that generalize to target tasks, which poses a critical limitation for rea",
      "url": "https://arxiv.org/abs/2601.21475",
      "category": "cs.NE"
    },
    {
      "title": "Vidmento: Creating Video Stories Through Context-Aware Expansion With Generative Video",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.22013v2 Announce Type: replace-cross \nAbstract: Video storytelling is often constrained by available material, limiting creative expression and leaving undesired narrative gaps. Generative video offers a new way to address these limitations by augmenting captured media with tailored visuals. To explore this potential, we interviewed eight video creators to identify opportunities and challenges in integrating generative video into their workflows. Building on these insights and establi",
      "url": "https://arxiv.org/abs/2601.22013",
      "category": "cs.HC"
    },
    {
      "title": "Degradation-Aware Frequency Regulation of a Heterogeneous Battery Fleet via Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.22865v2 Announce Type: replace-cross \nAbstract: Battery energy storage systems are increasingly deployed as fast-responding resources for grid balancing services such as frequency regulation and for mitigating renewable generation uncertainty. However, repeated charging and discharging induces cycling degradation and reduces battery lifetime. This paper studies the real-time scheduling of a heterogeneous battery fleet that collectively tracks a stochastic balancing signal subject to p",
      "url": "https://arxiv.org/abs/2601.22865",
      "category": "eess.SY"
    },
    {
      "title": "Reinforcement Learning-Based Co-Design and Operation of Chiller and Thermal Energy Storage for Cost-Optimal HVAC Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2601.22880v2 Announce Type: replace-cross \nAbstract: We study the joint operation and sizing of cooling infrastructure for commercial HVAC systems using reinforcement learning, with the objective of minimizing life-cycle cost over a 30-year horizon. The cooling system consists of a fixed-capacity electric chiller and a thermal energy storage (TES) unit, jointly operated to meet stochastic hourly cooling demands under time-varying electricity prices. The life-cycle cost accounts for both ca",
      "url": "https://arxiv.org/abs/2601.22880",
      "category": "eess.SY"
    },
    {
      "title": "How Hyper-Datafication Impacts the Sustainability Costs in Frontier AI",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.00056v2 Announce Type: replace-cross \nAbstract: Large-scale data has fuelled the success of frontier artificial intelligence (AI) models over the past decade. This expansion has relied on sustained efforts by large technology corporations to aggregate and curate internet-scale datasets. In this work, we examine the environmental, social, and economic costs of large-scale data in AI through a sustainability lens. We argue that the field is shifting from building models from data to act",
      "url": "https://arxiv.org/abs/2602.00056",
      "category": "cs.CY"
    },
    {
      "title": "LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.00462v2 Announce Type: replace-cross \nAbstract: Transforming a large language model (LLM) into a Vision-Language Model (VLM) can be achieved by mapping the visual tokens from a vision encoder into the embedding space of an LLM. Intriguingly, this mapping can be as simple as a shallow MLP transformation. To understand why LLMs can so readily process visual tokens, we need interpretability methods that reveal what is encoded in the visual token representations at every layer of LLM proc",
      "url": "https://arxiv.org/abs/2602.00462",
      "category": "cs.CV"
    },
    {
      "title": "Multi-Agent Teams Hold Experts Back",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.01011v3 Announce Type: replace-cross \nAbstract: Multi-agent LLM systems are increasingly deployed as autonomous collaborators, where agents interact freely rather than execute fixed, pre-specified workflows. In such settings, effective coordination cannot be fully designed in advance and must instead emerge through interaction. However, most prior work enforces coordination through fixed roles, workflows, or aggregation rules, leaving open the question of how well self-organizing team",
      "url": "https://arxiv.org/abs/2602.01011",
      "category": "cs.MA"
    },
    {
      "title": "OLion: Approaching the Hadamard Ideal by Intersecting Spectral and $\\ell_{\\infty}$ Implicit Biases",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.01105v2 Announce Type: replace-cross \nAbstract: Many optimizers can be interpreted as steepest-descent methods under norm-induced geometries, and thus inherit corresponding implicit biases. We introduce \\nameA{} (\\fullname{}), which combines spectral control from orthogonalized update directions with $\\ell_\\infty$-style coordinate control from sign updates. \\nameA{} forms a Lion-style momentum direction, approximately orthogonalizes it via a few Newton--Schulz iterations, and then app",
      "url": "https://arxiv.org/abs/2602.01105",
      "category": "cs.LG"
    },
    {
      "title": "Supervised Fine-Tuning Needs to Unlock the Potential of Token Priority",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.01227v2 Announce Type: replace-cross \nAbstract: The transition from fitting empirical data to achieving true human utility is fundamentally constrained by a granularity mismatch, where fine-grained autoregressive generation is often supervised by coarse or uniform signals. This position paper advocates Token Priority as the essential bridge, formalizing Supervised Fine-Tuning (SFT) not as simple optimization but as a precise distribution reshaping process that aligns raw data with the",
      "url": "https://arxiv.org/abs/2602.01227",
      "category": "cs.CL"
    },
    {
      "title": "TxRay: Agentic Postmortem of Live Blockchain Attacks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.01317v4 Announce Type: replace-cross \nAbstract: Decentralized Finance (DeFi) has turned blockchains into financial infrastructure, allowing anyone to trade, lend, and build protocols without intermediaries, but this openness exposes pools of value controlled by code. Within five years, the DeFi ecosystem has lost over 15.75B USD to reported exploits. Many exploits arise from permissionless opportunities that any participant can trigger using only public state and standard interfaces, ",
      "url": "https://arxiv.org/abs/2602.01317",
      "category": "cs.CR"
    },
    {
      "title": "From Pragmas to Partners: A Symbiotic Evolution of Agentic High-Level Synthesis",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.01401v3 Announce Type: replace-cross \nAbstract: The rise of large language models has sparked interest in AI-driven hardware design, raising the question: does high-level synthesis (HLS) still matter in the agentic era? We argue that HLS remains essential. While we expect mature agentic hardware systems to leverage both HLS and RTL, this paper focuses on HLS and its role in enabling agentic optimization. HLS offers faster iteration cycles, portability, and design permutability that ma",
      "url": "https://arxiv.org/abs/2602.01401",
      "category": "cs.CL"
    },
    {
      "title": "Stein-Rule Shrinkage for Stochastic Gradient Estimation in High Dimensions",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.01777v2 Announce Type: replace-cross \nAbstract: Stochastic gradient methods are central to large-scale learning, but they treat mini-batch gradients as unbiased estimators, which classical decision theory shows are inadmissible in high dimensions. We formulate gradient computation as a high-dimensional estimation problem and introduce a framework based on Stein-rule shrinkage. We construct a gradient estimator that adaptively contracts noisy mini-batch gradients toward a stable estima",
      "url": "https://arxiv.org/abs/2602.01777",
      "category": "cs.LG"
    },
    {
      "title": "CAM: A Causality-based Analysis Framework for Multi-Agent Code Generation Systems",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.02138v2 Announce Type: replace-cross \nAbstract: Despite the remarkable success that Multi-Agent Code Generation Systems (MACGS) have achieved, the inherent complexity of multi-agent architectures produces substantial volumes of intermediate outputs. To date, the individual importance of these intermediate outputs to the system correctness remains opaque, which impedes targeted optimization of MACGS designs. To address this challenge, we propose CAM, the first \\textbf{C}ausality-based ",
      "url": "https://arxiv.org/abs/2602.02138",
      "category": "cs.SE"
    },
    {
      "title": "EvoMU: Evolutionary Machine Unlearning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.02139v2 Announce Type: replace-cross \nAbstract: Machine unlearning aims to unlearn specified training data (e.g. sensitive or copyrighted material). A prominent approach is to fine-tune an existing model with an unlearning loss that retains overall utility. The space of suitable unlearning loss functions is vast, making the search for an optimal loss function daunting. Additionally, there might not even exist a universally optimal loss function: differences in the structure and overla",
      "url": "https://arxiv.org/abs/2602.02139",
      "category": "cs.LG"
    },
    {
      "title": "Decoupling Generalizability and Membership Privacy Risks in Neural Networks",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.02296v2 Announce Type: replace-cross \nAbstract: A deep learning model usually has to sacrifice some utilities when it acquires some other abilities or characteristics. Privacy preservation has such trade-off relationships with utilities. The loss disparity between various defense approaches implies the potential to decouple generalizability and privacy risks to maximize privacy gain. In this paper, we identify that the model's generalization and privacy risks exist in different region",
      "url": "https://arxiv.org/abs/2602.02296",
      "category": "cs.LG"
    },
    {
      "title": "ReasonEdit: Editing Vision-Language Models using Human Reasoning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.02408v3 Announce Type: replace-cross \nAbstract: Model editing aims to correct errors in large, pretrained models without altering unrelated behaviors. While some recent works have edited vision-language models (VLMs), no existing editors tackle reasoning-heavy tasks, which typically require humans and models to reason about images. We therefore propose ReasonEdit, the first VLM editor to let users explain their reasoning during editing, introducing a new, practical model editing setup",
      "url": "https://arxiv.org/abs/2602.02408",
      "category": "cs.CV"
    },
    {
      "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.02437v3 Announce Type: replace-cross \nAbstract: Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through two complementary reasoning paradigms. We incorporate world knowledge-enhanced textual reasoning into generation",
      "url": "https://arxiv.org/abs/2602.02437",
      "category": "cs.CV"
    },
    {
      "title": "Step-Wise Refusal Dynamics in Autoregressive and Diffusion Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.02600v2 Announce Type: replace-cross \nAbstract: Diffusion language models (DLMs) have recently emerged as a promising alternative to autoregressive (AR) models, offering parallel decoding and controllable sampling dynamics while achieving competitive generation quality at scale. Despite this progress, the role of sampling mechanisms in shaping refusal behavior and jailbreak robustness remains poorly understood. In this work, we present a fundamental analytical framework for step-wise ",
      "url": "https://arxiv.org/abs/2602.02600",
      "category": "cs.LG"
    },
    {
      "title": "Semantics-Aware Generative Latent Data Augmentation for Learning in Low-Resource Domains",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.02841v2 Announce Type: replace-cross \nAbstract: Despite strong performance in data-rich regimes, deep learning often underperforms in the data-scarce settings common in practice. While foundation models (FMs) trained on massive datasets demonstrate strong generalization by extracting general-purpose features, they can still suffer from scarce labeled data during downstream fine-tuning. To address this, we propose GeLDA, a semantics-aware generative latent data augmentation framework t",
      "url": "https://arxiv.org/abs/2602.02841",
      "category": "cs.LG"
    },
    {
      "title": "Learning to Select: Query-Aware Adaptive Dimension Selection for Dense Retrieval",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.03306v2 Announce Type: replace-cross \nAbstract: Dense retrieval represents queries and documents as high-dimensional embeddings, but these representations can be redundant at the query level: for a given information need, only a subset of dimensions is consistently helpful for ranking. Prior work addresses this via pseudo-relevance feedback (PRF) based dimension importance estimation, which can produce query-aware masks without labeled data but often relies on noisy pseudo signals and",
      "url": "https://arxiv.org/abs/2602.03306",
      "category": "cs.IR"
    },
    {
      "title": "DiGAN: Diffusion-Guided Attention Network for Early Alzheimer's Disease Detection",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.03881v2 Announce Type: replace-cross \nAbstract: Early diagnosis of Alzheimer's disease (AD) remains a major challenge due to the subtle and temporally irregular progression of structural brain changes in the prodromal stages. Existing deep learning approaches require large longitudinal datasets and often fail to model the temporal continuity and modality irregularities inherent in real-world clinical data. To address these limitations, we propose the Diffusion-Guided Attention Network",
      "url": "https://arxiv.org/abs/2602.03881",
      "category": "cs.CV"
    },
    {
      "title": "Structural shifts in institutional participation and collaboration within the AI arXiv preprint research ecosystem",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.03969v2 Announce Type: replace-cross \nAbstract: The emergence of large language models (LLMs) represents a significant technological shift within the scientific ecosystem, particularly within the field of artificial intelligence (AI). This paper examines structural changes in the AI research landscape using a dataset of arXiv preprints (cs.AI) from 2021 through 2025. Given the rapid pace of AI development, the preprint ecosystem has become a critical barometer for real-time scientific",
      "url": "https://arxiv.org/abs/2602.03969",
      "category": "cs.SI"
    },
    {
      "title": "Bypassing the Rationale: Causal Auditing of Implicit Reasoning in Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.03994v2 Announce Type: replace-cross \nAbstract: Chain-of-thought (CoT) prompting is widely used as a reasoning aid and is often treated as a transparency mechanism. Yet behavioral gains under CoT do not imply that the model's internal computation causally depends on the emitted reasoning text, i.e., models may produce fluent rationales while routing decision-critical computation through latent pathways. We introduce a causal, layerwise audit of CoT faithfulness based on activation pat",
      "url": "https://arxiv.org/abs/2602.03994",
      "category": "cs.LG"
    },
    {
      "title": "Understanding and Guiding Layer Placement in Parameter-Efficient Fine-Tuning of Large Language Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.04019v2 Announce Type: replace-cross \nAbstract: As large language models (LLMs) continue to grow, the cost of full-parameter fine-tuning has made parameter-efficient fine-tuning (PEFT) the default strategy for downstream adaptation. Constraints from inference latency in scalable serving and fine-tuning cost in edge or rapid-deployment settings make the choice of which layers to fine-tune unavoidable. Yet current practice typically applies PEFT uniformly across all layers, with limited",
      "url": "https://arxiv.org/abs/2602.04019",
      "category": "cs.LG"
    },
    {
      "title": "Improving 2D Diffusion Models for 3D Medical Imaging with Inter-Slice Consistent Stochasticity",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.04162v2 Announce Type: replace-cross \nAbstract: 3D medical imaging is in high demand and essential for clinical diagnosis and scientific research. Currently, diffusion models (DMs) have become an effective tool for medical imaging reconstruction thanks to their ability to learn rich, high-quality data priors. However, learning the 3D data distribution with DMs in medical imaging is challenging, not only due to the difficulties in data collection but also because of the significant com",
      "url": "https://arxiv.org/abs/2602.04162",
      "category": "cs.CV"
    },
    {
      "title": "Extracting Recurring Vulnerabilities from Black-Box LLM-Generated Software",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.04894v2 Announce Type: replace-cross \nAbstract: LLMs are increasingly used for code generation, but their outputs often follow recurring templates that can induce predictable vulnerabilities. We study \\emph{vulnerability persistence} in LLM-generated software and introduce \\emph{Feature--Security Table (FSTab)} with two components. First, FSTab enables a black-box attack that predicts likely backend vulnerabilities from observable frontend features and knowledge of the source LLM, wit",
      "url": "https://arxiv.org/abs/2602.04894",
      "category": "cs.CR"
    },
    {
      "title": "Evaluating Kubernetes Performance for GenAI Inference: From Automatic Speech Recognition to LLM Summarization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.04900v2 Announce Type: replace-cross \nAbstract: As Generative AI (GenAI), particularly inference, rapidly emerges as a dominant workload category, the Kubernetes ecosystem is proactively evolving to natively support its unique demands. This industry paper demonstrates how emerging Kubernetes-native projects can be combined to deliver the benefits of container orchestration, such as scalability and resource efficiency, to complex AI workflows. We implement and evaluate an illustrative,",
      "url": "https://arxiv.org/abs/2602.04900",
      "category": "cs.ET"
    },
    {
      "title": "Momentum Attention: The Physics of In-Context Learning and Spectral Forensics for Mechanistic Interpretability",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.04902v2 Announce Type: replace-cross \nAbstract: The Mechanistic Interpretability (MI) program has mapped the Transformer as a precise computational graph. We extend this graph with a conservation law and time-varying AC dynamics, viewing it as a physical circuit. We introduce Momentum Attention, a symplectic augmentation embedding physical priors via the kinematic difference operator $p_t = q_t - q_{t-1}$, implementing the symplectic shear $\\hat{q}_t = q_t + \\gamma p_t$ on queries and",
      "url": "https://arxiv.org/abs/2602.04902",
      "category": "cs.LG"
    },
    {
      "title": "SLAY: Geometry-Aware Spherical Linearized Attention with Yat-Kernel",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.04915v2 Announce Type: replace-cross \nAbstract: We propose a new class of linear-time attention mechanisms based on a relaxed and computationally efficient formulation of the recently introduced E-Product, often referred to as the Yat-kernel (Bouhsine, 2025). The resulting interactions are geometry-aware and inspired by inverse-square interactions in physics. Our method, Spherical Linearized Attention with Yat Kernels (SLAY), constrains queries and keys to the unit sphere so that atte",
      "url": "https://arxiv.org/abs/2602.04915",
      "category": "cs.LG"
    },
    {
      "title": "ASA: Training-Free Representation Engineering for Tool-Calling Agents",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.04935v2 Announce Type: replace-cross \nAbstract: Adapting LLM agents to domain-specific tool calling remains notably brittle under evolving interfaces. Prompt and schema engineering is easy to deploy but often fragile under distribution shift and strict parsers, while continual parameter-efficient fine-tuning improves reliability at the cost of training, maintenance, and potential forgetting. We identify a critical Lazy Agent failure mode where tool necessity is nearly perfectly decoda",
      "url": "https://arxiv.org/abs/2602.04935",
      "category": "cs.SE"
    },
    {
      "title": "Graph-Theoretic Analysis of Phase Optimization Complexity in Variational Wave Functions for Heisenberg Antiferromagnets",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.04943v2 Announce Type: replace-cross \nAbstract: Despite extensive study, the phase structure of the wavefunctions in frustrated Heisenberg antiferromagnets (HAF) is not yet systematically characterized. In this work, we represent the Hilbert space of an HAF as a weighted graph, which we term the Hilbert graph (HG), whose vertices are spin configurations and whose edges are generated by off-diagonal spin-flip terms of the Heisenberg Hamiltonian, with weights set by products of wavefunc",
      "url": "https://arxiv.org/abs/2602.04943",
      "category": "cond-mat.str-el"
    },
    {
      "title": "EBPO: Empirical Bayes Shrinkage for Stabilizing Group-Relative Policy Optimization",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.05165v2 Announce Type: replace-cross \nAbstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective for enhancing the reasoning capabilities of Large Language Models (LLMs). However, dominant approaches like Group Relative Policy Optimization (GRPO) face critical stability challenges: they suffer from high estimator variance under computational constraints (small group sizes) and vanishing gradient signals in saturated failure regimes where all responses yield i",
      "url": "https://arxiv.org/abs/2602.05165",
      "category": "cs.LG"
    },
    {
      "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.05494v2 Announce Type: replace-cross \nAbstract: Reinforcement Learning with Verified Reward (RLVR) has emerged as a critical paradigm for advancing the reasoning capabilities of Large Language Models (LLMs). Most existing RLVR methods, such as GRPO and its variants, ensure stable updates by constraining policy divergence through clipping likelihood ratios. This paper introduces a unified clipping framework that characterizes existing methods via a general notion of policy divergence, ",
      "url": "https://arxiv.org/abs/2602.05494",
      "category": "cs.LG"
    },
    {
      "title": "Alignment Verifiability in Large Language Models: Normative Indistinguishability under Behavioral Evaluation",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.05656v2 Announce Type: replace-cross \nAbstract: Behavioral evaluation is the dominant paradigm for assessing alignment in large language models (LLMs). In current practice, observed compliance under finite evaluation protocols is treated as evidence of latent alignment. However, the inference from bounded behavioral evidence to claims about global latent properties is rarely analyzed as an identifiability problem. In this paper, we study alignment evaluation through the lens of statis",
      "url": "https://arxiv.org/abs/2602.05656",
      "category": "cs.LG"
    },
    {
      "title": "Exploring AI-Augmented Sensemaking of Patient-Generated Health Data: A Mixed-Method Study with Healthcare Professionals in Cardiac Risk Reduction",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.05687v3 Announce Type: replace-cross \nAbstract: Individuals are increasingly generating substantial personal health and lifestyle data, e.g. through wearables and smartphones. While such data could transform preventative care, its integration into clinical practice is hindered by its scale, heterogeneity and the time pressure and data literacy of healthcare professionals (HCPs). We explore how large language models (LLMs) can support sensemaking of patient-generated health data (PGHD)",
      "url": "https://arxiv.org/abs/2602.05687",
      "category": "cs.HC"
    },
    {
      "title": "Bagging-Based Model Merging for Robust General Text Embeddings",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.05787v2 Announce Type: replace-cross \nAbstract: General-purpose text embedding models underpin a wide range of NLP and information retrieval applications, and are typically trained on large-scale multi-task corpora to encourage broad generalization. However, it remains unclear how different multi-task training strategies compare in practice, and how to efficiently adapt embedding models as new domains and data types continually emerge. In this work, we present a systematic study of mu",
      "url": "https://arxiv.org/abs/2602.05787",
      "category": "cs.IR"
    },
    {
      "title": "Rethinking Memory Mechanisms of Foundation Agents in the Second Half: A Survey",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06052v3 Announce Type: replace-cross \nAbstract: The research of artificial intelligence is undergoing a paradigm shift from prioritizing model innovations over benchmark scores towards emphasizing problem definition and rigorous real-world evaluation. As the field enters the \"second half,\" the central challenge becomes real utility in long-horizon, dynamic, and user-dependent environments, where agents face context explosion and must continuously accumulate, manage, and selectively re",
      "url": "https://arxiv.org/abs/2602.06052",
      "category": "cs.CL"
    },
    {
      "title": "Addressing the Waypoint-Action Gap in End-to-End Autonomous Driving via Vehicle Motion Models",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06214v2 Announce Type: replace-cross \nAbstract: End-to-End Autonomous Driving (E2E-AD) systems are typically grouped by the nature of their outputs: (i) waypoint-based models that predict a future trajectory, and (ii) action-based models that directly output throttle, steer and brake. Most recent benchmark protocols and training pipelines are waypoint-based, which makes action-based policies harder to train and compare, slowing their progress. To bridge this waypoint-action gap, we pr",
      "url": "https://arxiv.org/abs/2602.06214",
      "category": "cs.CV"
    },
    {
      "title": "Temperature Scaling Attack Disrupting Model Confidence in Federated Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06638v2 Announce Type: replace-cross \nAbstract: Predictive confidence serves as a foundational control signal in mission-critical systems, directly governing risk-aware logic such as escalation, abstention, and conservative fallback. While prior federated learning attacks predominantly target accuracy or implant backdoors, we identify confidence calibration as a distinct attack objective. We present the Temperature Scaling Attack (TSA), a training-time attack that degrades calibration",
      "url": "https://arxiv.org/abs/2602.06638",
      "category": "cs.LG"
    },
    {
      "title": "Zero-shot Generalizable Graph Anomaly Detection with Mixture of Riemannian Experts",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06859v2 Announce Type: replace-cross \nAbstract: Graph Anomaly Detection (GAD) aims to identify irregular patterns in graph data, and recent works have explored zero-shot generalist GAD to enable generalization to unseen graph datasets. However, existing zero-shot GAD methods largely ignore intrinsic geometric differences across diverse anomaly patterns, substantially limiting their cross-domain generalization. In this work, we reveal that anomaly detectability is highly dependent on t",
      "url": "https://arxiv.org/abs/2602.06859",
      "category": "cs.LG"
    },
    {
      "title": "InftyThink+: Effective and Efficient Infinite-Horizon Reasoning via Reinforcement Learning",
      "date": "Wed, 11 Feb 2026 00:00:00 -0500",
      "summary": "arXiv:2602.06960v2 Announce Type: replace-cross \nAbstract: Large reasoning models achieve strong performance by scaling inference-time chain-of-thought, but this paradigm suffers from quadratic cost, context length limits, and degraded reasoning due to lost-in-the-middle effects. Iterative reasoning mitigates these issues by periodically summarizing intermediate thoughts, yet existing methods rely on supervised learning or fixed heuristics and fail to optimize when to summarize, what to preserve",
      "url": "https://arxiv.org/abs/2602.06960",
      "category": "cs.CL"
    }
  ],
  "status": "success",
  "error": null
}